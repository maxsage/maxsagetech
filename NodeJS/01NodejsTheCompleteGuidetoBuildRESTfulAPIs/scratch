That means when the
        application involves I/O operations (eg accessing the file system or the network), the thread doesn’t wait (or
        block) for the result of the operation. It is released to serve other clients. - This architecture makes Node
        ideal for building I/O-intensive applications. - You should avoid using Node for CPU-intensive applications,
        such as a video encoding service. Because while executing these operations, other clients have to wait for the
        single thread to finish its job and be ready to serve them. - In Node, we don’t have browser environment objects
        such as window or the document object. Instead, we have other objects that are not available in browsers, such
        as objects for working with the file system, network, operating system, etc.

        09 Asking Questions ------------------- Asking Questions Section 1, Lecture 9 You may have questions throughout
        your course. Follow these steps to make the most of your course and become the best coder you can be.

        1. Do your own research. You can usually find the answer to your question by googling the question or the error
        you’re experiencing. 2. Try to solve the problem without “phoning a friend”. Coming to the resolution on your
        own will help you grow and become a stronger coder. 3. Still stuck? Post your question on the discussion board
        for the course. My team is here to help! 4. Help other students by answering their questions on the discussion
        board. The best way to learn something is to teach it.

        “Everyone should know how to code a computer, because it teaches you how to think!” – Steve Jobs

        Happy coding,

        Mosh

        Section 2 - Node Module System ============================== 10 Introduction --------------- Throughout this
        section we will investigate some of the built in modules in Node: os fs events http We will also cover how to
        create your own modules.

        11 Global Object ---------------- Previously we used the console.log command. The console object is known as a
        global object. It is part of the global scope which means we can access it from anywhere in our code.

        There are a bunch of other objects and functions that are globally available in Node. setTimeout() is used to
        call a function after a delay. This function is part of standard Javascript so it can be used on the client, in
        the browser or in Node. We also have: clearTimeout()

        setInterval() - call a function repeatedly at a specified interval. clearInterval() - stops the function from
        being called repeatedly.

        The above are all Javascript global objects.


        In browsers we have the window object that represents the global scope. So all the variables and functions that
        are defined globally we can access via the window object:

        window.console.log or console.log

        The Javascript engine will prefix this statement with window.console.log because that is where the object is
        defined. Similarly the setTimeout, clearTimeout, setInterval and clearInterval methods all belong to the window
        object so we can call

        window.setTimeout

        In Node instead of the window object we have an object called global so the functions discussed above through
        the global object. One thing to know about Node is that a variable declared like this:

        var message = '';

        is not added to the global object. So, in Node, if we wrote:

        console.log(global.message);

        we would see 'undefined' in the console. This is due to Node's modular system which we will learn about in the
        next section.

        12 Modules ---------- In the last section we learned that in client side Javascript that we run in a browser
        when we declare a variable or a function it is added to the global scope:

        var sayHello = function() {

        }

        window.sayHello();

        The problem with this behaviour that is in a real world application we often split our Javascript code into
        multiple files. This means that it is possible to define the same sayHello function. Because the function is
        added to the global scope one definition will overwrite the other.

        In order to build reliable and maintainable applications we should avoid defining variables and functions in the
        global scope. Instead we need modularity where we create small building blocks or modules where we define our
        variables and functions. They are then encapsulated in that module.

        Every file in a node application is considered a module.

        Variables and functions defined within the module are private (in OOP terms). If we want to make a variable of
        function available outside of the module we need to explicitly export it.

        Every Node application has at least one file or module which we refer to as the main module.

        If we write out the module object to the console:

        console.log(module)

        We will see a JSON object containing various properties such as id, exports, parent, filename, loaded etc:

        Module { id: '.', exports: {}, parent: null, filename:
        'C:\\DevelopmentTutorials\\TheCompleteNodeJSCourse\\02-node-module-system\\12-modules.js', loaded: false,
        children: [], paths: [ 'C:\\DevelopmentTutorials\\TheCompleteNodeJSCourse\\02-node-module-system\\node_modules',
        'C:\\DevelopmentTutorials\\TheCompleteNodeJSCourse\\node_modules', 'C:\\DevelopmentTutorials\\node_modules',
        'C:\\node_modules' ] }


        13 Creating a Module -------------------- Let's add a new module called logger.js for logging messages. The
        module will be re-used in this application and potentially other applications. In this module we will imagine
        that we are going to use a remote logging service for logging our messages. So there are third party websites
        out there that provide a url where we can send an http request to log a message:


        var url = 'http://mylogger.io/log';

        We also create a function called log that takes a message and sends an http request. For now, for simplicity, we
        will just write the message to the console:

        function log(message) { // Send an HTTP request }

        The variable and the log function are both scoped to this module - they are private and not visible from the
        outside.

        However in app.js we want to be able to access the log function. So we need to make this public and visible from
        the outside.

        One of the properties of the module object is exports which by default is set to an empty object. Anything that
        we add to this object will be exported from the module:

        module.exports.log = log;

        Similarly if we wanted to export the url we defined in 13-logger.js we could write the following:

        module.exports.url = url;

        We can change the name that get's exported:

        module.exports.endPoint = url;


        We only export a subset of functions from modules - keeping other details private.

        14 - Loading a Module ---------------------

        To load a module we use the require function:

        require('./13-logger');

        This is a node function it is not available in the browser. The js file extension is optional as Node assumes we
        will specify a Javascript file and therefore automatically adds the js extension.

        If the file was in a subfolder we could specify:

        require('./subFolder/logger');

        or if the file was in a parent folder:

        require('../logger');


        The require function returns the object that is exported from the specified module.

        To demonstrate write the following:

        var logger = require('./logger');

        console.log(logger);

        Then we run the application we get an object with a single method called log that is a function. We can now call
        this function in app.js:

        logger.log('message');

        In more recent versions of Javascript we have the ability to use a const. So, as a best practice, when loading a
        module using the require function it is better to store the result in constant: const logger =
        require('./13-logger');

        This prevents us from accidentally overwriting the value of logger:

        logger = 1;

        When using a const this will result in a "Assignment to constant variable" error.

        One last thing to mention is that sometimes instead of exporting an object from a module you might want to
        export a single function. For example, in our logger module, we don't necessarily need an object because we have
        a single method. An object would be useful if we had multiple methods or properties but in this case we can
        export a single function: module.exports = log;

        then in app.js call the function directly:

        logger('message');

        15 Module Wrapper Function -------------------------- You now know that the variables and functions defined in a
        module are scoped to that module. How does Node do this? To illustrate let's introduce a syntax error to the
        first line of logger.js (this must be on the first line):

        var x=;

        If you run logger.js you will receive the following error:

        (function (exports, require, module, __filename, __dirname) { var x =;

        SyntaxError: Unexpected token ;

        If you look above the SyntaxError message you will see a function declaration which accepts the following
        parameters - exports, require, module, __filename, __dirname.

        Under the hood Node does not execute the code defined in our module directly. Instead it wraps it inside a
        function (the one we saw in the error message above). So, at runtime, our code will look similar to this (we
        will remove the syntax error):

        (function (exports, require, module, __filename, __dirname) { var url = 'http://mylogger.io/log';

        function log(message) { // Send an HTTP request console.log(message); }

        module.exports = log; })

        The actual code is more complex than shown above but to avoid distracting from the topic we will keep the
        example simple. More advanced Javascript developers will recognise the code above as an Immediately Invoked
        Function Expression of IIFE.

        The takeaway is that Node never executes our code directly. Instead it wraps each module in a function. Looking
        at the parameters that the module accepts we have require (which we have seen before). The require function
        appears to be global but actually it is local to each module - in every module require is one of the parameter
        passed into the function.

        The function is known as the Module Wrapper Function. We have also used the module function previously. The
        exports parameter is a shortcut to module.exports so we could write:

        module.exports.log = log;

        or

        exports.log = log;

        However you can't reset exports like this:

        exports = log; // module.exports

        In addition we also have __filename and __dirname parameters which represent the name of the file and the path.
        Let's take a look:

        console.log(__filename); console.log(__dirname);

        __dirname returns a path to the directory that contains that module.

        16 Path Module -------------- In the last section we mentioned that there are a few useful modules that are
        built into the core of Node. These modules allow you to work with files, the network, operating system etc. and
        include the following: - File System - work with files. - HTTP - create web servers that listen for HTTP
        requests. - OS - work with the Operating System. - Path - provides utilities for working with paths. - Process -
        information about the current process. - Query Strings - useful when building HTTP services. - Stream - for
        working with streams of data.

        In this section we will investigate the Path module. If you run 16-path-module.js you will get the following
        information:

        { root: 'C:\\', dir: 'C:\\DevelopmentTutorials\\TheCompleteNodeJSCourse\\02-node-module-system', base:
        '16-path-module.js', ext: '.js', name: '16-path-module' }

        17 OS Module ------------ This section describes how to get information about the current operating system. Some
        of the available methods include: - freemem - totalmem - userInfo([options]) - uptime

        If you run 17-os-module.js you will get the following information:

        Total Memory: 17081073664 Free Memory: 10441883648

        Before node it was not possible to get information about the operating system using Javascript. Javascript only
        ran inside a browser and we could only work with the Window or Document objects.


        18 File System Module --------------------- Almost all of the functions in the fs module come in two forms -
        synchronous (blocking) or asynchronous (non-blocking). Where possible you should avoid using the synchronous
        methods. As we mentioned in the previous section a Node process has a single thread. If you are u using Node to
        build the backend for your application you may have hundreds or thousands of clients connecting to that
        back-end.

        If you keep that client busy you wont be able serve many clients.

        All the asynchronous methods take a function as their last argument. This function is known as a callback.

        19 Events Module ---------------- One of the core concepts in Node is events. An event is basically a signal
        that indicates that something has happened in our application.

        In the Events module we have a class called EventEmitter. When we call require events the require function
        returns an EventEmitter class (hence the casing):

        const EventEmitter = require('events');

        We then create an instance of the EventEmitter class:

        const emitter = new EventEmitter();

        The emit method raises an event:

        emitter.emit('messageLogged');

        In order to respond to the event being raised we need to register a listener:

        emitter.on('messageLogged', function() { console.log('Listener called'); });

        the on method takes two arguments - the name of the event to listen for and a callback function.

        The order in which you define the emitter and the listener is important. If you register the listener after
        calling the emit method it will not pick up the event. This is because when we call the emit method it iterates
        over all the registered listeners and calls them synchronously.

        20 Event Arguments ------------------

        Often when you raise an event you also want to send some information about that event. As an example, let's
        assume that when we log a message our remote login service might generate an id for that message. Perhaps we
        want to return that id to the client or it may give us a Url to access that log message directly. When raising
        an event, we can add additional arguments, referred to as event arguments:

        emitter.emit('messageLogged', 1, 'url');

        The magic values that we supply above are a bit confusing. A better practice is to encapsulate the values inside
        an object:

        emitter.emit('messageLogged', {id: 1, url: 'http://' });

        When registering the listener the callback function can also recieve the event argument:

        emitter.on('messageLogged', function(arg) { console.log('Listener called'); });

        One last way to simplify the code is to use the ECMAScript 6 arrow function. An arrow functon allows you to
        remove the function keyword and add an arrow =>:


        21 Extending Event Emitter --------------------------

        In the real world it is quite rare that you would work with the EventEmitter directly. Instead you normally
        create a class that has all the abilities of the EventEmitter and then you would use that class in your code.

        To explain open the 21-logger.js module where we are exporting a simple logger function called log which writes
        the message to the console. After this we want to raise an event. Later in the app module we will respond to
        that event.

        We create a class in 21-logger.js called Logger that extends the EventEmitter class:

        class Logger extends EventEmitter {

        This gives the Logger class all the functionality that is defined in EventEmitter but we can also add additional
        functionality. When a function is defined in a class it is known as a method. Also, the function keyword is not
        required.

        Instead of using the EventEmitter class in 21-logger.js we use an instance of the logger class

        22 HTTP Module -------------- One of the powerful building blocks of Node is the Http module that we use for
        creating networking applications. For example, we can create a web server that listens for Http requests on a
        given port. With this we can easily create a backend service for our client applications - like a web
        application that we build with React or Angular or a mobile application running on a mobile device.

        In the real world we are not going to use the Http module to build a backend service for our application. The
        reason is that as we add more routes our code becomes complicated. Instead we use a framework called express
        which gives our application a clean structure to handle various routes. Internally the express framework is
        built on top of the Http module in Node.

        23 Recap --------

        Node Core So, in this section, you learned that: - We don’t have the window object in Node. - The global object
        in Node is “global”. - Unlike browser applications, variables we define are not added to the “global” object. -
        Every file in a Node application is a module. Node automatically wraps the code in each file with an IIFE
        (Immediately-invoked Function Expression) to create scope. So, variables and functions defined in one file are
        only scoped to that file and not visible to other files unless explicitly exported. - To export a variable or
        function from a module, you need to add them to module.exports: module.exports.sayHello = sayHello; - To load a
        module, use the require function. This function returns the module.exports object exported from the target
        module: const logger = require(‘./logger’); - Node has a few built-in modules that enable us to work with the
        file system, path objects, network, operating system, etc. - EventEmitter is one of the core classes in Node
        that allows us to raise (emit) and handle events. Several built-in classes in Node derive from EventEmitter. -
        To create a class with the ability to raise events, we should extend EventEmitter: class Logger extends
        EventEmitter { }

        Node Package Manager ==================== 24 Introduction ----------------- NPM or Node Package Manager is
        command line tool as well as a registry of third party libraries that we can add to our Node applications. So
        for pretty much any kind of functionality that you want to add to your application there is most likely a free
        open source library/package or node module on npmjs.com.

        npm gets installed when you install node.

        To display the version of npm you have installed npm -v

        To display the version of node you have installed node -v

        To install a specific version of npm globally: npm i -g npm@5.5.1

        25 package.json --------------- package.json is a Json file that contains some basic information about the
        application or the project such as: - name - version - authors - address of git repo

        All node applications have a package.json file by default.

        To create a package.json file we run npm init

        To create a package.json file without specifying any options: npm init --yes

        26 Installing a Node Package ---------------------------- The underscore library is a Javascript utility menu:
        npm i underscore

        This will do two things: - Adds a dependencies section to pacakage.json - Downloads underscore into the
        node_modules folder

        In the underscore folder there will be another package.json file. Every node module has a package.json file just
        like our node application.

        As an aside, there is no longer a need to supply the --save flag when running npm install because the dependency
        is written to the package.json file by default.

        27 Using a Package ------------------ var _ = require('underscore');

        The require function first assumes that the module name supplied is a core module. In node we don't have a core
        module called underscore so the require function thinks maybe underscore is a file or folder in this project.
        Earlier in the course we learnt that in order to reference a file or folder we use ./ but our node application
        does not contain a file or folder called underscore so the require function then moves onto the third step. It
        assumes that the module exists inside the node_modules folder.

        28 Package Dependencies ----------------------- Install mongoose: npm i mongoose

        This should update our package.json file. The node_modules folder will contain a number of new folders - these
        are other node packages that mongoose is dependent upon. In the previous version of npm we had a different
        behaviour. All the dependencies of a given package were stored inside that package folder. However this created
        a mess because we ended up with the same package being installed multiple times. Also, in Windows, there is a
        limitation with the number of characters in a path. With current version of npm all dependencies as well as
        their dependencies are stored under the main node_modules folder. The exception is that if one of the packages
        uses a different version of a dependency then that version will be stored locally with that package.

        29 NPM Packages and SCM ----------------------- In a real world application we will have a large number of child
        folders in the node_modules folder. The size of the node_modules folder will be several megabytes. When checking
        in your source code you want to exclude this folder. This prevents people from having to wait around to download
        this large folder.

        So what about all our dependencies. Well these are all stored in the package.json file. We can restore all our
        dependencies by running: npm i This will download the relevant dependencies from npm registry.

        We will describe the steps required to exclude the node_modules folder from git.

        If you run:

        git status

        you should see that the node_modules folder is listed as one of the files or folders to be uploaded to git.

        If we add a folder called .gitignore to the root folder with the following contents:

        node_modules/

        and then run:

        git status

        again you should see the node_modules folder is now excluded from the list of files or folders to be uploaded to
        git.

        Finally we can run git add . and git commit -m "Our first commit"

        30 Semantic Versioning ---------------------- Earlier we mentioned the caret character: "mongoose": "^4.13.6" In
        order to understand it's purpose we first need to understand Semantic Versioning or SemVer. In Semantic
        Versioning the version of a node package has three components. The first number is the major version, the second
        is the minor version, the third is the patch version.

        Consider the above mongoose dependency. If the developers of mongoose discover a bug in this version they will
        fix the bug and release a new version 4.13.7.

        The minor version is used for adding new features that don't break the existing API: 4.14.0. The patch version
        is 0 here because the developers have not yet found a bug.

        Finally if they add a new features that could potentially break the existing applications that depend upon this
        version of mongoose then they will increase the major version: 5.0.0

        The caret character in the following dependency declaration: "mongoose": "^4.13.6" tells npm that we are
        interested in any version of mongoose as long as the major version is 4. So any newer minor or patch versions
        will be downloaded and installed when you run: npm i An alternative to using the caret character is to specify
        the following: // 4.x

        The other character used by npm is ~: "underscore": "~1.8.3" This example means that you are interested in any
        version as long as the major version is 1 and the minor version is 8. This can also be written: "underscore":
        "~1.8.x"

        If you want to ensure that an exact version of a node package is used then use: "underscore": "1.8.3"

        31 Listing the Installed Packages --------------------------------- To show all the npm packages and their
        dependencies: npm list

        The resulting tree displays the dependencies of your application and their dependencies.

        To list just the dependencies of your application: npm list --depth=0


        32 Viewing Registry Info for a Package -------------------------------------- To show metadata about a package
        (license details, dependencies etc.) npm view mongoose

        To view a specific property:

        npm view mongoose versions

        npm view mongoose dependencies

        This will display a subset of the information you get from npm view.


        33 Installing a Specific Version of a Package ---------------------------------------------

        To install a specific version of a package us the @ npm i mongoose@2.4.2

        34 Update Local Packages ------------------------ To show dependencies that are out of date: npm outdated

        To update minor and patch releases: npm update

        To update dependencies to the very latest versions we need to install: npm i -g npm-check-updates

        Now to update the package.json file ncu -u

        This just updates package.json. Then to install the dependency run: npm i

        35 DevDependencies ------------------ So far all the dependencies we have installed are application dependencies
        such as mongoose and underscore - our application needs these dependencies in order to function properly.

        Sometimes we use dependencies that are only required during development. For example: - tools for running unit
        tests - tools for performing static analysis on our code - tools for bundling Javascript

        These dependencies should not go into the production environment where we deploy our application.

        To install dev dependencies npm i jshint --save-dev

        You should see jshint has been added to a devDependencies section in package.json.

        36 Uninstalling a Package ------------------------- To uninstall a package: npm un mongoose

        37 Working with Global Packages ------------------------------- To install a global package: npm i -g npm

        All the commands listed so far work with the global flag: npm -g outdated

        To uninstall a global package: npm un -g npm

        38 Publishing a Package ----------------------- To publish a npm package: create a new directory (e.g. lion-lib)
        and add a package.json. Add a new file: index.js with required code: module.exports.add = function(a, b) {
        return a + b }

        If you don't have an account on npmjs.com you will need to run npm add user or if you have already got an
        account: npm login

        When logged in issue the following command: npm publish

        You will need to update the package name in package.json.

        We should now be able to use this package in another node application:

        var lion = require('lion-lib');

        39 Updating a Published Package ------------------------------- If we run: npm publish fom the lion-lib folder
        we receive an error:

        "You cannot publish over the previously published version 1.0.0: lion-lib"

        Depending on the kind of change we have made the we need to update the version number. In this instance we will
        just update the minor version: npm version minor then publish to npm: npm publish

        40 Recap -------- NPM So, in this section, you learned that: - Every Node application has a package.json file
        that includes metadata about the application. This includes the name of the application, its version,
        dependencies, etc. - We use NPM to download and install 3rd-party packages from NPM registry: - All the
        installed packages and their dependencies are stored under node_modules folders. This folder should be excluded
        from the source control. - Node packages follow semantic versioning: major.minor.patch - Useful NPM commands
        are: // Install a package npm i
        <packageName>
          // Install a specific version of a package npm i
          <packageName>@
            <version>
              // Install a package as a development dependency npm i
              <packageName> —save-dev // Uninstall a package npm un
                <packageName>
                  // List installed packages npm list —depth=0 // View outdated packages npm outdated // Update packages
                  npm update - To install/uninstall packages globally, use -g flag


                  Building RESTful API's Using Express ==================================== 41 Introduction
                  --------------- Earlier in the course we covered the HTTP module. We used this to create a web server
                  that listens on port 3000 and responds to requests made on the /api/courses endpoint. While this
                  approach is fine, it is not suitable for building a large complex application because you will more
                  than likely end up adding a lot of endpoints. So in this section we will look at express which is a
                  fast and lightweight framework for building web applications.

                  42 RESTful Services ------------------- Most applications follow the Client/Server architecture
                  Communication between the Client and Server occurs over HTTP We expose services on the Server that are
                  available to the client via HTTP requests This process uses REST (REpresentational State Transfer) -
                  REST is basically a principle for building these HTTP services We use simple HTTP protocol principles
                  to provide support to Create, Read, Update and Delete data - referred to as CRUD

                  We expose endpoints like this: http://vidly.com/api/customers

                  The client can send http requests to this endpoint to talk to our service.

                  The type of the http request determines the operation. Every http request has a verb or method that
                  determines it's intention: GET Get /api/customers, /api/customers/1 POST Create /api/customers/
                  Include customer object in the body of the request PUT Update /api/customers/1 Include customer object
                  in the body of the request DELETE Delete /api/customers/1

                  43 Introducing Express ---------------------- As we define more routes for our application it will
                  become necessary to use a framework to give our application a proper structure. This means we can
                  easily add more routes whilst keeping our application code maintainable.

                  express is one of the most popular frameworks for this purpose. It can be installed using npm: npm i
                  express

                  44 Building Your First Web Server --------------------------------- We will add a new file called
                  index.js (it could also be called app.js). First we load the express module: const express =
                  require('express'); const app = express();

                  The app object exposes several useful methods: app.get(); app.post(); app.put(); app.delete();

                  All these methods correspond to the http verbs discussed earlier. So we could do the following:

                  app.get('/', (req, res) => { res.send('Hello World'); });

                  app.listen(3000, () => console.log('Listening on port 3000...'));

                  In the terminal issue the following command: node index.js

                  Now in chrome browse to localhost:3000 and you should see the "Hello World" message.

                  Now let's define another route:

                  app.get('/api/courses', (req, res) => { res.send([1, 2, 3]); });

                  Now we have to restart the process in the terminal using Ctrl+C

                  So in this implementation we don't have the if blocks we used earlier in the HTTP module code. Instead
                  we define new routes by calling app.get. As our application grows we are free to move routes to other
                  files (e.g. courses.js for routes related to courses).

                  45 Nodemon ---------- Up to this point, each time the code is changed we have been required to restart
                  the node process in the terminal. We can use the nodemon node package to watch for changes and restart
                  our process automatically:

                  npm i -g nodemon

                  now instead of using node to run our application we use nodemon:

                  nodemon index.js

                  If you make a change to one of the routes and refresh the browser you should see the change takes
                  effect immediately - there is no need to restart the process manually. nodemon also writes "[nodemon]
                  restarting due to changes....." to the terminal

                  46 Environment Variables ------------------------ One thing we could improve on in the code is
                  switching the hard coded port value of 3000: app.listen(3000, () => console.log('Listening on port
                  3000...'));

                  For an environment variable. 3000 is an arbitrary number. While this should work on your development
                  machine it is unlikely to work in a development environment. In a hosting environment the port will be
                  dynamically assigned.

                  We can read the value of environment variable using the process object:

                  const port = process.env.PORT || 3000; app.listen(port, () => console.log(`Listening on port
                  ${port}...`));

                  To set an environment variable on Mac use:

                  export PORT=5000

                  On Windows use:

                  setx PORT "5000"

                  You should receive the following message:

                  SUCCESS: Specified value was saved.

                  You will also need to restart Webstorm to pickup the changes.


                  Now if we run the application using nodemon:

                  nodemon index.js

                  You should see something similar to this:

                  [nodemon] 1.17.1 [nodemon] to restart at any time, enter `rs` [nodemon] watching: *.* [nodemon]
                  starting `node index.js` Listening on port 5000...

                  47 Route Parameters ------------------- Currently we have a route for getting the list of courses:

                  app.get('/api/courses', (req, res) => { res.send([1, 2, 3]); });

                  In this section we will demonstrate how to create a route that gets a single course. In the discussion
                  earlier on RESTful services we said that in order to retrieve a single course we include the id of the
                  course in the url:

                  // /api/courses/1

                  To implement a route like this use the following:

                  app.get('/api/courses/:id', (req, res) => { res.send(req.params.id); });

                  Now in chrome if you browse to localhost:3000/api/courses/1 you should see the course id of "1"
                  displayed.

                  It is possible to have multiple parameters in a route. Imagine a route for managing blog posts:

                  app.get('/api/posts/:year/:month', (req, res) => { res.send(req.params); });

                  If you browse to localhost:5000/api/posts/2018/1 you should see the following:

                  // 20181004180450 // http://localhost:5000/api/posts/2018/1

                  { "year": "2018", "month": "1" }

                  This is the req.params object. With express we can retrieve querystring parameters as well as route
                  parameters. These are parameters that appear in the Url after a question mark. For example we can get
                  all the posts for January 2018 and sort by name using the following:

                  http://localhost:5000/api/posts/2018/1?sortBy=name

                  By convention, route parameters are used for mandatory values whereas query parameters are used for
                  optional values. We can read a url parameter like so:

                  req.query;

                  Query parameters are stored in an object with key value pairs.

                  48 Handling HTTP GET Requests ----------------------------- Now let's implement a new endpoint to get
                  a single course from the server. Define an array called courses:

                  const courses = [ { id: 1, name: 'course1' }, { id: 2, name: 'course2' }, { id: 3, name: 'course3' },
                  ];

                  So now we have two endpoints - one to get all the courses and the other to get a single course. In the
                  endpoint to get all the courses we will return our courses array:

                  app.get('/api/courses', (req, res) => { res.send(courses); })

                  In the second one we will write some logic to look for the course with the given id:

                  const course = courses.find(c => c.id === parseInt(req.params.id));

                  find is a method on every array in Javascript. As an argument we pass the method a function using the
                  arrow function syntax. We write some logic that returns a boolean value that determines if this course
                  is the one we are looking for or not. We store the result in a const called course. You might ask why
                  I didn't use var here. var is perfectly fine but going forward best practice states to either use the
                  let or const keywords. We use let to define a variable that we can reset later. We use const when
                  defining a constant. This prevents the variable from being overwritten elsewhere in the code.

                  If we don't find a course with the given id the convention (with RESTful apis) is to return a status
                  code of 404:

                  if (!course) res.status(404).send('The course with the given id was not found');

                  In the code above we also send the optional message. If we do find a course with that id then we will
                  just return it to the client: res.send(course);

                  If we browse to a course that does exist:

                  localhost:5000/api/courses/10

                  then just that course is returned. If we browse to a course that doesn't exist:

                  localhost:5000/api/courses/10

                  We will receive the message saying the course was not found. If you open chrome developer tools and
                  click on the Network tab refresh the page and you will see the status 404.

                  49 Handling HTTP POST Requests ------------------------------ So far the routes we have created all
                  response to HTTP GET requests. In this lecture we will learn how to respond to HTTP POST requests. We
                  use an HTTP POST request to create a new course:

                  app.post('/api/courses', (req, res) => {

                  });

                  Similar to the get method we need to specify a path: /api/courses because we are going to POST to the
                  collection of courses. That's why we use the plural name. Next we add our route handler using the
                  arrow function.

                  In this route handler we need to read the course object which should be in the body of the request and
                  use it's properties to create a new course object and then add that object to our courses array:

                  const course = { id: courses.length + 1, name: req.body.name };

                  Again, we use a const here because we are not going to reset this course object later. In this demo,
                  to keep things simple, we are not working with a database so we just add one to the length of our
                  courses array. Next we need to read the name property from the body of the request. We assume that in
                  the request body we have an object and that object has a name property. In order for this line to work
                  we need to enable parsing of JSON objects in the body of the request because by default this feature
                  is not enabled in express. So at the top of the file after we get the app object:

                  app.use(express.json());

                  This may look a bit strange at this point in time but we will cover this in detail later in the
                  course. Basically, here, we are adding a piece of middleware. When we call express.json() this method
                  returns a piece of middleware and then we call app.use to use that middleware in the request
                  processing pipeline.

                  Back in the route handler we push the course into our courses array:

                  courses.push(course);

                  Finally, by convention, when we post an object to the server and the server creates a new object or
                  resource we should return that object in the body of the response:

                  res.send(course);

                  We do this because we are assigning this id on the server and we need to return this course object to
                  the client because chances are the client needs to know the id of this new object.

                  50 - Calling Endpoints Using Postman ------------------------------------ To call HTTP services we use
                  an application called Postman.

                  CREATE SEPARATE DOCUMENTATION FOR POSTMAN

                  51 - Input Validation --------------------- In this lecture we will look at input validation. Best
                  practice dictates that we should never trust information sent by the client. It should always be
                  validated.

                  In this example:

                  app.post('/api/courses', (req, res) => { const course = { id: courses.length + 1, name: req.body.name
                  }; courses.push(course); res.send(course); });

                  We are dealing with a simple object with only one property: name we can write some validation logic
                  like this:

                  if(!req.body.name || req.body.name.length < 3) { // 400 Bad Request res.status(400).send('Name is
                  required and should be minimum 3 characters'); return; }

                  So if the name property doesn't exist or is less than 3 characters in length we set the response
                  status to 400 Bad Request. We then send a rather generic error message along with setting the status.
                  Finally we return to prevent the rest of the function from being executed.

                  In a real world application we are likely to be working with more complex objects than the one we are
                  using here. We don't want to add too many validation rules in if statements at the top of the route
                  handler. We will look at a node package that makes it easier to validate input: joi.

                  npm i joi@13.1.0

                  Now, back in the code, at the top of the file we need to load the module:

                  const Joi = require('joi');

                  We use a capital for the Joi variable because this module returns a class. As we said before we use
                  Pascal naming conventions when we name our classes - so the first letter of every word should be
                  uppercase.

                  Also as a best practice put all your require calls at the top of the file. This way you can easily see
                  what are the dependencies of this module. So our current module is dependent on joi and express.

                  Go back the route handler. With joi we need to define a schema. A schema defines the shape of our
                  objects - what properties do we have in our object, what is the type of each property in the object,
                  do we have an email, do we have a string, what are the minimum or maximum number of characters, do we
                  have a number, what range should that number be in.

                  First we define a schema:

                  const schema = { name: Joi.string().min(3).required() };

                  So we set schema to an object with a name property. We tell joi to expect a string with a minimum of
                  three characters that is required.

                  Next we call the validate method passing in the req.body and schema:

                  const result = Joi.validate(req.body, schema); console.log(result);

                  We store the object returned by the validate method in a const called result. For this demo I'm going
                  to log this result on the console.

                  Now if we use Postman to create another course object (POST to http://localhost:3000/api/courses with
                  the course specified in the body and the object sent to JSON(application/json)) in the terminal we
                  should see a result object with two properties - error and value. Only one of these can have a value.
                  In this case because we sent a valid course object we have this course object here as the value of the
                  value property and you can see error is null:

                  { error: null, value: { name: 'new course' }, then: [Function: then], catch: [Function: catch] }

                  If we send an invalid object, for example by removing the name property, then value will be null and
                  error will be set:

                  { ValidationError: child "name" fails because ["name" is required]

                  Back in the route handler instead of using the manual validation logic we can check the value of the
                  result.error property:

                  if(result.error) { res.status(400).send(result.error); return; }

                  We also don't need the console.log statement any longer so we can remove that.

                  If we use Postman to submit another invalid request and look at the response we get an object with
                  properties such as isJoi, name, details etc. details is an array of error messages. The first one
                  should be "name is required". This object is too complex to send to the client. If you want to
                  simplify this go back to the code and instead of returning the whole result.error object you can drill
                  down to the detail arrays first elements message property:

                  result.error.details[0].message

                  52 - Handling HTTP PUT Requests ------------------------------- Now let's see how we can update a
                  course. Add a new route handler with the PUT method:

                  app.put('/api/courses/:id', (req, res) => { // Look up the course // If not existing, return 404 const
                  course = courses.find(c => c.id === parseInt(req.params.id)); if (!course) res.status(404).send('The
                  course with the given id was not found');

                  // Validate // If invalid, return 400 - Bad request const schema = { name:
                  Joi.string().min(3).required() };

                  const result = Joi.validate(req.body, schema); if(result.error) {
                  res.status(400).send(result.error.details[0].message); return; }

                  // Update course course.name = req.body.name;

                  // Return the updated course res.send(course);

                  });


                  The route handler contains a lot of logic, a good proportion of which we have already covered and can
                  pull in from different methods. The code to look up the course and return a 404 if it doesn't exist
                  can be found in the route handler to get a single course We can get the validation from the post
                  endpoint. The problem with this approach is that , although in this example we are dealing with a
                  simple schema, real world applications may have much more complex schemas. This would mean our
                  validation code was duplicated in two route handlers. We'll resolve this shortly. Next we update the
                  course.name property. If we had more properties we would update them here also. Finally we need to
                  return the updated course to the client.

                  Now we will extract the validation logic into it's own function which can be used in both route
                  handlers:

                  function validateCourse(course) { const schema = { name: Joi.string().min(3).required() };

                  return Joi.validate(course, schema); };

                  In the code above, instead of validating the req.body we validate the course object. Also we return
                  the result to the caller - there is no need to define a const.

                  New we can reuse this in our PUT endpoint:

                  const result = validateCourse(req.body);

                  This code can be made a bit cleaner by using the object destructuring features of modern Javascript.
                  Currently we get the result object and then we are accessing result.error in two different places.
                  Since all we are interested in is the error property we can get this using object destructuring. With
                  object destructuring when declaring a variable or object we add curly braces and inside we add the
                  property of the target object (in this instance error):

                  const { error } = validateCourse(req.body); if(error) {
                  res.status(400).send(error.details[0].message); return; }

                  With the above code we don't need to repeat result.error in two seperate places we can simply use
                  error.

                  We now need to add this new way of validating a course to the HTTP POST request.

                  Back in POSTMAN test the PUT and POST endpoints with valid and invalid values in the data.

                  Handling HTTP Delete Requests ----------------------------- Out of all the CRUD operations we have now
                  implemented Read, Update and Delete. In this lecture we will look at how to respond to HTTP DELETE
                  requests:

                  app.delete('/api/courses/:id', (req, res) => { // Look up the course // If not existing, return 404
                  const course = courses.find(c => c.id === parseInt(req.params.id)); if (!course)
                  res.status(404).send('The course with the given id was not found');

                  // Delete const index = courses.indexOf(course); courses.splice(index, 1);

                  // Return the same course res.send(course);

                  });

                  Test this in Postman using valid and invalid course ids.

                  There are currently three bugs in this code. Currently in the PUT endpoint if we don't have a course
                  with a given id we return a 404 to the client. However at this point we should exit the route handler
                  otherwise the rest of the code will be executed:

                  if (!course) return res.status(404).send('The course with the given id was not found');

                  To make this code cleaner we can use the same technique to deal with an invalid request:

                  if(error) return res.status(400).send(error.details[0].message);

                  The same issue exists in the DELETE route handler so let's fix that:

                  if (!course) return res.status(404).send('The course with the given id was not found');

                  and also when GETting a single course:

                  if (!course) return res.status(404).send('The course with the given id was not found');

                  We can also clean up the code in the POST route handler:

                  if(error) return res.status(400).send(error.details[0].message);

                  54 - Project - Build the Genres API ----------------------------------- From this lecture we are going
                  to start building the backend services for our vidly application. vidly is an imaginary service for
                  renting out movies. Throughout the course we will build the backend of vidly bit by bit. Your first
                  task is to create a service for managing the list of genres. Each movie has a genre like action,
                  horror etc. We should have an endpoint for getting all the genres. We should also have endpoints for
                  creating, updating and deleting genres.

                  55 - Recap ---------- Building RESTful APIs with Express So, in this section, you learned that: - REST
                  defines a set of conventions for creating HTTP services: - POST: to create a resource - PUT: to update
                  it - GET: to read it - DELETE: to delete it - Express is a simple, minimalistic and lightweight
                  framework for building web servers. // Build a web server const express = require(‘express’); const
                  app = express(); // Creating a course app.post(‘/api/courses’, (req, res) => { // Create the course
                  and return the course object res.send(course); }); // Getting all the courses app.get(‘/api/courses’,
                  (req, res) => { // To read query string parameters (?sortBy=name) const sortBy = req.query.sortBy; //
                  Return the courses res.send(courses); }); // Getting a single course app.get(‘/api/courses/:id’, (req,
                  res) => { const courseId = req.params.id;

                  // Lookup the course // If not found, return 404 res.status(404).send(‘Course not found.’); // Else,
                  return the course object res.send(course); }); // Updating a course app.put(‘/api/courses/:id’, (req,
                  res) => { // If course not found, return 404, otherwise update it // and return the updated object.
                  }); // Deleting a course app.delete(‘/api/courses/:id’, (req, res) => { // If course not found, return
                  404, otherwise delete it // and return the deleted object. }); // Listen on port 3000 app.listen(3000,
                  () => console.log(‘Listening…’)); - We use Nodemon to watch for changes in files and automatically
                  restart the node process. - We can use environment variables to store various settings for an
                  application. To read an environment variable, we use process.env. // Reading the port from an
                  environment variable const port = process.env.PORT || 3000; app.listen(port); - You should never trust
                  data sent by the client. Always validate! Use Joi package to perform input validation.

                  Express Advanced Topics ======================= 56 - Introduction ----------------- In the last
                  section we learnt how to build RESTful services using express. In this section we are going to look at
                  more advanced express topics including: - middleware - configuration - debugging - templating engines

                  57 - Middleware --------------- One of the core concepts in express that we need to learn is the
                  concept of middleware or middleware functions. A middleware function is basically a function that
                  takes a request object and either returns a response to the client or passes control to another
                  middleware function. You have already seen two examples of middleware functions - one is the route
                  handler function:

                  app.get('/api/genres', (req, res) => { res.send(genres); });

                  In express every route handler function we have is technically a middleware function because it takes
                  a request object and returns a response to the client. So it terminates the request response cycle.

                  The other example is:

                  app.use(express.json());

                  So when we call the express.json() method it returns a middleware function. The job of this middleware
                  function is to read the request and if there is an object in the body of the request it will pass the
                  body of the request into a JSON object then it will set the req.body property. So essentially at
                  runtime when we receive a request on the server the request goes through the Request Processing
                  Pipeline. In this pipeline we have one or more middleware functions. Each middleware function either
                  terminates the request response cycle by returning a response object or it can pass control to another
                  middleware function.

                  Our current implementation has two middleware functions. The first one is the middleware function that
                  parses the request body into a Json object but in this case it doesn't terminate the request/response
                  lifecycle so it passes control to the second middleware function which is the route handler.

                  In our route handler we have the request object with the body property populated. Here we can perform
                  some operation and then terminate the request/response cycle by returning a response to the client.

                  Express includes a few built-in middleware functions but we can also create custom middleware
                  functions that we can put at the front of our request processing pipeline. Every request that we get
                  on the server will then go through our middleware function. With this custom middleware function we
                  can perform cross cutting concerns. For example we can do logging, authentication, authourization and
                  so on.

                  An express application is essentially nothing but a bunch of middleware functions.

                  58 - Creating Custom Middleware ------------------------------- Now let me show you how to create a
                  custom middleware function:

                  app.use(function (req, res, next) { console.log('Logging...'); next(); });

                  So we call app.use and pass a function that takes req, res and next (which is reference to the next
                  middleware function in the pipeline). In the function we just do a simple console.log. Then we call
                  next() to pass control to the next middleware function in the pipeline. If we don't call next() then
                  our request will end up hanging because we are not terminating our request/response lifecycle.

                  If we comment out the line that calls next(); then in Postman perform a GET request. You will see that
                  you don't receive a response. If you also check the terminal you can see our Logging message. This
                  indicates our middelware function was called successfully but because we are not passing control to
                  another middelware function to terminate the request response cycle our request ends up hanging.

                  Uncomment the call to next();

                  We can also create another middelware function for performing authentication:

                  app.use(function (req, res, next) { console.log('Authenticating...'); next(); });

                  Back in Postman send another request and, if you check the terminal, you should see two messages:

                  Logging... Authenticating...

                  The thing to take away here is that our middleware functions are called in sequence. First our Logging
                  middelware function is called, then the middelware function for authenticating the user, and then
                  finally the route handler which is another middelware function.

                  In terms of clean coding when you want to create custom middleware function you don't want to create
                  all that code inside index.js. Each middleware function should be in a separate file or module.

                  Create a new file called logger.js and move the Logging middelware function out of index.js and into
                  logger.js:

                  function log(req, res, next) { console.log('Logging...'); next(); }

                  module.exports = log;

                  Call the function log and export it. In index.js load the new logger module at the top of the file:

                  const logger = require('./logger.js');

                  then install it by calling app.use:

                  app.use(logger);

                  We pass the logger function. Now we can understand exactly what this line means:

                  app.use(express.json());

                  When we call express.json() it returns a middleware function that has three parameters: req, res, and
                  next. That middleware function parses the req body and if there is a Json object it will set req.body
                  and then it will pass control to the next middleware function.

                  59 - Built-in Middleware ------------------------ In the last lecture you learned how to build custom
                  middleware. We discussed before that express has some built-in middleware functions. One of them is
                  the json middleware that parses the body of the request and if there is a json object it will populate
                  req.body.

                  Another similar middelware function is urlencoded:

                  app.use(express.urlencoded());

                  We receive a middleware function as a result from this method call. This middleware function parses
                  incoming requests with url encoded payloads. So a request with a body like this:

                  key=value&key=vale

                  This is more of a traditional approach - it is not used all that often these days. Basically if you
                  have an http form with input fields and post that form to the server then the body of the request will
                  look like the above.

                  So the urlencoded middleware function parses this body and populates req.body like a Json object.

                  To demonstrate go back to Postman and perform a POST request to:

                  http://localhost:5000/api/courses

                  Previously we passed a Json object in the body by selecting raw and then JSON (application/json).
                  However in this demo we are going to use x-www-form-urlencoded which allows us to pass key value pairs
                  in the body of the request and they will be concatenated when this request is sent to the server. We
                  add name as the key and mycourse as the value. If we send this request you should see that we have
                  created a new course on the server. So our middleware function was able to read our request with
                  urlencoded payload.

                  If you check the terminal you will see a message:

                  body-parser deprecated undefined exteded: provide extended option

                  This is telling us that we should pass an object with extended set to true:

                  app.use(express.urlencoded( { extended: true }));

                  This allows us to pass arrays and complex objects using the urlencoded format.

                  Finally the last built-in middleware function that we have in express is static which we use to serve
                  static files:

                  app.use(express.static('public'));

                  We pass the name of the folder to the static method (public). We put all our static assets like css,
                  images and so on inside this folder. For this demo we create a public folder with a readme.txt file
                  inside it.

                  If we browse to http://localhost:5000/readme.txt the browser should serve the contents of the text
                  file. Note that we do not have public in the url. Our static content is served from the root of the
                  site.

                  60 - Third-party Middleware --------------------------- In this lecture we will look at some third
                  party middleware available in express. If you browse to expressjs.com and click on Resources you
                  should see a link to Middleware. These are all the third-party middelware that you can use in your
                  applications.

                  helmet helps you secure your application by setting various http headers.

                  So back in the terminal install helmet:

                  npm i helmet

                  Then in index.js at the top of the file we load the helmet module using the require function:

                  const helmet = require('helmet');

                  Which returns a function which we can call:

                  app.use(helmet());

                  which, in turn, returns a middleware function which we can then use.

                  The other third-party middleware which may be useful is morgan which can be used to log http requests:

                  npm i morgan

                  We load morgan using the require function:

                  const morgan = require('morgan');

                  then we use it like this:

                  app.use(morgan('tiny'));

                  morgan accepts different formats. Above we use 'tiny'

                  With morgan in place everytime we send a request to the server it will be logged. So if you send a
                  simple GET request to http://localhost:5000/api/courses and then check the terminal you should see the
                  following:

                  GET /api/courses 200 79 - 7.491 ms

                  This is the tiny format. The above information indicates we sent an http GET request to the
                  /api/courses endpoint. The result was a status 200 which means successful. The request took 7.491ms to
                  respond.

                  For more details you can set a different format. By default morgan logs to the console but you can
                  also configure it to write to a log file.

                  61 - Environments ----------------- In a more complex enterprise application you need to know what
                  environment your code is running on - development or production. You may want to enable or disable
                  certain features based on the current environment. For example, perhaps you only want to enable
                  logging of http requests when in a development environment. Let's look at how to do this.

                  Earlier you learned about the process object - a global object in node which gives us access to the
                  current process. The process object has a property called env which gives us access to the system's
                  environment variables. We have a standard environment variable called NODE_ENV which returns the
                  environment for this node application. If it's not set we get undefined. We can set this to
                  development, testing, staging, production. To demonstrate let's log this on the console:

                  console.log(`NODE_ENV: ${process.env.NODE_ENV}`);

                  Another way to get the current environment is by using the app object.:

                  console.log(`app: ${app.get('env')}`);

                  The difference here is that if the environment variable is not set app.get('env') will return
                  development not undefined.

                  The approach you choose is down to personal preference.

                  In this demo we want to enable logging of http requests only on a development machine so we can write
                  code like this:

                  if (app.get('env') == 'development') { app.use(morgan('tiny')); console.log('Morgan enabled....') }

                  If you run the application now and check the terminal you should see:

                  Morgan enabled.....

                  If you set the environment variable to production and re-run you will see that morgan is not enabled
                  (the console message wont appear).

                  62 - Configuration ------------------ One topic which goes hand in hand with environments (which we
                  covered in the previous lecture) is the topic of storing configuration settings for the application
                  and overriding those settings in each environment. For example, in your development environment you're
                  going to use a different database and mail server. So in this lecture we will look at how to store
                  configuration settings for our application and then how to override them in each environment.

                  The most popular package for managing configuration settings is rc:

                  npmjs.com/package/rc

                  However this package has several issues which is why we will look at:

                  npmjs.com/package/config

                  We install config like this:

                  npm i config

                  Now in the project create folder called config and add a default configuration file called
                  default.json with the following json object:

                  { "name": "My Express App" }

                  Now create a new file called development.json which will contain configuration settings specific to
                  the development environment. As part of this we are able to override the settings that we have defined
                  in default.json and add additional settings:

                  { "name": "My Express App - Development", "mail": { "host": "dev-mail-server" } }

                  As you can see from the above code we can add configuration settings that are complex objects - "mail"
                  above.

                  Create another file called production.json and copy the settings from development.json to this file.
                  Change the name and mail host settings:

                  { "name": "My Express App - Production", "mail": { "host": "prod-mail-server" } }

                  Now back in index.js load the config module:

                  const config = require('config');

                  and add some code to write the configuration settings to the console:

                  // Configuration console.log('Application Name:' + config.get('name')); console.log('Mail Server:' +
                  config.get('mail.host'));

                  Now try switching NODE_ENV between development and production and you should see those settings
                  written to the console changing.

                  It is important that you don't store applicationsecrets in these configuration files. You should use
                  environment variables for this instead. For example, let's assume that we want to store the password
                  for our mail server. In the terminal set an environment variable to store the mail server password:

                  setx vidly_mailpassword 1234

                  Add another file called custom-environment-variables.json to the configuration file. We use this file
                  to define the mapping of configuration settings to environment variables:

                  { "mail": { "password": "vidly_mailpassword" } }

                  Back in index.js let's display the password of the mail server:

                  console.log('Mail Password:' + config.get('mail.password'));

                  The config object will look at various sources to find a value for the configuration setting. The
                  source could be a configuration or json file an environment variable or even a command line argument
                  (check the documentation)

                  If you run the application now you should see the mail server password in the console:

                  Mail Password:1234

                  63 - Debugging -------------- Earlier in the section we wrote code to check if we were in the
                  development environment. If yes then we enabled morgan:

                  if (app.get('env') == 'development') { app.use(morgan('tiny')); console.log('Morgan enabled....') }

                  In the above code we use the console.log command which is a Javascript programmers best friend. The
                  problem with this approach, however, is that when you've finished debugging you comment out or delete
                  the console.log lines. If you then need them in the future you need to rewrite them or uncomment them.
                  This approach can become very tedious.

                  A better way to log messages for the purposes of debugging is to use the debug package in node. With
                  debug we can replace all the console.log statements with a call to a debug function. We can then use
                  an environment variable to enable/disable debuggging. This approach also let's us control the level of
                  information we want to see. Perhaps, you are working on a database problem so you only want to view
                  debugging information related to the database.

                  In the terminal install debug:

                  npm i debug

                  In index.js load the debug module:

                  const startupDebugger = require('debug')('app:startup');

                  The require function above returns a function which we call passing in an argument which is an
                  arbitrary namespace that we define for debugging. For example, we can define the namespace
                  app:startup. Now when we call this function with the app:startup argument we get a function for
                  writing debugging messages in that namespace. We call that function startupDebugger.

                  Potentially we can have another debugger for debugging database related messages. So, once again, we
                  load the debug module, we get a function, we call that function, passing in a namespace app:db. This
                  will return a debugging function which we store in dbDebugger:

                  const dbDebugger = require('debug')('app:db');

                  Now we can replace our console.log line with a call to startupDebugger function:

                  if (app.get('env') == 'development') { app.use(morgan('tiny')); startupDebugger('Morgan enabled....')
                  }

                  Potentially, somewhere in the application, we may perform some database work. There you might need to
                  write some debugging information. For this we can use the dbDebugger function:

                  // Db work... dbDebugger('Connected to the database....');

                  Now we go back to the terminal an use an environment variable to determine what kind of debugging
                  information we want to see in the console:

                  setx DEBUG app:startup

                  Now, if you run the application, we will see only the debugging messages that are part of this
                  namespace app:startup:

                  app:startup Morgan enabled.... +0ms

                  Next time you run, if you don't want to see any debugging information just reset the environment
                  variable:

                  setx DEBUG ""

                  We may want to see debugging messages from multiple namespaces. So we can set our environment variable
                  like so:

                  setx DEBUG app:startup,app:db

                  which will result in the following being written to the console:

                  app:startup Morgan enabled.... +0ms app:db Connected to the database.... +0ms

                  If you want to see all the debugging message for the app namespace we can use a wildcard:

                  setx DEBUG app:*

                  The beautiful thing about this debugging module is that it colour codes the namespace to allow us to
                  easily distinguish between various debugging messages.

                  There is a faster way to set the level of debugging we want to see. We don't have to set the
                  environment variable explicitly. We can set the environment variable at the time of running our
                  application:

                  DEBUG=app:db nodemon index.js

                  The above doesn't work on my development environment!

                  Finally, in this demo we created two debugging functions: startupDebugger and dbDebugger. In a real
                  world scenario you may not need multiple debugger functions in the same file or module. In that case
                  you can simplify the code by changing the name of the debugger function to just debug:

                  debug('Morgan enabled....');

                  64 - Templating Engines ----------------------- In all the endpoints we have implemented so far we
                  return JSON objects in the response. Sometimes however you need to return HTML to the client. That's
                  where you would use a templating engine. There are various templating engines available for express
                  applications. The most popular are: - Pug (previously known as Jade) - Mustache - EJS

                  Each templating engine has a different syntax for generating dynamic Html and returning it to the
                  client. We will use Pug to generate dynamic HTML and return it to the client. First install Pug:

                  npm i pug

                  Back in index.js set the view engine for the application:

                  app.set('view engine', 'pug');

                  When we set this express will internally load this module so we don't have to require it.

                  There is another optional setting for overriding the path for templates:

                  app.set('views', './myViews');

                  The default value is ./views.

                  Add a new folder called views with a file called index.pug. With pug we can define our template using
                  a syntax like this:

                  html head title=title body h1= message

                  We specify html elements then with the title element we set the value dynamically to a variable that
                  will be set at runtime. We do the same with the h1 message. Pug has a cleaner syntax than regular
                  Html. Of course some people love it, some people hate it. Let's see how we can convert this to regular
                  Html and return it to the client.

                  Back in our index module remember earlier when we defined a route for the root of the application:

                  app.get('/', (req, res) => { res.send('Hello World'); });

                  Here we send a simple message to the client. We want to replace this with Html markup using the render
                  function and return it to the client:

                  res.render('index', { title: 'My Express App', message: 'Hello' });

                  As the first argument we specify the name of our view: index. As the second argument we pass an object
                  which includes all the values for the parameters that we have defined in our template - title and
                  message.

                  Start the application and browse to http://localhost:3000. We should see the Html markup we generated
                  using the pug template with the title and h1 generated dynamically:

                  <html>
                  <head><title>My Express App</title></head>
                  <body><h1>Hello</h1></body>
                  </html>

                  65 - Database Integration ------------------------- A separate section later in the course will look
                  in depth into working with MongoDb but in this lecture we will look at what our various database
                  integration options are when using Node and Express.

                  expressjs.com/en/guide/database-integration.html provides a list of database drivers that are
                  available for you to use.

                  66 - Authentication ------------------- Authentication is outside the scope of express because express
                  is a minimal lightweight framework which doesn't have an opinion on authentication.

                  67 - Structuring Express Applications ------------------------------------- If you look back at the
                  index.js file we have created over the last few sections you will see we have ended up with quite a
                  large file.

                  In a real world application you don't want to write all that code inside index.js so we will look at
                  how to properly structure the application.

                  The first thing to do is to take out all of the code for the courses api and put it into a separate
                  file . In other words, for every api endpoint we want to have a separate file/module. So, for example,
                  all the routes for dealing with courses should be in a file called courses.js and all the routes for
                  dealing with authors should be in authors.js.

                  Create a new directory called routes and a new file called courses.js

                  Now in index.js select all the code for working with courses and paste it into courses.js which should
                  leave you with approximately 40 lines of code in index.js.

                  Now let's finish refactoring courses.js. First we need to load express:

                  const express = require('express');

                  In index.js we called express as a function and we got an app object. This approach does not work when
                  you separate the routes in a separate module. Here we need to use a router:

                  const router = express.Router();

                  You will need to also refactor the rest of the courses.js file to use router object instead of the app
                  object.

                  Finally at the bottom of courses.js we export the router:

                  module.exports = router;

                  In summary, we get the router at the top, add routes to it and finally export the router at the end of
                  the module.

                  Next we need to load the course module inside the index module. So back in index.js:

                  const courses = require('./routes/courses');

                  Finally, once we load the module we need to call

                  app.use('/api/courses', courses);

                  We supply two arguments - the first is a path, the second is the courses router object that we
                  imported. Basically we are telling express that for any routes starting /api/courses use the courses
                  router.

                  With the above complete we can go back to the courses module and make our routes a little bit shorter
                  by removing all references to /api/courses. So instead of:

                  router.get('/api/courses', (req, res) => { res.send(courses); });

                  we can use:

                  router.get('/', (req, res) => { res.send(courses); });

                  Next move the courses array from index.js to courses.js:

                  const courses = [ { id: 1, name: 'course1' }, { id: 2, name: 'course2' }, { id: 3, name: 'course3' },
                  ];

                  Next we can move the home route from index.js to a new file in the routes folder called home.js:

                  const express = require('express'); const router = express.Router();

                  router.get('/', (req, res) => { res.render('index', { title: 'My Express App', message: 'Hello' });
                  });

                  module.exports = router;

                  In index.js load the module:

                  const home = require('./routes/home');

                  Finally in the middleware calls we say that any path that starts with / should use the home router:

                  app.use('/', home);

                  Now index.js just contains the startup code for our application.

                  One last thing. Earlier we created the logger middleware and put it into a separate module. We
                  exported the logger function at the end of the module. Now, in terms of structuring your application,
                  it is possible you might have multiple middleware functions. It is better to keep these all in a
                  folder called middleware so create that folder and move logger.js inside it.

                  In index.js, where we load the middleware don't forget to change the path:

                  const logger = require('./middleware/logger.js');

                  68 - Project - Restructure the App ---------------------------------- Currently in the vidly
                  application, as it stands, all of the routes for dealing with genres have been defined in index.js. As
                  an exercise, you can move all the routes to a new routes folder.

                  Watch the video for a description of how to refactor the genres routes into their own module (starting
                  at approx 0:54).

                  69 - Recap ---------- Express: Advanced Topics So, in this section, you learned that: - A middleware
                  function is a function that takes a request object and either terminates the request/response cycle or
                  passes control to another middleware function. - Express has a few built-in middleware functions: -
                  json(): to parse the body of requests with a JSON payload - urlencoded(): to parse the body of
                  requests with URL-encoded payload - static(): to serve static files - You can create custom middleware
                  for cross-cutting concerns, such as logging, authentication, etc. // Custom middleware (applied on all
                  routes) app.use(function(req, res, next)) { // … next(); } // Custom middleware (applied on routes
                  starting with /api/admin) app.use(‘/api/admin’, function(req, res, next)) { // … next(); } - We can
                  detect the environment in which our Node application is running (development, production, etc) using
                  process.env.NODE_ENV and app.get(‘env’). - The config package gives us an elegant way to store
                  configuration settings for our applications. - We can use the debug package to add debugging
                  information to an application. Prefer this approach to console.log() statements. - To return HTML
                  markup to the client, use a templating engine. There are various templating engines available out
                  there. Pug, EJS and Mustache are the most popular ones.

                  Asynchronous Javascript ======================= 70 - Synchronous Vs. Asynchronous Code
                  -------------------------------------- In the last section we used a simple array to manage our
                  courses:

                  const courses = [ { id: 1, name: 'course1' }, { id: 2, name: 'course2' }, { id: 3, name: 'course3' },
                  ];

                  In real-world applications however instead of using an in memory array we use a database. Before
                  learning about database access we should ensure we have a good and in-depth understanding of
                  asynchronous programming.

                  Create a new project using:

                  npm init --yes

                  to accept defaults. Create a new file called index.js and add the following code:

                  console.log('Before'); console.log('After');

                  This is an example of a synchronous or blocking program. In this program when the code executes the
                  first line is blocking and the second line has to wait until the first line finishes execution. These
                  type of programs are known as synchronous or blocking.

                  In contrast we have asynchronous or non-blocking programs. An example of an asynchronous program is as
                  follows:

                  console.log('Before'); setTimeout(() => { console.log('Reading a user from the database....'); },
                  2000); console.log('After');

                  The setTimeout takes two arguments, the first one is a function, the second is the time interval to
                  wait before executing the function. We will use this to simulate a call to a database which takes two
                  seconds.

                  When this program is executed some may think first the "Before" message will be displayed, followed by
                  a wait of two seconds, then the "Reading a user from the database..." message, followed by the "After"
                  message.

                  However that is not how this program will work. If you run the application from the terminal you will
                  see the following output:

                  Before After Reading a user from the database...

                  So "Before" and "After" are displayed immediately then we have a wait of two seconds before "Reading a
                  user from the database..." is displayed.

                  The setTimeout function is an example of an asynchronous or non-blocking function. When we call this
                  function it will schedule a task to be performed in the future - in this example the arrow function
                  containing the console.log command. It doesn't wait for that task to be completed, it doesn't block it
                  just schedules it and returns control which leads to the code that display the "After" message being
                  displayed.

                  One thing to make clear is that asynchronous does not mean concurrent or multi-threaded. In this
                  application we have a single thread which first executes the first line, then schedules a function to
                  be executed in two seconds, next it will display the "After" message in the console. After that it
                  will be free so two seconds afterwards it will execute the arrow function and display the message in
                  the console.

                  Earlier in the course we used the metaphor of a restaurant. So in a synchronous restaurant the waiter
                  comes to you, takes your order, gives it to the kitchen and then sits there waiting till your food is
                  ready before moving on to the next table. This is an example of synchronous or blocking restaurants.

                  In contrast, in an asynchronous kitchen, the waite doesn't wait in the kitchen. So while the chef is
                  preparing your meal the waiter will move onto the next table to take their order. What is important
                  here is that we have a single waiter or waitress. This is like a single thread in a program. So we
                  don't have multiple threads, we don't have concurrency.

                  Why do we need to know all this? Because in node programs whenever you are dealing with an operation
                  that involves disk or network access you are dealing with asynchronous code. So we need to know how
                  asynchronous code behaves. More importantly we need to know how to write asynchronous code in a clean
                  and maintainable way.

                  71 - Patterns for Dealing with Asynchronous Code ------------------------------------------------- Now
                  let's make the program from the previous lecture a little bit more real. So I'm going to extract the
                  setTimeout function to a new function called getUser adding a parameter of id. We will also return a
                  user object from the function call:

                  function getUser(id) { setTimeout(() => { console.log('Reading a user from the database....'); return
                  { id: id, gitHubUsername: 'mosh' }; }, 2000); }

                  If we try and get the user like this:

                  const user = getUser(1); console.log(user);

                  It won't work. The console.log function will write out undefined. The reason for this is that the
                  function that we pass to setTimeout is executed 2 seconds later. So what we are returning from this
                  function will not be available at the time we call getUser.

                  If we want to return a value from getUser we have to return it here:

                  function getUser(id) { setTimeout(() => { console.log('Reading a user from the database....'); return
                  { id: id, gitHubUsername: 'mosh' }; }, 2000);

                  return 1; }

                  This value of 1 will then be available on this line:

                  const user = getUser(1);

                  But that's not what we want because when accessing a database the result is not available immediately
                  - it may take 1/2 a second, 1 second, 5 seconds - who knows. That's why we are using setTimeout - to
                  simulate a long running operation. In this case we are reading something from the database and at this
                  point:

                  return { id: id, gitHubUsername: 'mosh' };

                  the result will be ready.

                  So how can we access the user object from the main program? There are three patterns to deal with
                  asynchronous code. - callbacks - promises - async/await

                  Async/await is really just some syntactical sugar over promises.

                  72 Callbacks ------------ In this lecture we will demonstrate how to use a callback to get the user
                  object. We need to make a small change to the signature of the getUser function, we need to add
                  another parameter called callback. callback is a function which we are going to call once the result
                  of an asynchronous operation is ready - like this:

                  function getUser(id, callback) { setTimeout(() => { console.log('Reading a user from the
                  database....'); callback({ id: id, gitHubUsername: 'mosh' }); }, 2000); }

                  back in the main application we can delete the const user from

                  const user = getUser(1);

                  because we are not going to get a return value from the function any longer. Now our getUser function
                  needs a second argument. We need to pass a function that will be called with this object:

                  { id: id, gitHubUsername: 'mosh' }

                  So we can pass a function that takes a user:

                  getUser(1, function(user) { });

                  Now we have access to the user object that we have "read" from the database - so we can display it on
                  the console:

                  getUser(1, function(user) { console.log('User', user); });

                  If we now run the application you should see the following output:

                  Before After Reading a user from the database.... User { id: 1, gitHubUsername: 'mosh' }

                  So this is an example of a callback or callback function. When the result of an asynchronous operation
                  is ready this function:

                  function(user) { console.log('User', user); });

                  will be called with the result - in this case the user object. We can also use the arrow function
                  syntax here:

                  getUser(1, (user) => { console.log('User', user); });

                  It's the same thing.

                  Let's imagine that once we read a user object from the database then we're going to look at the
                  gitHubUsername property and then we're going to call gitHub api to get the list of repositories for
                  this user. So create a function as follows:

                  function getRepositories(username) { return [ 'repo1', 'repo2', 'repo3' ]; }

                  This function is synchronous - we don't have any async code, there is no call to setTimeout or
                  anything asynchronous. Our job is convert this function to an asynchronous function (that takes two
                  seconds to complete) and then call it in the getUser function once we have the user object. Use
                  callback to get the list of repositories. Finally display the repositories on the console.

                  To make the function asynchronous we use setTimeout and provide a callback function and a timeout of 2
                  seconds:

                  function getRepositories(username) { setTimeout(() => {}, 2000);

                  return ['repo1', 'repo2', 'repo3']; }

                  Optionally we can add a console.log to the setTimeout function:

                  console.log("Calling GitHub API");

                  Finally we need to return the array or repos to the client or consumer of this function. However, as
                  you learned earlier, here we cannot return a value like this:

                  return ['repo1', 'repo2', 'repo3'];

                  Instead we have to use a callback:

                  function getRepositories(username, callback) { setTimeout(() => { console.log("Calling GitHub API");
                  callback(['repo1', 'repo2', 'repo3']); }, 2000); }

                  so we add a second parameter here - callback which is a function. We call this function with our repos
                  array.

                  Now we have an asynchronous function which takes a callback to return the result. Now back in our main
                  code after we get the user object we are going to get the repositories for that user:

                  getRepositories(user.gitHubUsername, (repos) => { console.log(repos); });

                  Now if you run the application you should see the following output:

                  Before After Reading a user from the database.... User { id: 1, gitHubUsername: 'mosh' } Calling
                  GitHub API [ 'repo1', 'repo2', 'repo3' ]

                  So the "Before" and "After" messsages are displayed immediately then 2 seconds later we see "Reading a
                  user from the database" then after another 2 seconds we see the array of repos: [ 'repo1', 'repo2',
                  'repo3' ]

                  73 - Callback Hell ------------------ So if we look at the code from the previous lecture you will see
                  a nesting structure is starting to appear getUser, getRepositories etc. When you nest several callback
                  functions this nesting can make the code difficult to read in comparison with synchronous
                  implementations where the code wont get indented at all.

                  This is referred to as callback hell or the christmas tree problem.

                  74 - Named Function to Rescue ----------------------------- Let's look at a simple solution to resolve
                  the callback hell problem:

                  getUser(1, (user) => { getRepositories(user.gitHubUsername, (repos) => { getCommits(repos, (commits)
                  => {

                  }); }); });

                  The technique we are going to use is to replace an anonymous function with a named function. What do
                  we mean by this? Look at the second argument to the getCommits function:

                  getCommits(repos, (commits) => {

                  });

                  This is what we call an anonymous function. A function that doesn't have a name. So we are going to
                  replace each anonymous function with a named function allowing us to flatten the structure of the
                  code.

                  We want to start at the deepest level and work up. We define a new function called displayCommits:

                  function displayCommits(commits) { console.log(commits); }

                  then in the getCommits function we can pass a reference to this function:

                  getCommits(repos, displayCommits());

                  We can apply the same technique to getRepositories and getUser functions. So in the getRepositories
                  method we have another anonymous function:

                  getRepositories(user.gitHubUsername, (repos) => { getCommits(repos, displayCommits); });

                  This anonymous function takes an array of repositories and then gets the commits for those
                  repositories. So let's create a function called getCommits with the same signature - an array or
                  repos. We also move the code we want to call into this function:

                  function getCommits(repos) { getCommits(repos, displayCommits); }

                  Then we can replace the anonymous function with a reference to our new named function:

                  getRepositories(user.gitHubUsername, getCommits);

                  Ok, one more time, here is our last anonymous function:

                  (user) => { getRepositories(user.gitHubUsername, getCommits); });

                  So this anonymous function takes a user object and gets the repositories for that user. So we create a
                  function called getRepositories that takes a user and in the body of the function we call
                  getRepositories with the arguments from our last anonymous function above (gitHubUsername and a
                  reference to the getCommits function):

                  function getRepositories(user) { getRepositories(user.gitHubUsername, getCommits); }

                  This may look a little bit confusing at first because here we have a function called getRepositories
                  but inside this function we are calling another function that is also called getRepositories. However,
                  these two functions are different because the first one takes a use object whilst the second function
                  takes a string (gitHubUsername) and a callback function.

                  Now we can replace the last anonymous function with a reference to getRepositories:

                  getUser(1, getRepositories);

                  Now we no longer have a deeply nested structure.

                  So we call getUser, when we have the user then we get the repositories for that user. In the
                  getRepositories function we pass the username and when we have the repositories we call getCommits for
                  one of the repositories. Similarly when we get the commits for one of the repositories we display them
                  to the console.

                  This approach is not ideal but it is better than before - at least we no longer have callback hell.

                  75 - Promises ------------- Javascript promises are extremely powerful when it comes to dealing with
                  asynchronous code. So what is a promise? A promise is an object that holds the eventual result of an
                  asynchronous operation. So when an asynchronous operation completes it can either result in a value or
                  an error. A promise, basically promises you it will give you the result of an asynchronous operation.

                  This promise object can be in one of three states:

                  - Initially, when we first create a promise, it will be in the pending state. At this point it will
                  kick off some asynchronous operation. - When the results are ready the promise can either be fulfilled
                  or resolved which basically means the asynchronous operation completed successfully so here we are
                  going to have a value. - If something went wrong during the execution of that asynchronous operation
                  the promise will be in the rejected state - in this case we will have an error

                  Let's see this in action. Add a new file called promises.js with the following code:

                  const p = new Promise()

                  This constructor function takes an argument - a function with two parameters:

                  const p = new Promise(function(resolve, reject) { });

                  So when creating a new promise we should create a function with two parameters - resolve and reject.
                  We can use the arrow function syntax here:

                  const p = new Promise((resolve, reject) => { });

                  In the body of this function we are going to kick off some async work - accessing a database, calling
                  a web server, start a timer etc.

                  Eventually when the async work completes we should either have a value or an error. If there is a
                  value then we want to return this to the consumers of this promise. So somewhere in our code we will
                  be consuming this promise because this promise object promises us that it is going to give us the
                  result of an asynchronous operation. So we need to send this result to the consumer of this promise.
                  The way we do that is by using the resolve or reject parameters. Basically these two parameters are
                  functions so we can call resolve:

                  const p = new Promise((resolve, reject) => { // Kick off some async work // ... resolve(1); });

                  We are using resolve to send this value to the consumers of the promise object.

                  Alternatively if something goes wrong we want to return an error to the consumer of the promise. In
                  that case instead of the resolve function we call reject. We can pass an error message to reject. In
                  best practice, it is better to pass an error object instead of a simple string:

                  const p = new Promise((resolve, reject) => { // Kick off some async work // ... //resolve(1);
                  reject(new Error('message')); });

                  Let's imagine our asynchronous operation completes successfully and produces 1 as a result:

                  const p = new Promise((resolve, reject) => { // Kick off some async work // ... resolve(1);
                  //reject(new Error('message')); });

                  Now we need to consume this promise object somewhere else in the code. You will see it provides two
                  methods: - catch for catching any errors - then for getting the result of our asynchronous operation

                  So we call then and write the result to the console:

                  p.then(result => console.log('Result', result));

                  Run the application and you should see the following output:

                  Result 1

                  In this implementation there isn't any asynchronous work, we are simply resolving the value
                  immediately. Let's make this a little bit more real life by adding a setTimeout function:

                  setTimeout(() => { resolve(1); // pending => resolved, fulfilled //reject(new Error('message')); //
                  pending => rejected }, 2000);

                  So now after 2 seconds this asynchronous operation will produce a value of 1.

                  Let's imagine that during the execution of this asynchronous operation something goes wrong. So we
                  want to return an error to the consumer of this promise. So instead of resolve we use reject:

                  setTimeout(() => { resolve(1); // pending => resolved, fulfilled //reject(new Error('message')); //
                  pending => rejected }, 2000);

                  We can chain .catch onto the end of our .then function to handle any errors:

                  p .then(result => console.log('Result', result)) .catch(err => console.log('Error', err.message));

                  We simply write the error to the console. Each error object that we have in Javascript has a message
                  property. So the error message that we pass here:

                  new Error('message')

                  Will be stored in property called message.

                  If we run the application now we should see an error message:

                  Error message

                  So what you need to take away from this lecture is that anywhere you have an asynchronous function
                  that takes a callback you should modify that function to return a promise.

                  76 - Replacing Callbacks with Promises -------------------------------------- This is the code using
                  callbacks that we wrote earlier where callback hell is starting to show:

                  console.log('Before'); getUser(1, (user) => { console.log('User', user);

                  getRepositories(user.gitHubUsername, (repos) => { console.log(repos); }); }); console.log('After');

                  function getUser(id, callback) { setTimeout(() => { console.log('Reading a user from the
                  database....'); callback({ id: id, gitHubUsername: 'mosh' }); }, 2000); }

                  function getRepositories(username, callback) { setTimeout(() => { console.log("Calling GitHub API");
                  callback(['repo1', 'repo2', 'repo3']); }, 2000); }

                  In order to resolve the callback hell problem we should modify our asynchronous functions to return a
                  promise. We will start with getUser:

                  function getUser(id) { return new Promise((resolve, reject) => { setTimeout(() => {
                  console.log('Reading a user from a database...'); resolve({id: id, gitHubUsername: 'mosh'}); }, 2000);
                  }); }

                  We return a new promise (the constructor of which takes an argument of a function which accepts two
                  parameters: resolve and reject). We use the resolve and reject parameters to signal the result of an
                  asynchronous operation or an error.

                  Again we use setTimeout to perform some async work. Finally we remove the callback parameter:

                  getUser(id)

                  Now in order to return the user object to the consumer of the promise we use the resolve function:

                  resolve({id: id, gitHubUsername: 'mosh'});

                  We apply the same technique to the getRepositories and getCommits methods:

                  function getRepositories(username) { return new Promise((resolve, reject) => { setTimeout(() => {
                  console.log('Calling GitHub API...'); resolve(['repo1', 'repo2', 'repo3']); }, 2000); }); }

                  function getCommits(repo) { return new Promise((resolve, reject) => { setTimeout(() => {
                  console.log('Calling GitHub Api...'); resolve(['commit']); }, 2000); }); }

                  Now none of our asynchronous functions here take a callback. Instead they return a promise.

                  77 - Consuming Promises ----------------------- So here we have this asynchronous code that uses the
                  callback approach:

                  getUser(1, (user) => { getRepositories(user.gitHubUsername, (repos) => { getCommits(repos[0],
                  (commits) => { console.log(commits); }) }) });

                  In this lecture I am going to show you how to rewrite this using promises:

                  getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos => getCommits(repos[0]))
                  .then(commits => console.log('Commits', commits)) .catch(err => console.log('Error', err.message));

                  So we call getUser passing 1 as an argument. getUser returns a promise:

                  const p = getUser(1);

                  In the last lecture you learned the Promise object has two methods catch and then. We use catch to
                  catch errors and we use then to get the result of an asynchronous operation:

                  p.then()

                  The result of the asynchronous operation is a user object because in the getUser function we are
                  resolving this promise with a user object. So we pass a function that takes a user:

                  p.then(user => console.log(user));

                  and we write that user to the console. If we run the application at this point we see the following in
                  the terminal:

                  Before After Reading a user from a database... { id: 1, gitHubUsername: 'mosh' }

                  So after two seconds we read a user from the database and our user object is written to the console.
                  We can simplify this code by getting rid of the constant and chaining then to what we get from the
                  getUser function:

                  getUser(1) .then(user => console.log(user));

                  In our previous implementation once we got a user then we got the repositories for that user. So let's
                  modify the code so that instead of calling console.log we are going to call getRepositories with an
                  argument of user.gitHubUsername:

                  getUser(1) .then(user => getRepositories(user.gitHubUsername));

                  If the function that we pass to the then method returns a value then we will wrap that value inside a
                  promise. That means, if we return a value, we are going to have another promise:

                  getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos => getCommits(repos[0]))

                  So we call then on that promise as well. In this case the promise in question is the one returned from
                  the getRepositories function.

                  function getRepositories(username) { return new Promise((resolve, reject) => { setTimeout(() => {
                  console.log('Calling GitHub API...'); resolve(['repo1', 'repo2', 'repo3']); }, 2000); }); }

                  So getRepositories returns a promise and eventually it will resolve that promise with an array of
                  repositories. So we chain then on the second promise which, when resolved, will give us an array or
                  repositories. At this point we want to get the commits for the first repository so we call getCommits
                  passing the first repository as an argument.

                  getCommits(repos[0])

                  Once again the getCommits function returns a promise so we can chain then on that promise. That
                  promise, when resolved, will eventually have a list of commits for the given repository. So here we
                  pass a function:

                  .then(commits => console.log('Commits', commits));

                  If we run the program one more time:

                  Before After Reading a user from a database... Calling GitHub API... Calling GitHub Api... Commits [
                  'commit' ]

                  We get "Before" and "After" then two seconds later we get "Reading a user from a database..." then two
                  seconds later we get "Calling GitHub API..." once for getting the repositories and again to get the
                  list of commits. Then we see the array of commits.

                  Now look at the callback and the implementation that uses promises side by side:

                  console.log('Before');

                  getUser(1, (user) => { getRepositories(user.gitHubUsername, (repos) => { getCommits(repos[0],
                  (commits) => { console.log(commits); }) }) });

                  getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos => getCommits(repos[0]))
                  .then(commits => console.log('Commits', commits));

                  console.log('After');

                  The first implementation used callbacks which resulted in the nested structure - the callback hell
                  problem. In the second implementation we use promises which gives us a much flatter structure. This is
                  the beauty of using promises because promises expose the then method we can chain them to implement a
                  complex asynchronous operation.

                  Finally, as a best practice, when we are working with promises we should make sure to catch any
                  errors. So at the end add a catch statement and just write the error to the console:

                  getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos => getCommits(repos[0]))
                  .then(commits => console.log('Commits', commits)) .catch(err => console.log('Error', err.message));

                  With this implementation if an error occurs during any of the asynchronous operations the function
                  passed to the catch method will be called.

                  78 - Creating Settled Promises ------------------------------ So you have seen a taste of promises
                  throughout this section. In this lecture we are going to explore the API of a Promise object in
                  Javascript in more detail.

                  Create a file called index.js. Sometimes you want to create a promise that is already resolved - this
                  is particularly useful when writing unit tests - so you want to simulate a scenario where an
                  asynchronous operation, like calling a web service, completes successfully.

                  The Javascript Promise class has a static method called resolve which returns a promise which is
                  already resolved. We can optionally pass a value or a user object:

                  const p = Promise.resolve({ id: 1 });

                  This promise is already resolved so we can call the then method:

                  p.then(result => console.log(result));

                  get the result and display it on the console. If we run this program we will see the following in the
                  terminal:

                  { id: 1 }

                  We see the user object that our promise holds. Similarly sometimes you want to create a promise that
                  is already rejected. If that's the case we simply call the reject method instead of resolve passing an
                  Error object:

                  const r = Promise.reject(new Error('reason for rejection...')); r.catch(error => console.log(error));

                  Now that our promise is rejected we call catch to get the error. We also rename result to error.

                  If we run the application we should see the following output on the console:

                  Error: reason for rejection... at Object.
                  <anonymous>
                    (C:\DevelopmentTutorials\TheCompleteNodeJSCourse\06-asynchronous-javascript\78-creating-settled-promises\index.js:4:26)
                    at Module._compile (module.js:653:30) at Object.Module._extensions..js (module.js:664:10) at
                    Module.load (module.js:566:32) at tryModuleLoad (module.js:506:12) at Function.Module._load
                    (module.js:498:3) at Function.Module.runMain (module.js:694:10) at startup
                    (bootstrap_node.js:204:16) at bootstrap_node.js:625:3

                    We see the "reason for rejection" message and the call stack that comes with every error object in
                    Javascript. This is the reason why, as a best practice, whenever you want to reject a promise it's
                    better to use a native error object because it will include the call stack. If we were to pass a
                    simple string instead:

                    const r = Promise.reject('reason for rejection...');

                    We wouldn't see the call stack show above.

                    79 - Running Parallel Promises ------------------------------ Sometimes you want to run a few
                    asynchronous operations in parallel. When they all complete you want to perform some action. For
                    example, you may call the Facebook API and the Twitter API and when the result of both these
                    asynchronous operations are ready then you want to return something to the client.

                    Let's simulate this:

                    const p1 = new Promise((resolve) => { setTimeout(() => { console.log('Async operation 1....');
                    resolve(1); }, 2000); });

                    const p2 = new Promise((resolve) => { setTimeout(() => { console.log('Async operation 2....');
                    resolve(2); }, 2000); });

                    In the above promises we exclude the reject parameter because we only need resolve in this example.
                    We call setTimeout again and give it a callback function and a timeout of two seconds. We perform a
                    simple console.log and then resolve the promise.

                    We then duplicate the code to create another promise which is our second asynchronous operation. We
                    resolve this promise with a value of 2.

                    Now we kick off both asynchronous operations and when they complete we do something:

                    Promise.all([p1, p2]) .then(result => console.log(result));

                    We call the all method (another method that is available on the Promise class). We give it an array
                    of promises. This method will return a new promise that will resolve when all the promises in this
                    array are resolved.

                    We get the promise and call then, get the result and display it on the console. Let's see what
                    happens when we run this application:

                    Async operation 1.... Async operation 2.... [ 1, 2 ]

                    So, we get two seconds delay then both asynchronous operations are kicked off at the same time.
                    Eventually we get the result which is an array of two numbers.

                    A few things to clarify.

                    Firstly, we don't have real concurrency or multi-threading. We are still dealing with one thread but
                    that thread is kicking off multiple asynchronous operations almost at the same time - it's not
                    exactly at the same time. First it starts Async operation 1, the thread is released, so immediately
                    after it starts the second Async operation. We don't wait for the result of the first asynchronous
                    operation to be ready in order to kick off the second asynchronous operation. The situation we had
                    in our previous example was that we got the user object, then we got the repositories, then we got
                    the commits for the first repository. So each asynchronous operation started after the previous
                    asynchronous operation completed. That was different. In this implementation both the asynchronous
                    operations are started almost at the same time.

                    The second thing is that when we get the result it will be available as an array. In this case each
                    promise is resolved with a value - in this case 1 and 2. Our result array will have two values 1 and
                    2.

                    Now what if one of these promises fails?

                    Let's change the first promise by adding a reject parameter, then instead of resolving, let's reject
                    it and pass an error:

                    const p1 = new Promise((resolve, reject) => { setTimeout(() => { console.log('Async operation
                    1....'); reject(new Error('because something failed.')); }, 2000); });

                    Now, we add a catch method to get the error if one of our promises is rejected:

                    Promise.all([p1, p2]) .then(result => console.log(result)) .catch(err => console.log('Error',
                    err.message));

                    Run the application:

                    Async operation 1.... Async operation 2.... Error because something failed.

                    It should be noted that if any of our promises is rejected, the final promise that is returned from
                    Promise.all is considered rejected.

                    One last thing, before we finish the lecture. Go back to our first promise and set it back to
                    resolve as before:

                    const p1 = new Promise((resolve) => { setTimeout(() => { console.log('Async operation 1....');
                    resolve(1); }, 2000); });

                    Sometimes we want to kick of multiple asynchronous operations but we want to do something as soon as
                    the first asynchronous operation completes. If that's the case use Promise.race instead of
                    Promise.all:

                    Promise.race([p1, p2]) .then(result => console.log(result)) .catch(err => console.log('Error',
                    err.message));

                    Again pass an array of promises and as soon as one of the promises in the array is fulfilled the
                    promise that is returned from this race method will be considered fulfilled.

                    Let's see what happens when we run this application:

                    Async operation 1.... Async operation 2.... 1

                    Both our asynchronous operations are started but our promise was resolved as soon as the first
                    asynchronous operation completed. In this case the result we have is not an array - it's the value
                    of the first fulfilled promise.

                    80 Async and Await ================== Earlier, in index.js, you saw how we could rewrite
                    asynchronous code that used a callback based approach:

                    getUser(1, (user) => { getRepositories(user.gitHubUsername, (repos) => { getCommits(repos[0],
                    (commits) => { console.log(commits); }) }) });

                    to use promises:

                    // Promise-based approach getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos
                    => getCommits(repos[0])) .then(commits => console.log('Commits', commits)) .catch(err =>
                    console.log('Error', err.message));

                    We then discussed how we could make this code even simpler. Now in Javascript we have a new feature
                    called Async and Await. If you are familiar with C# there we also have the same feature.

                    Async and Await helps you write asynchronous like synchronous code. Let's illustrate what I mean by
                    this by rewriting the promise approach shown above using Async and Await.

                    // Async and Await approach async function displayCommits() { try { const user = await getUser(1);
                    const repos = await getRepositories(user.gitHubUsername); const commits = await
                    getCommits(repos[0]); console.log(commits); } catch (err) { console.log('Error', err.message); } }
                    displayCommits();

                    We call getUser. The getUser function returns a promise. Now anytime you're calling a function that
                    returns a promise you can await the result of that function - then get the actual result just like
                    calling a synchronous function:

                    const user = await getUser(1);

                    Now that we have a user object we can call getRepositories to get the repositories for this user.
                    The getRepositories function also returns a promise so we can await the result and then store the
                    repositories in a const:

                    const repos = await getRepositories(user.gitHubUsername);

                    Now that we have the repositories we can call getCommits passing the first repository. Again because
                    the getCommits function returns a promise we can await it and store the commits in a const.

                    const commits = await getCommits(repos[0]);

                    Finally we can do a console.log of the commits:

                    console.log(commits);

                    So we can see with the await operator we can write asynchronous code that looks like synchronous
                    code. The code above is much easier to understand than the code in the callbacks or even promises
                    demos shown earlier. We don't have to go through a chain of calls to the then method.

                    So this is await. But where is async. Well whenever you use the await operator in a function you
                    need to decorate that function with the async modifier. In this particular example we have written
                    this code block outside of a function. To satisfy the Javascript engines requirement that whenever
                    you use await you should have a function that is decorated with async we define a function called
                    display commits:

                    function displayCommits() { }

                    We can move our code block inside this function and decorate the function with async:

                    async function displayCommits() { const user = await getUser(1); const repos = await
                    getRepositories(user.gitHubUsername); const commits = await getCommits(repos[0]);
                    console.log(commits); }

                    Finally we can call this function:

                    displayCommits()

                    If you look at the return type of the function it returns Promise
                    <void>. That means a promise that once fulfilled doesn't result in a value. Basically, this is
                      telling us that Async and Await are built on top of promises. They are syntactical sugar in the
                      language that allow use to write asynchronous code that looks synchronous. Internally , when the
                      Javascript engine converts this code, it's going to convert the code to something like the example
                      we saw earlier that used promises:

                      getUser(1) .then(user => getRepositories(user.gitHubUsername)) .then(repos =>
                      getCommits(repos[0])) .then(commits => console.log('Commits', commits)) .catch(err =>
                      console.log('Error', err.message));

                      So, even though our code looks synchronous, it does'nt execute synchronously. In other words, when
                      we are awaiting the result of this function:

                      const user = await getUser(1);

                      We are not really waiting or blocking in a synchronous fashion. So, in terms of the code
                      execution, when a Javascript engine executes this line:

                      const user = await getUser(1);

                      at this point it's going to release our thread to do other work. When the result of the getUser
                      function is available then we come back here:

                      const user = await getUser(1);

                      and store the result in the user const and call the second line:

                      const repos = await getRepositories(user.gitHubUsername);

                      Again we have await so the thread is released to do other work.

                      Let's run the application in the terminal:

                      Before After Reading a user from a database... Calling GitHub API... Calling GitHub API...
                      ['commit']

                      One last thing before we finish this lecture. In our promised based approach we used a catch
                      method to get any errors. When using Async and Await we don't have this catch method - instead we
                      use a try/catch block:

                      // Async and Await approach async function displayCommits() { try { const user = await getUser(1);
                      const repos = await getRepositories(user.gitHubUsername); const commits = await
                      getCommits(repos[0]); console.log(commits); } catch (err) { console.log('Error', err.message); } }
                      displayCommits();

                      So we try to run the code in our try block. If anything goes wrong we execute the code in our
                      catch block.

                      Now let's simulate an error in the getRepositories function by rejecting the promise:

                      function getRepositories(username) { return new Promise((resolve, reject) => { setTimeout(() => {
                      console.log('Calling GitHub API...'); //resolve(['repo1', 'repo2', 'repo3']); reject(new
                      Error('Could not get the repos.')); }, 2000); }); }

                      Now run the application:

                      Before After Reading a user from a database... Calling GitHub API... Error Could not get the
                      repos.

                      So when using Async and Await you need to wrap your code inside a try/catch block.

                      81 - Exercise ============= In 12exercise-before.js we have some code that is written using the
                      callback based approach:

                      getCustomer(1, (customer) => { console.log('Customer: ', customer); if (customer.isGold) {
                      getTopMovies((movies) => { console.log('Top movies: ', movies); sendEmail(customer.email, movies,
                      () => { console.log('Email sent...') }); }); } });

                      So we have the getCustomer function which takes an id of 1 and in the callback function we get a
                      customer object. We do a simple console.log. If the customer isGold we are going to call
                      getTopMovies which has another callback function. The argument here is the list of movies. At this
                      point we do another console.log and then finally we send an email to this customer with the list
                      of top movies. When we are done we have another callback function which performs a simple
                      console.log.

                      If we run the application:

                      Customer: { id: 1, name: 'Mosh Hamedani', isGold: true, email: 'email' } Top movies: [ 'movie1',
                      'movie2' ] Email sent...

                      It takes about 4 seconds to get a Customer, then we get the top movies, finally we send an email
                      to this customer with the top movies.

                      To complete the exercise rewrite the code using Async and Await.

                      Solution -------- In order to use Async and Await we have to modify our getCustomer or
                      getTopMovies to return a promise. Once a function returns a promise then we can await it.

                      Starting with the getCustomer function:

                      function getCustomer(id) { return new Promise((resolve, reject) => { setTimeout(() => { resolve({
                      id: 1, name: 'Mosh Hamedani', isGold: true, email: 'email' }); }, 4000); }); }

                      First we remove the callback, then we return a new Promise passing a callback which is called the
                      executor. This function has two arguments - resolve and reject. We add our async code to the
                      promise. Finally instead of calling the callback function we call resolve.

                      Now perform the same process with the getTopMovies function: - remove the callback - return a new
                      Promise - move the async code into the promise code block - replace the callback with resolve

                      Finally perform the process with the sendEmail function.

                      So, we have modified our functions to return a promise, now let's go back to the main code and
                      rewrite that:

                      async function notifyCustomer() { try { const customer = await getCustomer(1);
                      console.log('Customer: ', customer); if(customer.isGold) { const movies = await getTopMovies();
                      console.log('Top movies: ', movies); await sendEmail(customer.email, movies); console.log('Email
                      sent...') } } catch(err) { console.log('Error', err.message); } }

                      First we call getCustomer(1) which returns a promise which can be awaited. We store the customer
                      in a const called customer. Next we do a console.log.

                      Next we check if customer isGold and if so we call getTopMovies, which again returns a promise
                      which can be awaited and stored in a const called movies. After that we do another console.log.
                      Finally we send an email passing the customers email and their list of top movies. Again this
                      returns a promise which we await. When done we do another console.log.

                      As discussed before, whenever you use await your code should be inside a function that is
                      decorated with the async modifier.

                      We then call the function:

                      notifyCustomer();

                      Additionally we have added a try/catch block to the async notifyCustomer function.

                      82 - Introducing MongoDB ======================== Back to our Vidly application and so far we have
                      stored the list of genres in an array in memory. That's not how we build real world applications
                      because when the server restarts we will lose all our data. For this reason, we will store our
                      data in a database.

                      Now, as mentioned previously, when you build applications with Node and Express you have a large
                      number of options in terms of the database you want to use. In this course we will use MongoDB
                      because that's a very popular Database Management System that is quite often used in applications
                      built with Node and Express.

                      MongoDB is a document or no SQL database. It is different from traditional relational databases
                      like SQL Server or My SQL. In MongoDB we don't have the concept of tables, schemas, views, records
                      columns etc.

                      Unlike relational databases where you design your database ahead of time in MongoDB there is no
                      such thing as schema or design. You simply store JSon objects in MongoDB. So here we have an array
                      of genres. We can simply store all the objects in this array in a collection in MongoDB. This also
                      means that when we query our data we get JSon objects out of MongoDB and we can simply return
                      those objects back to the client - there is no transformation.

                      83 - Installing MongoDB on Mac ============================== In this lecture we will see how to
                      install MongoDB on a Mac. Firstly browse to brew.sh which is the website for Homebrew. Homebrew is
                      a package manager for Mac OS - very similar to npm.

                      To install copy this line: /usr/bin/ruby -e "$(curl -fsSL
                      https://raw.githubusercontent.com/Homebrew/install/master/install)"

                      into a terminal session, enter your password. This will download some binaries and install
                      Homebrew. We can now install MongoDB with the following command:

                      brew install mongodb

                      Next create a directory for MongoDB to store it's data

                      sudo mkdir -p /data/db

                      Now make sure that the data directory has the correct permissions:

                      sudo chown -R `id -un` /data/db

                      Now we need to run Mongo Daemon:

                      mongod

                      Back in the browser goto mongodb.com and click the Download button. Download MongoDB Compass (make
                      sure you select the Mac OS for platform). Open the DMG file and drag and drop MongoDB Compass onto
                      the applications folder.

                      Run MongoDb Compass and connect to the host on localhost 27017. You should see the admin and local
                      default databases.

                      84 - Installing MongoDB on Windows ================================== In this lecture we will see
                      how to install MongoDb on Windows. Browse to mongodb.com and click the download button. Then
                      select the Community Server tab, make sure Windows is selected and download the .msi.

                      Run the installer, and perform a complete installation. Compass doesn't seem to install with
                      MongoDb even if you leave the checkbox to Install MongoDb Compass checked. Compass is the client
                      application that we can use to connect to our MongoDb Server to look at our databases.

                      Let's now install MongoDB Compass. From mongodb.com select the Compass tab, select Windows and
                      Download. Run the installer.

                      Next open up C:\Program Files\MongoDB\Server\CURRENT VERSION\bin - select this path. Next in the
                      Windows Search Bar search for View Advanced System Settings. Select Environment Variables. Select
                      the Path environment variable and click Edit. Click New and paste the path we copied earlier that
                      contains the MongoDB Server.

                      Now open up a command prompt and run:

                      mongod

                      Initially you will receive an error:

                      Path: Data directory C:\data\db\ not found, terminating

                      Create this folder and run mongod again.

                      You should see some output ending with something similar to this:

                      2018-12-11T21:25:35.132+0000 I NETWORK [initandlisten] waiting for connections on port 27017

                      Now run MongoDB Compass, and leave the default values in the Connect to Host screen:

                      host: localhost port: 27017

                      Click connect and you should see a couple of default databases: admin and local.

                      85 - Connecting to MongoDB ========================== Let's create a new project for this section.
                      Run npm init with the yes flag:

                      npm init --yes

                      Now install mongoose:

                      npm i mongoose@5.0.1

                      Mongoose gives a simple API to work with a MongoDB database.

                      Create a new file called index.js and add the following code:

                      const mongoose = require('mongoose');

                      mongoose.connect('mongodb://localhost/playground') .then(() => console.log('Connected to
                      MongoDB...')) .catch(err => console.error('Could not connect to MongoDB...', err));

                      First we load the mongoose module and store it in constant. This object has method called connect
                      which we can use to connect to MongoDB. We pass a connection string of
                      mongodb://localhost/playground. The connection string contains the MongoDB server name followed by
                      the database. A production environment would have a different connection string that ideally would
                      be obtained from a configuration file. It doesn't matter that the database does not exist. The
                      first time we write something to the database MongoDB will automatically create this database for
                      us. The connect method returns a promise. This means we can call .then() and write to the console
                      that we have connected. The connect method also provides a catch method that we can use to catch
                      any errors connecting to the database.

                      If we run the application:

                      nodemon index.js

                      And you should see that your are successfully connected:

                      [nodemon] 1.17.3 [nodemon] to restart at any time, enter `rs` [nodemon] watching: *.* [nodemon]
                      starting `node index.js` Connected to MongoDB...

                      86 - Schemas ============ Now that we have connected to a MongoDB database the next thing we need
                      to do is create a schema. We use a schema to define the shape of documents within a collection in
                      MongoDB. To demonstrate go back to MongoDB Compass. I've created a database called playground and
                      in this database we have a collection called courses:

                      figure xx-xx

                      A collection in MongoDB is like a table in a relational database. The courses collection contains
                      three documents. A document in MongoDB is similar to a row in a relational database.

                      If we take a look at the collection:

                      figure xx-xx

                      We see an example of a document. Each document is a container of key/value pairs. So we have:

                      _id: A unique identifier for each document tags: An array of key value pairs

                      We also have date, name, author, isPublished and __v (version).

                      In mongoose we have a concept called schema which is specific to Mongoose - it is not part of
                      MongoDB. We use the schema to define the shape of documents in a MongoDB collection - what are the
                      properties we have in a document.

                      To create a schema add the following code:

                      const courseSchema = new mongoose.Schema({ name: String, author: String, tags: [ String ], date: {
                      type: Date, default: Date.now }, isPublished: Boolean });

                      We define a const called courseSchema and set it to a new mongoose.Schema class. When creating an
                      instance of this class we specify the key/value pairs that we should have in course documents
                      (name, author, tags, date, isPublished)

                      Each object in the tags array of strings is stored as a key/value pair. The key will be the index
                      and the value will be the string.

                      We add a default value to the date property of Date.now. We specify this in an object.

                      The list of types we can use when creating a schema is:

                      String Number Date Buffer - used for storing binary data Boolean ObjectID - used for assigning
                      unique identifiers Array

                      87 - Models ===========

                      So here's our course schema that defines the shape of course documents in our MongoDB database.
                      Now we need to compile this into a model. What is a model? Earlier in the course we talked about
                      the concept of classes and objects. As an example I said that we could have a class called Human
                      and an object like John:

                      // Classes, objects // Human, John

                      An object is an instance of a class. The class is just a blueprint but an object is an instance of
                      that blueprint.

                      In this application we want to have a class called Course. Then we want to be able to create
                      instances of that class like Node Course:

                      // Classes, objects // Course, nodeCourse

                      Then we can save that Node Course to our database. To create a class like Course we need to
                      compile our Schema into a model. The mongoose object has a method called model that takes two
                      arguments. The first argument is the singular name of the collection that this model is for. So,
                      in our MongoDB database we want to have a collection called Courses so here's the singular name:

                      mongoose.model('Course', )

                      The second argument is the schema that defines the shape of the documents in this collection:

                      mongoose.model('Course', courseSchema);

                      With this we get a Course class in our application. So we can set this to a const called Course:

                      const Course = mongoose.model('Course', courseSchema);

                      Note here we are using Pascal naming convention so the first letter of Course is uppercase. That
                      indicates this is a class not an object. Now we can create an object based on this class:

                      const course = new Course({ name: 'Javascript Course', author: 'Max Sage', tags: ['javascript',
                      'client'], isPublished: true });

                      We create a course object. Note here we use Camel case - so the first letter of the first word is
                      lowercase. So we use Camel case to name our objects and Pascal case to name our classes.

                      We set the course object to a new Course and in the constructor function we pass an object to
                      initialize our course object. You can see the tags property is set to any array of two strings.
                      This is one interesting thing about Mongo or NoSQL databases. A document in MongoDB can be a
                      complex object. The tags property is an array of strings - you wouldn't find this in a relational
                      database. A row in a relational database has simple attributes. If you want to model the above
                      structure in a relational database you would need three tables:

                      - Courses - Tags - CourseTags

                      The CourseTags table would be an intermediary table because here we have a many to many
                      relationship between Courses and Tags.

                      In MongoDB or in a NoSQL database we don't have this structure. You dont have to define or script
                      the above tables. We simply create our objects and store them in a database. That's why we call
                      them schema-less - we don't have a schema.

                      We omit the date property to let the default value of Date.now to take effect.

                      To recap, once we have a schema we need to compile that into a model which gives us a class. Next
                      we can create an object based on that class. This object maps to a document in a MongoDB database.

                      88 - Saving a Document ======================

                      Here's our course object that maps to a Course Document in MongoDB. Let's save this to our
                      database. The course object has a method called save:

                      course.save();

                      Here we are dealing with an asynchronous operation - it's going to take some time to save this
                      course in the database because we are going to access the filesystem. The save method returns a
                      promise which we can await and get the result:

                      const result = await course.save();

                      The result returned is the actual course object that is saved in the database. When we save this
                      course MongoDB is going to assign a unique identifier to the course object/document. We log the
                      assigned id on the console:

                      console.log(result);

                      As mentioned previously, whenever you use await your code should be inside an async function:

                      async function createCourse() { }

                      We move our code inside the function and call the function:

                      createCourse();

                      In terminal we will run this application using node instead of nodemon because we dont want to
                      create a new document every time we modify our code slightly:

                      node index.js

                      You should see output similar to the following:

                      Connected to MongoDB... { tags: [ 'javascript', 'client' ], _id: 5c112ac86ccab44c6867a388, name:
                      'Another Course', author: 'Max Sage', isPublished: true, date: 2018-12-12T15:35:36.837Z, __v: 0 }

                      This output displays the document that is actually stored in MongoDB. You can see the unique id
                      that MongoDB has assigned:

                      _id: 5c112ac86ccab44c6867a388

                      In MongoDB compass browse the courses collection of the playground database and you will see this
                      newly created document:

                      figure xx-xx

                      The beauty of MongoDB and other NoSQL databases is that we didn't have to create or script the
                      table. We simply created a document and stored it in our MongoDB database.

                      Back in the code, let's modify the code to create another document:

                      const course = new Course({ name: 'Angular Course', author: 'Max Smith', tags: ['angular',
                      'frontend'], isPublished: true });

                      Then in the next lecture we will look at querying documents. Rerun the application again:

                      node index.js

                      You should see output similar to the following:

                      { tags: [ 'angular', 'frontend' ], _id: 5c1134d8ad46321564d9a0c8, name: 'Angular Course', author:
                      'Max Smith', isPublished: true, date: 2018-12-12T16:18:32.125Z, __v: 0 }


                      In MongoDB Compass you should also see the additional document has been added to the collection.

                      89 - Querying Documents =======================

                      Now let's look at retrieving documents from a MongoDB database. Let's create another function:

                      async function getCourses() { const courses = await Course .find({author: 'Mosh', isPublished:
                      true }) .limit(10) .sort({ name: 1 }) // 1 ascending order -1 descending order .select({ name:1,
                      tags: 1}); console.log(courses); }

                      The Course class (defined earlier) has a bunch of methods for querying documents:

                      - find - findById - findOne

                      There are several other find methods available which are generally used to find a document and
                      then remove or update it. We will look at these methods later.

                      The find method returns a document query object:

                      figure xx-xx

                      The document query object is kind of like a promise. It has a then method that can be used to
                      await it then get the result:

                      const courses = await Course.find(); console.log(courses);

                      With this we get all the courses in our database which we write to the console. Back in terminal
                      run the application:

                      node index.js

                      You should receive an array of objects something like this:

                      [ { tags: [ 'javascript', 'client' ], date: 2018-12-12T15:35:36.837Z, _id:
                      5c112ac86ccab44c6867a388, name: 'Another Course', author: 'Max Sage', isPublished: true, __v: 0 },
                      { tags: [ 'angular', 'frontend' ], date: 2018-12-12T16:18:32.125Z, _id: 5c1134d8ad46321564d9a0c8,
                      name: 'Angular Course', author: 'Max Smith', isPublished: true, __v: 0 } ]

                      We can also use the find method to pass a filter which consists of an object with one or more
                      key/value pairs:

                      .find({author: 'Max Smith', isPublished: true })

                      We can also sort our documents, set a limit on the number of documents returned, select specific
                      properties within the document etc. Let's create a more complex query. Earlier we saw that the
                      find method returns a DocumentQuery object. We can customise the query:

                      const courses = await Course .find({author: 'Max Smith', isPublished: true }) .limit(10) .sort({
                      name: 1 }) // 1 ascending order -1 descending order .select({ name:1, tags: 1});

                      We can apply a limit, sort the documents by passing an object containing one or more value pairs
                      (1 for ascending, 2 for descending), select the properties we want returned. You will still
                      receive the _id property back which is assigned by MongoDB by default.

                      90 - Comparison Query Operators ============================= Since Mongoose is built on top of
                      the MongoDB driver the standard operators that MongoDB understands are also available in Mongoose:

                      eq - equal ne - not equal gt - greater than gte - greater than or equal to lt - less than lte -
                      less than or equal to in nin - not in

                      For the purpose of this lecture let's image that our courses have a price property. Let's say we
                      want to get all the courses that are $10:

                      .find({ price: 10})

                      If we want to find all the courses where the price is 10 or more. We express this in Javascript
                      using JSon objects. An object, in this context, is basically a collection of key/value pairs - for
                      the example above our key is price and our value is 10. With this simple value we can't express
                      the concept of more than or greater than 10. To achieve this we again pass an object containing
                      key/value pairs. We can use one of the operators described above as a key:

                      .find({ price: { $gt: 10}})

                      What if we want to get the courses that are between 10 and 20 dollars. We can use another operator
                      for this:

                      .find({ price: { $gte: 10, $lte: 20}})

                      Imagine we want to get courses that are $10, $15 or $20:

                      .find({price: { $in: [10, 15, 20]}})

                      We use an array to pass the values we are interested in searching for.

                      91 - Logical Query Operators ============================ In this lecture we will investigate how
                      to use the logical query operators. Our original query for getting all the courses by a specific
                      author that have been published looks like this:

                      .find({ author: 'Max Smith', isPublished: true })

                      Now, what if we want to get the courses that are published by Max Smith or the courses that are
                      published - regardless of the author. In this scenario we would use the or operator:

                      .find() .or([ {author: 'Max Smith'}, { isPublished: true}])

                      We pass an array to the or method which contains an array of key/value pairs. The and logical
                      operator uses exactly the same syntax. It is functionally similar to passing a filter to the find
                      method.

                      92 - Regular Expressions ========================

                      In our original query we are getting courses who's author is exactly the string specified:

                      .find({author: 'Max Smith', isPublished: true })

                      If we have courses where the author is Maxwell Smith or Max James they will not be returned. If
                      you want to have more control over filtering strings we need to use a regular expression. For
                      example, if we want to get courses who's Author starts with Max we would use the following query:

                      .find({author: /^Max/ })

                      Instead of passing a string we pass a regular expression denoted by /pattern/. In regular
                      expressions we use the caret character to represent a string that starts with something. In our
                      example we look for an author that starts with Max.

                      If you want to look for authors that end with a given string you use the following regular
                      expression:

                      .find({author: /Sage$/i})

                      Dollar sign in regular expressions indicates the end of a string. If you want the query to be case
                      sensitive you add an i to the end.

                      If you want to get courses who's author contains a given word you use the following syntax:

                      .find({author: /.*Sage.*/i })

                      This will locate the string Sage anywhere in the author field. .* in a regular expression means we
                      can have 0 or more characters before the or after the specified string. Again we use i at the end
                      of the regular expression to make it case insensitive.

                      We can use more complex regular expressions - google it if you want to know more.

                      93 - Counting =============

                      So in this query:

                      async function getCourses() { const courses = await Course .find({author: 'Mosh', isPublished:
                      true }) .limit(10) .sort({ name: 1 }) .select({ name: 1, tags: 1 }); console.log(courses); }

                      We are filtering our courses and picking only the name and tags properties. If we run the
                      application we get something like this:

                      [ { tags: [ 'angular', 'frontend' ], _id: 5c2776c84d1009065ce2e60a, name: 'Angular Course' }, {
                      tags: [ 'javascript', 'client' ], _id: 5c2776a673f3482cb426ca39, name: 'Javascript Course' } ]

                      Sometimes you just want to retrieve the number of documents that match your criteria. In this case
                      we can switch the select method for the count method:

                      .count();

                      94 - Pagination ===============

                      The method that goes hand in hand with the limit method (covered earlier) is the skip method which
                      can be used to implement pagination.

                      First define two constants - pageNumber and pageSize:

                      const pageNumber = 2; const pageSize = 10;

                      Here the values have been hardcoded for simplicity but in a real world application you would pass
                      these values as query string parameters in our RESTfull API:

                      /api/courses?pageNumber=2&pageSize=10

                      In order to implement pagination we need to skip all the documents in the previous page:

                      .skip((pageNumber - 1) * pageSize)

                      Here we are assuming that page number starts from 1 - so more acurately this is page number not
                      page index. Next, we change limit to pageSize:

                      .limit(pageSize)

                      With this we can get the documents in a given page.

                      95 - Exercise 1 ===============

                      In this exercise we use two files: exercise-data.json exercise.txt

                      The json file contains 7 course objects which we are going to import into a new database called
                      mongo-exercises.

                      The exercise.txt file contains a command which we can run from a terminal to import the json file:

                      mongoimport --db mongo-exercises --collection courses --file exercise-data.json --jsonArray

                      The flags have the following meaning:

                      --db Specifies the database to use for the import --collection Specifies the collection to use
                      --file Specify the file which contains the data to import --jsonArray Specifies the data to be
                      imported is in the format of a Json Array

                      Once you run this command you should be able to browse the new database and the courses collection
                      from MongoDB Compass.

                      The first exercise is to write a program to get all the published courses, sort them by name, pick
                      only the name and author properties and display them.

                      First we load mongoose and store it in a const:

                      const mongoose = require('mongoose');

                      Next we connect to our MongoDb database:

                      mongoose.connect('mongodb://localhost/mongo-exercises')

                      Next we create a schema to define the shape of documents in our courses collection:

                      const courseSchema = new mongoose.Schema({ name: String, author: String, tags: [ String ], date: {
                      type: Date, default: Date.now }, isPublished: Boolean, price: Number });

                      Next we create a model specifying the collection in singular form and the schema:

                      const Course = mongoose.model('Course', courseSchema);

                      Now we have a model we can use it to query our courses:

                      async function getCourses() { return await Course .find( { isPublished: true, tags: 'backend' })
                      .sort({ name: 1 }) .select({name: 1, author: 1}); }

                      Because we are using await we use an async function. We call the getCourses function:

                      const courses = await getCourses();

                      As we mentioned earlier, when we decorate a function with async our JavaScript engine
                      automatically wraps the result in a promise:

                      //TODO fig xx-xx

                      For this reason we await the result and store it in a const. Because we use the await operator we
                      need to wrap this line in an async function which we will call run:

                      async function run(){ const courses = await getCourses(); console.log(courses); }

                      Finally we call the run function:

                      run();

                      If you now run the application you should see something similar to this:

                      [ { _id: 5c2788220a54c304a4a8b0da, name: 'ASP.NET MVC Course', author: 'Mosh' }, { _id:
                      5c2788220a54c304a4a8b0d8, name: 'Express.js Course', author: 'Mosh' }, { _id:
                      5c2788220a54c304a4a8b0d9, name: 'Node.js Course', author: 'Mosh' }, { _id:
                      5c2788220a54c304a4a8b0dc, name: 'Node.js Course by Jack', author: 'Jack' } ]

                      96 - Exercise 2 ===============

                      For the second exercise we need to get all the published frontend and backend courses, sort them
                      by their price in a descending order, pick only their name and author, and display them.

                      The code in this exercise is identical to exercise 1 apart from the query in getCourses:

                      async function getCourses() { return await Course // First solution is to use the in comparison
                      query operator .find({isPublished: true, tags: {$in: ['backend', 'frontend']}}) .sort({ price: -1
                      }) .select({name: 1, author: 1, price: 1, tags: 1, isPublished: true}); }

                      So we want to get all the published frontend and backend courses. An array:

                      .find({isPublished: true, tags: ['backend', 'frontend']})

                      wont work because this will return courses that contain both the specified tags (the logical AND
                      operator will be applied). We need to modify this query to use the in operator (discussed earlier
                      in the section on comparison operators):

                      .find({isPublished: true, tags: {$in: ['backend', 'frontend']}})

                      We set the tags property to an object. This object contains key value pairs. The keys are MongoDB
                      operators - in this case $in. The Javascript construct we use to represent multiple values is an
                      array. We set an array of two strings: 'frontend' and 'backend'.

                      Next we sort by price in a descending order:

                      .sort({ price: -1 })

                      Alternatively we can use the following syntax:

                      .sort('-price')

                      Finally we specify that just the name, author and price properties should be returned:

                      .select('name author price')

                      Run the application and you should see something similar to the following:

                      [ { _id: 5c2788220a54c304a4a8b0d9, name: 'Node.js Course', author: 'Mosh', price: 20 }, { _id:
                      5c2788220a54c304a4a8b0da, name: 'ASP.NET MVC Course', author: 'Mosh', price: 15 }, { _id:
                      5c2788220a54c304a4a8b0de, name: 'Angular Course', author: 'Mosh', price: 15 }, { _id:
                      5c2788220a54c304a4a8b0dc, name: 'Node.js Course by Jack', author: 'Jack', price: 12 } ]

                      You can see that the most expensive course is displayed first with the other courses sorted by
                      price descending as specified.

                      The other way to write this query is to use the or operator instead of the in operator:

                      async function getCourses() { return await Course // Second solution is to use the or logical
                      query operator .find({isPublished: true}) .or([ {tags: 'frontend'}, {tags: 'backend'}]) .sort({
                      price: -1 }) .select({name: 1, author: 1, price: 1, tags: 1, isPublished: true}); }

                      This should return the exact same result as the first method.

                      97 - Exercise 3 ===============

                      For the third exercise we will get all the published courses that are $15 or more, or have the
                      word 'by' in their title.

                      Again, the code is the same apart from the query in getCourses:

                      async function getCourses() { return await Course .find({ isPublished: true}) .or( [{ name:
                      /.*by.*/i}, { price: {$gte: 15}}]) .sort({ price: -1 }) .select({name: 1, author: 1, price: 1}); }

                      We cannot use a simple value to express a concept like $15 or more:

                      .or([ { price: 15 }])

                      So we use an object that contains key value pairs. Our keys, again, are MongoDB operators ($gte in
                      this case):

                      .or([ { price: { $gte: 15 }}])

                      Our second filter should get the courses that have the word by in their title:

                      .or( [{ name: /.*by.*/i}, { price: {$gte: 15}}])

                      Again we cannot use a simple value because we will then just get courses who's name is "by". We
                      replace the string with a regular expression:

                      /pattern/

                      In regular expressions we use the period to represent a character and the * to represent 0 or
                      more:

                      /.*by.*/

                      This will return 0 or more characters before or after the search criteria "by". We add an i to
                      ensure the search is case insensitive:

                      /.*by.*/i

                      If we run the application we should see something similar to the following:

                      [ { _id: 5c2788220a54c304a4a8b0d9, name: 'Node.js Course', author: 'Mosh', price: 20 }, { _id:
                      5c2788220a54c304a4a8b0da, name: 'ASP.NET MVC Course', author: 'Mosh', price: 15 }, { _id:
                      5c2788220a54c304a4a8b0de, name: 'Angular Course', author: 'Mosh', price: 15 }, { _id:
                      5c2788220a54c304a4a8b0dc, name: 'Node.js Course by Jack', author: 'Jack', price: 12 } ]

                      We get four courses, the first three have a price that is greater than or equal to 15$. The fourth
                      course has the string "by" in the name.

                      98 - Updating Documents Query First ===================================

                      In this lecture we will cover how to update documents in a MongoDB database. Let's create a new
                      async function called updateCourse:

                      async function updateCourse(id) { }

                      updateCourse();

                      This function takes a parameter of the id of the course which we want to update. There are
                      basically two ways to update a document in MongoDB:

                      - Query first - Update first

                      Query first involves the following steps: - find a document - modify it's properties - save the
                      document

                      Update first involves the following steps: - update directly - optionally get the updated document

                      We will look at the second approach in the next lecture. So for Query first update the
                      updateCourse function:

                      Course.findById(id);

                      this returns a promise which we await and store in a constant:

                      const course = await Course.findById(id);

                      We need to check that a course with that id actually exists:

                      if(!course) return;

                      If not we return immediately. However, if a course with that id does exist, we can update the
                      course:

                      course.isPublished = true; course.author = 'Another Author';

                      Another approach involves using the set method instead of setting multiple properties:

                      course.set({ isPublished: true; author: 'Another Author' });

                      Finally we call the save method:

                      const result = await course.save(); console.log(result);

                      The save method returns a promise which we await. We then log it on the console. We can use
                      MongoDB Compass to get a valid Course Id which we can paste into the call to updateCourse:

                      updateCourse('5c2788220a54c304a4a8b0d9');

                      If we run the application you should see something similar to this:

                      Connected to MongoDB... { tags: [], _id: 5ad1fb7a51d9a0bad08426b8, name: 'Node Course', authors: [
                      { _id: 5ad1fb7a51d9a0bad08426b6, name: 'Mosh' }, { _id: 5ad1fb7a51d9a0bad08426b7, name: 'John' }
                      ], __v: 5, date: 2018-12-30T13:02:25.348Z, isPublished: true, author: 'Another Author' }

                      99 - Updating A Document - Update First =======================================

                      In the last lecture you learned about the query first approach to update a document. This approach
                      is useful, if you receive an input from the client and you want to make sure that the update is a
                      valid operation.

                      For example, if the course is already published then perhaps we shouldn't be able to update the
                      Author. To implement this business rule we need to retrieve the course first. Then we can add
                      logic like this:

                      if (course.isPublished) return;

                      However, sometimes you just want to update one or more documents directly in the database. So
                      instead of findById we use the update method:

                      const course = await Course.update({ _id: id });

                      The first argument is a query or filter object. In the example above we pass an id which should
                      return just one document. We can pass something more generic:

                      const course = await Course.update({ isPublished: false });

                      This will update all the courses that are not published.

                      The second argument to the update method is the update object:

                      const course = await Course.update({ _id: id }, {

                      });

                      The update object uses one or more of the MongoDB update operators: $currentDate Sets the value of
                      a field to current date, either as a Date or a Timestamp. $inc Increments the value of the field
                      by the specified amount. $min Only update the field if the specified value is less than the
                      existing field value $max Only update the field if the specified value is greater than the
                      existing field value. $mul Multiplies the value of the field by the specified amount. $rename
                      Renames a field. $set Sets the value of a field in a document. $setOnInsert Sets the value of a
                      field if an update results in an insert of a document. Has no effect on update operations that
                      modify existing documents. $unset Removes the specified field from a document.

                      We will use the set operator in our example:

                      const result = await Course.update({ _id: id }, { $set: { author: 'Mosh', isPublished: false } });

                      With the update method we can update the document directly in the database without retrieving it
                      first.

                      If we run the application you should see something similar to this:

                      { n: 1, nModified: 1, ok: 1 }

                      We can see in the results object that we have modified one object.

                      Sometimes you want to get the document that was updated. For this you can use findByIdAndUpdate
                      instead of update:

                      const course = await Course.findByIdAndUpdate(id , { $set: { author: 'Jack', isPublished: true }
                      });

                      The first argument is an id instead of a query object. We get back a course object so rename the
                      const to course instead of result.

                      If we run this application you should see something like:

                      Connected to MongoDB... { tags: [ 'express', 'backend' ], _id: 5c2788220a54c304a4a8b0d8, date:
                      2018-01-24T21:42:27.388Z, name: 'Express.js Course', author: 'Moshi', isPublished: false, price:
                      10, __v: 0 }

                      The author and the isPublished properties do not reflect the new value. What we get here is the
                      original document before the update operation.

                      To get the updated document you need to pass an option:

                      const course = await Course.findByIdAndUpdate(id , { $set: { author: 'Jason', isPublished: false }
                      }, { new: true });

                      So we add an object with a key of new and a value of true. If we run again we should now see the
                      updated document:

                      Connected to MongoDB... { tags: [ 'express', 'backend' ], _id: 5c2788220a54c304a4a8b0d8, date:
                      2018-01-24T21:42:27.388Z, name: 'Express.js Course', author: 'Jason', isPublished: false, price:
                      10, __v: 0 }

                      100 - Removing Documents ========================

                      Copy the code from the previous lecture and rename the updateCourse method removeCourse:

                      async function removeCourse(id) { const result = await Console.deleteOne({ _id: id });
                      console.log(result); }

                      The deletOne method will only ever delete one document. So if you specify a more generic query
                      then only the first document that matches the query will be deleted.

                      If you run the application you should see something like this:

                      { n: 1, ok: 1 }

                      The result object shows we have deleted one document.

                      If you want to delete multiple documents, instead of delete one use delete many:

                      async function removeCourse(id) { const result = await Course.deleteMany({ isPublished: true });
                      console.log(result); }

                      This method also returns a result object that shows us the number of documents that were deleted.

                      If you want to get the document that was deleted we use another method:

                      const course = await Course.findByIdAndRemove(id);

                      If the document has already been deleted this method will return null.

                      101 - Recap ===========

                      CRUD Operations using Mongoose and MongoDB ------------------------------------------

                      So, in this section, you learned that:

                      - MongoDB is an open-source document database. It stores data in flexible, JSONlike documents. -
                      In relational databases we have tables and rows, in MongoDB we have collections and documents. A
                      document can contain sub-documents. - We don’t have relationships between documents. - To connect
                      to MongoDB:

                      Connecting to MongoDB --------------------- const mongoose = require(‘mongoose’);
                      mongoose.connect(‘mongodb://localhost/playground') .then(() => console.log(‘Connected…’))
                      .catch(err => console.error(‘Connection failed…’));

                      - To store objects in MongoDB, we need to define a Mongoose schema first. The schema defines the
                      shape of documents in MongoDB.

                      Defining a schema ----------------- const courseSchema = new mongoose.Schema({ name: String,
                      price: Number });

                      - We can use a SchemaType object to provide additional details:

                      Using a SchemaType object ------------------------- const courseSchema = new mongoose.Schema({
                      isPublished: { type: Boolean, default: false } });

                      - Supported types are: String, Number, Date, Buffer (for storing binary data), Boolean and
                      ObjectID. - Once we have a schema, we need to compile it into a model. A model is like a class.
                      It’s a blueprint for creating objects:

                      Creating a model ---------------- const Course = mongoose.model(‘Course’, courseSchema);

                      CRUD Operations ---------------

                      Saving a document -----------------

                      let course = new Course({ name: ‘…’ }); course = await course.save();

                      Querying documents ------------------

                      const courses = await Course .find({ author: ‘Mosh’, isPublished: true }) .skip(10) .limit(10)
                      .sort({ name: 1, price: -1 }) .select({ name: 1, price: 1 });

                      Updating a document (query first) ---------------------------------

                      const course = await Course.findById(id); if (!course) return; course.set({ name: ‘…’ });
                      course.save();

                      Updating a document (update first) ----------------------------------

                      const result = await Course.update({ _id: id }, { $set: { name: ‘…’ } });

                      Updating a document (update first) and return it ------------------------------------------------

                      const result = await Course.findByIdAndUpdate({ _id: id }, { $set: { name: ‘…’ } }, { new: true
                      });

                      Removing a document -------------------

                      const result = await Course.deleteOne({ _id: id }); const result = await Course.deleteMany({ _id:
                      id }); const course = await Course.findByIdAndRemove(id);


                      Section 8 Mongoose - Data Validation ====================================

                      102 - Validation ================

                      This is the course schema that we defined earlier in this section:

                      const courseSchema = new mongoose.Schema({ name: { type: String, required: true }, author: String,
                      tags: [ String ], date: { type: Date, default: Date.now }, isPublished: Boolean, price: Number });

                      By default all the properties that we defined above are optional. So if I create course and leave
                      out all the properties:

                      const course = new Course({ });

                      And then save that course to the database then that would be a perfectly valid operation.

                      Currently MongoDB doesn't care if we add a course without a name or price. In this lecture we will
                      see how to add validation.

                      Let's make the name required:

                      const courseSchema = new mongoose.Schema({ name: { type: String, required: true }, author: String,
                      tags: [ String ], date: { type: Date, default: Date.now }, isPublished: Boolean, price: Number });

                      First we replace the String definition with an object. We set the type to String and required to
                      true.

                      Now if we create a course without a name and try to save the course in the database we will
                      receive an exception:

                      (node:19536) UnhandledPromiseRejectionWarning: ValidationError: Course validation failed: name:
                      Path `name` is required.

                      This means that the promise was rejected but the rejection has not been handled. Remember that
                      promises can be in three states:

                      - pending - fulfilled - rejected

                      We can add a try/catch block to handle the rejection:

                      try { const result = await course.save(); console.log(result); } catch (ex) {
                      console.log(ex.message); }

                      Now if you run the application you should see the following:

                      Course validation failed: name: Path `name` is required. Connected to MongoDB...

                      So MongoDB doesn't allow us to save invalid course objects to the database - validation kicks at
                      the point we try and save our course to the database.

                      We can also manually trigger validation:

                      try { await course.validate(); } catch (ex) { console.log(ex.message); }

                      The validate method returns a promise of void so we can await the validate method. If our course
                      is invalid we will get an exception and end up in the catch block.

                      Running the application should return the same result:

                      Course validation failed: name: Path `name` is required. Connected to MongoDB...

                      The problem with the validate method returning a promise of void is that we don't get any result.
                      Ideally the validate method would return a boolean so we could write something like this:

                      try { const isValid = await course.validate(); if (!isValid) { } } catch (ex) {
                      console.log(ex.message); }

                      The only option you have to get that kind of boolean is to pass a callback to the validate method:

                      try { course.validate((err) => { if (err) { console.log('Validation failed.'); } }); } catch (ex)
                      { console.log(ex.message); }

                      We pass a function that takes an error object then we can execute some logic if we find any
                      errors.

                      So, if we return back to our original code:

                      try { //await course.validate(); const result = await course.save(); console.log(result); } catch
                      (ex) { console.log(ex.message); }

                      One thing to validate here is that this validation that we implemented on the name property:

                      name: { type: String, required: true },

                      is only meaningful in mongoose. MongoDB doesn't care about this name property. So if you have
                      worked with databases like SQL Server or MySQL you know that in these database we can define
                      validation at the database level.

                      In MongoDB we can't specify required fields at the database level - this logic is only meaningful
                      in Mongoose. At the time we try and save the course Mongoose runs the validation logic and if the
                      course is not valid Mongoose prevents it being saved to the database.

                      One last point of clarification. Earlier in the section about express we looked at a validation
                      package called Joi. We used Joi for validation so you might be asking why we have two kinds of
                      validation. The two types of validation complement each other. We use Joi in our restful APIs to
                      make sure the data that the client is sending is valid data. However, we still need the Mongoose
                      validation to make sure that the data saved in the database is in the right shape.

                      It is possible that the client sends us a valid course in the body of the request, but when we
                      create a course object in our Http service we may, for example, forget the name property to what
                      we get from req.body.name:

                      name: 'Angular Course', // req.body.name

                      So by enforcing validation in Mongoose we can ensure that programming errors like the one
                      described above will not result in invalid documents being persisted in a MongoDB database.

                      103 - Built-in Validators =========================

                      In the last lecture we learned about the required validator which is one of the built-in
                      validators in Mongoose. In this lecture we will examine the built-in validators in more detail.

                      The required property can be set to a boolean or a function that returns a boolean. This is useful
                      when you want to conditionally make a property required or not. To demonstrate, let's imagine that
                      price is only required if the course is published:

                      price: { type: Number, required: function() { return this.isPublished; }, }

                      First we replace Number with an object, set the type to number. Add the required property and
                      specify a function. If publised is true then the price will be required.

                      For clarification, we cannot replace the function we specified above with an arrow function:

                      required: () => { return this.isPublished; },

                      This is because arrow functions don't have their own this. Arrow functions use the this value of
                      the enclosing execution context. In this particular context, there will be a function somewhere in
                      the Mongoose module that will call this function:

                      () => { return this.isPublished; },

                      The this reference above will reference that function not the course object.

                      Now, let's comment out the name and price properties and test the application:

                      Course validation failed: price: Path `price` is required., name: Path `name` is required.

                      The validation message is returned as a simple string.

                      Depending on the type of properties defined in your schema you will have different properties
                      available. For example, with strings you also have minlength, maxlength and match.

                      name: { type: String, required: true, minglength: 5, maxlength: 255, // match: /pattern/ },

                      match allows you to pass a regular expression (not really relevant for the name of a course)

                      Another useful validator we have for strings is enum. To demonstrate add another property called
                      category:

                      category: { type: String, required: true, enum: ['web', 'mobile', 'network'] },

                      We set the enum validator to an array of valid strings. When we create a course the category will
                      have to be set to one of these categories otherwise we will receive a validation error.

                      Add category to to the course object:

                      category: '-'

                      If we reinstate the name and price properties in the course object and then run the application
                      you will see:

                      Course validation failed: category: `-` is not a valid enum value for path `category`.

                      104 - Custom Validators =======================

                      Sometimes the built-in validators in Mongoose don't give us the kind of validation that we need.

                      For example, look at the tags property:

                      tags: [ String ],

                      tags is a string array. What if we want to enforce a rule that every course should have at least
                      one tag. We cannot use the required validator here because with required you can simply pass an
                      empty array and that would be perfectly valid from Mongooses point of view.

                      Here we need a custom validator. First replace the tags String definition with an object:

                      tags: { type: Array, validate: { validator: function(v) { return v.length > 0; }, message: 'A
                      course should have at least one tag.' } },

                      We set the type to Array. Then we define a custom validator. We set the validate property to a an
                      object. In this object we define a property called validator which we set to a function. This
                      function takes an argument v (short for value). We define the custom validator logic inside this
                      function:

                      return v.length > 0;

                      We define a message property.

                      Set a valid category and then change the tags property to pass an empty array:

                      tags: [], // empty array

                      Test the application:

                      A course should have at least one tag.

                      If we exclude the tags property altogether:

                      // tags: [], // empty array

                      Test the application:

                      A course should have at least one tag.

                      We get the same message. If we don't set the tags property then because it's type is defined as
                      array Mongoose will initialize this to an empty array.

                      Set the tags property to null:

                      Cannot read property 'length' of null

                      Ths is not the kind of validation message we want to get. To remedy this we need to modify our
                      validation logic:

                      return v && v.length > 0;

                      Now the property will only be classed as valid when v has a value with a length greater than 0.

                      105 - Async Validators ======================

                      Sometimes the validation logic may involve getting something from a database or from a remote http
                      service. In that case we need an async validator.

                      To convert our synchronous tags validator to an asynchronous one we first set the isAsync property
                      to true:

                      tags: { type: Array, validate: { isAsync: true, validator: function(v, callback) { setTimeout(()
                      => { // Do some async work const result = v && v.length > 0; callback(result); }, 4000); return v
                      && v.length > 0; }, message: 'A course should have at least one tag.' } },

                      We change the signature of the method we supply to the validator property by adding a second
                      argument of a callback.

                      Remember, in the section about asynchronous JavaScript, you learned that one of the simplest
                      approaches to deal with asynchronous code is to use a callback.

                      In this function we use the setTimeout function to simulate an async operation. So, at some point,
                      we will receive the result:

                      const result = v && v.length > 0;

                      In this demo we use the same logic as used previously. In a real world scenario the result would
                      be calculated based on the value that you get from your file system, database or remote service.

                      Finally we call the callback function with the result.

                      Test the application:

                      A course should have at least one tag.

                      We get a delay of 4 seconds before we see the validation message.

                      106 - Validation Errors =======================

                      So far we have only displayed a simple message about our validation error. In this lecture we will
                      examine the error object in more detail.

                      The exception we get in the catch block has a property called errors which provides a separate
                      property for each invalid property in our course object. Currently in our course object we have
                      two invalid properties - category and tags:

                      const course = new Course({ name: 'Angular Course', category: '-', author: 'Mosh', tags: null, //
                      tags property set to null isPublished: true, price: 15 });

                      With this the errors object will have two properties tags and categories. We can iterate over all
                      the properties in this error object and get more details about each validation error:

                      for(field in ex.errors) console.log(ex.errors[field]);

                      Test the application:

                      { ValidatorError: `-` is not a valid enum value for path `category`.

                      Below the Validation Error we see the stack trace. The validation error objects contain the
                      following properties:

                      - message - name - properties properties gives us information about the validation requirements
                      for this property. Using the category property as an example: - validator Gives us access to our
                      validator function - type The type of this validator is enum - enumValues 'web', 'mobile',
                      'network' - path The name of our property - in this case category - value The current value - kind
                      a shortcut to properties.type - enum in this example - path category - value the current value for
                      this property. '-' in this example.

                      So here:

                      for(field in ex.errors) console.log(ex.errors[field]);

                      We are iterating over these validation error objects and we have multiple validation error objects
                      - category and tag.

                      If you want to get the validation message for each invalid property you simply access the message
                      property:

                      for(field in ex.errors) console.log(ex.errors[field].message);

                      Run the application again:

                      `-` is not a valid enum value for path `category`. A course should have at least one tag.

                      107 - Schema Type Options =========================

                      When defining a schema we've learned that we can set the type of the property directly:

                      author: String,

                      or use a schema type object:

                      category: { type: String, required: true, enum: ['web', 'mobile', 'network'] },

                      This object has a few properties which we covered in the last section (type, required, enum etc.)
                      In this lecture we will cover a few more useful properties that are available on schema type
                      objects.

                      For strings we have three additional properties that you can use. Using the category property as
                      an example.

                      Lowercase. When set to true Mongoose will automatically convert the property to lowercase:

                      category: { type: String, required: true, enum: ['web', 'mobile', 'network'], lowercase: true,
                      trim: true },

                      If we set the category to Web:

                      async function createCourse() { const course = new Course({ name: 'Angular Course', category:
                      'Web', // uppercase W author: 'Mosh', tags: ['frontend'], isPublished: true, price: 15.8 });

                      Run the application (you might need to create a course with a category first):

                      { tags: [ 'One tag' ], _id: 5c2a65812b5c35126c84f186, name: 'Angular Course', category: 'web',
                      price: 15 }

                      Look at the category - you have a lowercase web. You also have uppercase. Finally you have trim
                      which will automatically remove any paddings we have around our string.

                      We have another couple of schema type object properties which can be used irrespective of the type
                      of property you are working with. For example, lets say we always want to round the value of our
                      price property:

                      price: { type: Number, required: function() { return this.isPublished; }, min: 10, max: 200, get:
                      v => Math.round(v), set: v => Math.round(v) }

                      We define a custom getter and setter. We pass an arrow function that takes v for value as an
                      argument. Now we define our custom logic for getting this value. So we can apply Math.round to
                      round the value. We pass a similar function in the setter.

                      If we now set our price to a decimal:

                      async function createCourse() { const course = new Course({ name: 'Angular Course', category:
                      'Web', // uppercase W author: 'Mosh', tags: ['frontend'], isPublished: true, price: 15.8 });

                      Run the application:

                      { tags: [ 'frontend' ], date: 2018-12-31T19:54:27.482Z, _id: 5c2a73f354daee1cd461fe1e, name:
                      'Angular Course', category: 'web', author: 'Mosh', isPublished: true, price: 16, __v: 0 }

                      We create a new course object and the price is set to 16. This is because when we set the price
                      value in our createCourse method the custom setter was called which rounded the value. If you look
                      at the last course document in Compass you should see the price is set to 16:

                      //TODO fig xx-xx

                      Edit the type of the property to Double and modify the value to 15.8. Here we are simulating a
                      scenario where we have a document that was stored in the database before we implemented the
                      rounding logic.

                      In this case if you read the courses and access the price property our custom getter will be
                      called and the value will be rounded.

                      Modify getCourses to find the id of the course you just created:

                      async function getCourses() { // Make sure you provide an _id for a Course that has a category
                      const courses = await Course .find({ _id: '5c2a73f354daee1cd461fe1e'}) .sort( { name: 1}) .select(
                      { name: 1, category: 1, tags: 1, price: 1});

                      console.log(courses[0].price); }

                      If you read the price property specifically:

                      console.log(courses[0].price);

                      And run the application you will see the price property is rounded:

                      16

                      Note if you return the whole course object:

                      console.log(courses[0]);

                      the price DOES not get rounded:

                      { tags: [ 'frontend' ], _id: 5c2a73f354daee1cd461fe1e, name: 'Angular Course', category: 'web',
                      price: 15.8 }

                      108 - Project Add Persistence to Genres API ===========================================

                      Now we will go back to our vidly project. Earlier in the course we built the genres module. In the
                      module we used an array to keep all the genres in our application (54 - Project Build the Genres
                      API):

                      const genres = [ { id: 1, name: 'Horror' }, { id: 2, name: 'Comedy' }, { id: 3, name: 'Thriller'
                      }, { id: 3, name: 'Sci-Fi' } ];

                      Now that you know how to use MongoDB and Mongoose I want you to remove the array and modify the
                      route handlers (get, post etc.) to work with our MongoDB database.

                      Solution --------

                      I got the previous project from 68 - Project - Restructure the App

                      First install Mongoose:

                      npm i mongoose

                      Back in the code we need to connect to MongoDB. However we don't want to make the connection in
                      genres.js because that is something we can do once at the application level. The genres.js module
                      is purely responsible for our genres api. In this application in the future we are going to have
                      more APIs for working with videos, rentals etc. We don't want to connect with MongoDB multiple
                      times. We connect once when the application starts.

                      So in index.js load mongoose:

                      const mongoose = require('mongoose');

                      Then connect to MongoDB passing the connection string:

                      mongoose.connect('mongodb://localhost/vidly') .then(() => console.log('Connected to MongoDB'))
                      .catch(err => console.error('Could not connect to MongoDB...'));

                      The connect method returns a promise. If the connection is resolved we display a message on the
                      console. If it is not we catch an error.

                      Back in the genres module we also load mongoose:

                      const mongoose = require('mongoose');

                      Ok so now we have to define a schema for our genres:

                      const genreSchema = new mongoose.Schema({ name: { type: String, required: true, minlength: 5,
                      maxlength: 50 } });

                      The database is going to manage the id property so we just need the name property here. We provide
                      a schema type object with a type of String, required to true and a minlength/maxlength.

                      Now that we have a schema we need to create a model:

                      const Genre = new mongoose.model('Genre', genreSchema);

                      We pass the collection we want to work with - Genre in it's singular form. Then we pass the
                      schema. This is the only place in our code where we have referenced genreSchema so technically we
                      don't really need a separate constant to store the schema. We can move the schema definition
                      inside the model method:

                      const Genre = new mongoose.model('Genre', new mongoose.Schema({ name: { type: String, required:
                      true, minlength: 5, maxlength: 50 } }));

                      This makes our code a little bit cleaner.

                      Now that we have a model we can get rid of the genres array:

                      const genres = [ { id: 1, name: 'Action' }, { id: 2, name: 'Horror' }, { id: 3, name: 'Romance' },
                      ];

                      Our first route is the get route. Here we should return all the genres in our database:

                      router.get('/', async (req, res) => { const genres = await Genre.find().sort('name');
                      res.send(genres); });

                      We set genres to Genre.find(). This returns a promise which we await. We also mark the function as
                      async.

                      In this implementation we could remove the constant add the Genre.find() method here:

                      res.send(await Genre.find());

                      However, some people prefer to have the separate constant, because they think it makes the code
                      more readable.

                      Next, let's work on our post route handler. Here, currently, we are creating a genre object:

                      const genre = { id: genres.length + 1, name: req.body.name };

                      We set the genre to a new Genre model and then pass the object to initialize our genre. We don't
                      need to supply an id any longer because this is now handled by the database:

                      const genre = new Genre({ name: req.body.name });

                      Now we need to save the genre object to the database. Instead of pushing it into an array:

                      genres.push(genre);

                      We call genre.save() which returns a promise which we await. The result we get is the actual genre
                      document that is saved in the database. This document contains the id property, which we want to
                      return to the client. To achieve this we change the genre declaration from a const to a let:

                      let genre = new Genre({ name: req.body.name });

                      and then we can reset genre:

                      genre = await genre.save();

                      Here we are using the async method so we need to mark our route as async:

                      router.post('/', async (req, res) => {

                      We can then return genre to the client:

                      res.send(genre);

                      The next route handler is the put method. First we need to find the genre, if it is not found we
                      need to return a 404 error, then we need to validate the object that we receive from the client,
                      if the object is valid we can update the genre.

                      In this scenario we can use the query first or update first approach. In this lecture we will use
                      the update first approach:

                      router.put('/:id', async (req, res) => { const genre = await
                      Genre.findByIdAndUpdate(req.params.id, { name: req.body.name }, { new: true });

                      We call findByIdAndUpdate passing the first argument of req.params.id and the second argument of
                      our update object where we set name to req.body.name. Finally our third argument is the options
                      object where we set new to true which will get the updated object from the database. We await the
                      promise returned by findByIdAndUpdate, get the result and store it in the genre const. We mark the
                      function as async because we have used await here.

                      If don't have a genre we need to return an array so we remove the line that finds the genre in an
                      array:

                      const genre = genres.find(c => c.id === parseInt(req.params.id));

                      But keep the line that returns the 404 error if we don't have a genre:

                      if (!genre) return res.status(404).send('The genre with the given ID was not found.');

                      With this new implementation we need to move these two lines:

                      const { error } = validateGenre(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      We need to validate this genre that we're getting in the request before attempting to update the
                      database.

                      We can also remove this property:

                      genre.name = req.body.name;

                      The genre we now have is the update genre.

                      Let's move onto the delete route handler where will use a similar approach:

                      const genre = await Genre.findByIdAndRemove(req.params.id);

                      We use Genre.findByIdAndRemove passing the req.params.id. We get a promise which we await and
                      store in a const. Because we have used await we set the method to async:

                      router.delete('/:id', async (req, res) => {

                      We no longer need to look up a genre in an array:

                      const genre = genres.find(c => c.id === parseInt(req.params.id));

                      We retain the line to return a 404 if no genre is found:

                      if (!genre) return res.status(404).send('The genre with the given ID was not found.');

                      We can remove the next two lines because we are no longer working with an array:

                      const index = genres.indexOf(genre); genres.splice(index, 1);

                      Finally, if we delete the genre successfully, we will return the genre to the client:

                      res.send(genre);

                      The last route handler is get where get a single genre:

                      const genre = await Genre.findById(req.params.id);

                      Because we have used await we mark the method as async:

                      router.get('/:id', async (req, res) => {

                      We remove the line to look up the genre in the genres array:

                      const genre = genres.find(c => c.id === parseInt(req.params.id));

                      If we don't have a genre we return a 404 error:

                      if (!genre) return res.status(404).send('The genre with the given ID was not found.');

                      otherwise we return the genre object to the client:

                      res.send(genre);

                      Now run the application.

                      TypeError: Cannot read property 'Genre' of undefined


                      This error is due to the new keyword here:

                      const Genre = new mongoose.model('Genre', new mongoose.Schema({ name: { type: String, required:
                      true, minlength: 5, maxlength: 50 } }));

                      This is not a Class it is a method:

                      const Genre = mongoose.model('Genre', new mongoose.Schema({ name: { type: String, required: true,
                      minlength: 5, maxlength: 50 } }));

                      Rerun the application:

                      Listening on port 3000... Connected to MongoDB

                      In postman send a get request to our Genres:

                      //TODO fig xx-xx

                      Currently because we don't have any genres in our database we get an empty array.

                      Use a post request to create a new Genre.

                      If you get the following error:

                      (node:3388) UnhandledPromiseRejectionWarning: ReferenceError: Joi is not defined

                      It may be that you need to load Joi in the genres module instead of index.js

                      Resend the Post request in Postman and you should get a 200 response along with the document that
                      was created in MongoDB:

                      { "_id": "5c2bad1b29c84b2e60b33f54", "name": "Thrilleerrrr", "__v": 0 }

                      You get the id that is generated by MongoDB along with __v which is the version coming from Mongo.
                      If you don't want to return this to the client you can simply exclude it from the genre object.

                      New use Postman to get all the genres in the database.

                      Now issue a Put request in Postman to update the name of a genre:

                      http://localhost:3000/api/genres/5c2bad1b29c84b2e60b33f54

                      You should see the following:

                      { "_id": "5c2bad1b29c84b2e60b33f54", "name": "Filleerrrr", "__v": 0 }

                      If you specify an invalid name:

                      { "name": "" }

                      You should receive a validation error along with a 400 Bad Request:

                      "name" is not allowed to be empty

                      Also if you specify an id that doesn't exist you should receive the message:

                      The genre with the given ID was not found.

                      Finally test the Delete request and you should see the following response:

                      { "_id": "5c2bad1b29c84b2e60b33f54", "name": "Filleerrrr", "__v": 0 }

                      109 - Project Build Customers API =================================

                      The second exercise is to build an endpoint to manage the customers. And this is the shape of our
                      Customer object:

                      - isGold Boolean - name String - phone String

                      Solution --------

                      In the routes folder add a new file called customer.js. In this module we are going to implement
                      all the routes for working with customers.

                      In index.js we need to load the customers module:

                      const customers = require('./routes/customers');

                      Now we tell express that wherever we have a route that starts with /api/customers you need to
                      delegate the handling of those routes to this customers router that we get from the customers
                      module:

                      app.use('/api/customers', customers);

                      We can see that, with the current structure, we don't pollute index.js with all the details of
                      various routes in our application. We are encapsulating the related routes inside modules. So in
                      the customers we will need similar code to what we have in the genres module. We can copy over
                      alot of the code from genres to customers and modify the relevant portions of code:

                      const Joi = require('joi'); const mongoose = require('mongoose'); const express =
                      require('express'); const router = express.Router();

                      const Genre = mongoose.model('Genre', new mongoose.Schema({ name: { type: String, required: true,
                      minlength: 5, maxlength: 50 } }));


                      router.get('/', async (req, res) => { const genres = await Genre.find().sort('name');
                      res.send(genres); });

                      router.post('/', async (req, res) => { const { error } = validateGenre(req.body); if (error)
                      return res.status(400).send(error.details[0].message);

                      let genre = new Genre({ name: req.body.name }); genre = await genre.save();

                      res.send(genre); });

                      At the end export the router:

                      module.exports = router;

                      Now let's tailor the code for customers instead of genres. All our require statements remain the
                      same.

                      We need to define a new model:

                      const Customer = mongoose.model('Customer', new mongoose.Schema({ name: { type: String, required:
                      true, minlength: 5, maxlength: 50 }, isGold: { type: Boolean, default: false }, name: { type:
                      String, required: true, minlength: 5, maxlength: 50 } }));

                      Now we can move onto the route handlers. Our first route handler should get all the customers:

                      router.get('/', async (req, res) => { const customers = await Customer.find().sort('name');
                      res.send(customers); });

                      Now the second route handler for posting a new customer:

                      router.post('/', async (req, res) => { const { error } = validateCustomer(req.body); if (error)
                      return res.status(400).send(error.details[0].message);

                      let customer = new Customer({ name: req.body.name, phone: req.body.phone, isGold: req.body.isGold
                      }); customer = await customer.save();

                      res.send(customer); });

                      When posting a new customer we have to validate it so we will also need a validateCustomer
                      function. We can also copy this from genres as well and make some modifications:

                      function validateCustomer(customer) { const schema = { name:
                      Joi.string().min(5).max(50).required(), phone: Joi.string().min(5).max(50).required(), isGold:
                      Joi.boolean() };

                      return Joi.validate(customer, schema); }

                      You might argue here that we have some kind of duplication because we have a schema for Joi
                      validation and we have also defined a schema for Mongoose validation. In my opinion there is no
                      point refactoring the code to get rid of the duplication because the requirements for the
                      properties do not change often enough to warrant the work.

                      Now modify the other route handlers to complete the customers module.

                      110 - Restructuring the Project ===============================

                      If you look at the customers module as it currently stands you can see the definition of the
                      Customer model, then our route handlers, then the validateCustomer function.

                      If you look at the definition of the Customer model you can see it is not a big complex module -
                      this would not be the case in a real world application. So chances are, in the real world, the
                      code in this module will grow. to keep our applications maintainable we need to ensure that each
                      module is responsible for only one thing - the single responsibility principle in practice.

                      In this application the customers module that we have is part of the routes module. Technically
                      all we should have in the customer module is the definition of our Customers routes. The
                      definition of the Customer model doesn't really belong in this module.

                      We need to extract this code and put it elsewhere. Create a models folder. We will use this to
                      store modules like customer.js, genres.js etc.

                      Add a new file called customers.js and move the Customer model definition into our new file in the
                      models folder. You will also need to add require statements for the dependencies to Joi and
                      Mongoose:

                      const Joi = require('joi'); const mongoose = require('mongoose');

                      const Customer = mongoose.model('Customer', new mongoose.Schema({ name: { type: String, required:
                      true, minlength: 5, maxlength: 50 }, isGold: { type: Boolean, default: false }, name: { type:
                      String, required: true, minlength: 5, maxlength: 50 } }));

                      You can also move the function for validating a Customer into customer.js

                      function validateCustomer(customer) { const schema = { name:
                      Joi.string().min(5).max(50).required(), phone: Joi.string().min(5).max(50).required(), isGold:
                      Joi.boolean() };

                      return Joi.validate(customer, schema); }

                      So now we have the single responsibility principle in practice. Our customer module has all the
                      code for defining and validating a customer object. Our customers.js module knows all about
                      various routes to work with customers. That means we no longer to load Joi as the responsibility
                      of validating a customer has been moved to customer.js

                      Finally at the end of the module we need to export the customer class as well as the
                      validateCustomer function:

                      module.exports.Customer = Customer;

                      A shorter way is to simply use the exports property:

                      exports.Customer = Customer;

                      So earlier we discussed that exports is a reference to module.exports. So we can simply add extra
                      properties in that object.

                      Similarly we need to export the validateCustomer function. We can make the name shorter (validate
                      instead of validateCustomer):

                      exports.validate = validateCustomer;

                      Now back in the old customers.js module we have two choices. One is to load the customer module
                      like this:

                      const customer = require('../models/customer');

                      This customer module has two properties - Customer and validate. If we use the approach above to
                      load the customer module then when we want to reference the customer type or model we have to
                      write code like this:

                      const customer = await customer.Customer.find().sort('name');

                      This is quite ugly. A better approach is to use object destructuring. This object that is returned
                      from loading this module has two properties - Customer and validate. We can destructure the object
                      and load it into two constants:

                      const { Customer, validate } = require('../models/customer');

                      So we add curly braces when defining the constant so now the Customer const will be set to what is
                      returned from this module .Customer. This means you don't have to repeat .Customer in several
                      places.

                      Similarly the validate property will be set to what is returned from the module .validate.

                      Finally we need to replace the two calls to validateCustomer with validate (our shorter name).

                      If you now look at the number of lines of code we have in this module it is a lot shorter.

                      As an exercise modify the genres module to extract the model and put it in a separate module.

                      111 - Recap ===========

                      Mongoose: Validation -------------------- So, in this section, you learned that:

                      - When defining a schema, you can set the type of a property to a SchemaType object. You use this
                      object to define the validation requirements for the given property.


                      // Adding validation new mongoose.Schema({ name: { type: String, required: true } }) - Validation
                      logic is executed by Mongoose prior to saving a document to the database. You can also trigger it
                      manually by calling the validate() method. - Built-in validators: - Strings: minlength, maxlength,
                      match, enum - Numbers: min, max - Dates: min, max - All types: required

                      // Custom validation tags: [ type: Array, validate: { validator: function(v) { return v &&
                      v.length > 0; }, message: ‘A course should have at least 1 tag.’ } ]

                      - If you need to talk to a database or a remote service to perform the validation, you need to
                      create an async validator:

                      validate: { isAsync: true validator: function(v, callback) { // Do the validation, when the result
                      is ready, call the callback callback(isValid); } }

                      - Other useful SchemaType properties: - Strings: lowercase, uppercase, trim - All types: get, set
                      (to define a custom getter/setter)

                      price: { type: Number, get: v => Math.round(v), set: v => Math.round(v) }

                      Section 9 - Mongoose- Modeling Relationships Between Connected Data
                      ===================================================================

                      112 - Modelling Relationships =============================

                      So in all the examples we have looked at so far we have worked with single, self-contained
                      documents. In the real world, the entities and concepts that we work with, they have some kind of
                      association. For example, you can have a Course object or document and of course this course has
                      an author. But the Author is more than just a name - it's more than just a simple string.

                      You might have a collection of Authors where we store author documents. In each author document we
                      could have properties like name, website, image etc. In this lecture we will discuss how to work
                      with related objects. There are two approaches:

                      - Using References (Normalization) - Using Embedded Documents (De-normalization)

                      With the first approach, references, we have a separate collection for storing our Authors. So we
                      can have an Author object like this:

                      let author = { name: 'Mosh' }

                      We can add various properties in the author object and then we would have a separate collection
                      where we store course objects like this:

                      let course = { author: 'id' }

                      So here we have a course object. We set the author to the id of an author document in the authors
                      collection. So here we are using a reference.

                      For clarification, in relational databases, we have this concept of relationships which enforces
                      data integrity. However in MongoDB or NoSQL databases in general, we don't really have a
                      relationship. So even though I'm setting the ID of an author here there is actually no association
                      or relationship between the author and course object in the database. This means it is possible to
                      set the author's id property to something invalid and MonoDB doesn't care about that.

                      Now we could take this example to the next level by saying that a course might have multiple
                      authors. So instead of the author property we could have authors which we set to an array of
                      references where we store multiple id's:

                      let course = { author: 'id', authors: [ 'id1', 'id2' ] }

                      However, for simplicity, let's just work with a single author:

                      let course = { author: 'id' }

                      The other approach is to use embedded documents or de-normalization. We can embed an author
                      document inside of a course document. So here we can have a course object or document and in this
                      document we have the author property which we set to an object:

                      let course = { author: { name: 'Mosh' } }

                      The object will contain all the properties relevant to an Author. So we are embedding a document
                      inside of another document. This is called de-normalization. If you have never worked with NoSQL
                      databases before and you come from a relational database background, you may think that the first
                      approach is the way to go. However, that is not necessarily the case when working with NoSQL
                      databases - each approach has it's strength and weaknesses. What approach you choose really
                      depends on your application and it's querying requirements.

                      So basically, you need to do a trade-off between query performance versus consistency. With the
                      first approach (references or normalization) you have a single place to define an author. If
                      tomorrow, I decide to change the name of this author from Mosh to Mosh Hamedani, there is a single
                      place that I need to modify. All courses that are referencing that author will automatically see
                      the update.

                      This means the first approach provides consistency. However, every time we want to query a course
                      we need to do an extra query to load the related author. Sometimes that extra query may not be a
                      big deal but in certain situations you might want to make sure a query runs as fast as possible.
                      If that's the case you need to look at the second approach - using embedded documents.

                      With this approach we can load a course object and it's author using a single query because the
                      author is embedded inside the course object or the course document. However, with this approach,
                      if tomorrow I decide to change the name of this author from Mosh to Mosh Hamedani then the chances
                      are there will be multiple course documents that need to be updated. If our update operation
                      doesn't complete successfully, it is possible that we wil have some course documents that are not
                      updated. This will result in inconsistent data.

                      So, in every part of your application, you will need to think about the queries that you will run
                      ahead of time. You will design your database based on those queries.

                      There is a third approach, known as the hybrid approach. Imagine, for example, that each author
                      has 50 properties. We don't want duplicate all those properties inside every course in database.
                      So we can have a separate collection of authors, but instead of using a reference here, we can
                      embed an author document inside of a course document but not the complete representation for that
                      author. So, with the hybrid approach, our database will look like this:

                      // Hybrid let author = { name: 'Mosh' // 50 other properties }

                      Now we have a separate collection of courses. In this collection we'll have course documents like
                      this:

                      let course = { author: { id: 'ref', // Reference to an author document name: 'Mosh' // Only embed
                      a subset of properties - not the complete representation of an author document } }

                      The id property is a reference to an author document. The name property is the name of the author
                      as a string and is embedded into the course document. With this approach we can quickly read a
                      course object, along with it's author, so we can optimize our query performance but we don't have
                      to store all the properties of an author inside a course document.

                      This approach is particularly useful if you want to have a snapshot of your data at a point in
                      time. For example, imagine you were designing an e-commerce site. There we will have collections
                      like orders, products, shopping carts and so on. In each order, we need to store the snapshot of a
                      product, because we want to know the price of that product at a given point in time. That's where
                      the hybrid approach is useful.

                      So, again, which approach you use really depends on the application you are building - there is no
                      right or wrong. Each approach has it's strength and weaknesses.

                      113 - Referencing Documents ===========================

                      In this lecture, we will discuss how to reference a document in another document. The demo code
                      contains two modules. The first is author with three properties:

                      - name - bio - website

                      The other is course with one property:

                      - name

                      In this lecture we will add another property - author where we will reference an author document.
                      We also have a few helper functions: - createAuthor - createCourse - listCourses

                      All these functions are similar to what you have seen earlier in this section - so there is
                      nothing new here.

                      Now before getting started go to MongoDB compass and delete the playground database so we can
                      start on a clean canvas.

                      At the bottom of index.js you can see we have a call to the creatAuthor function.

                      createAuthor('Mosh', 'My bio', 'My Website');

                      Run the application:

                      Connected to MongoDB... { _id: 5c33787f925b1d69c861529e, name: 'Node Course', author:
                      5ad1e8e7d8773c8828a03c3b, __v: 0 }

                      So we created one Author - you can see the id above. Now let's copy this and then back in the code
                      comment out the call to createAuthor and enable createCourse pasting in the id from above:

                      createCourse('Node Course', '5c33787f925b1d69c861529e');

                      If you look at the implementation of this function we create a course object with two properties:

                      - name - author

                      Save the file, and back in the terminal run the application again:

                      Connected to MongoDB... { _id: 5c338a931514bb0cc4f07ae0, name: 'Node Course' __v: 0 }

                      This has created a course object - you can see the id and name above but we don't have an author.
                      The reason for this is because when we defined this course model we only added the name property:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String } }));

                      So when saving a course object, only the properties that you have defined in your model will be
                      persisted in the database. So here, in our model, we need to add another property author:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: { type:
                      mongoose.Schema.Types.ObjectId, ref: 'Author' } }));

                      We set this to a schema type object. The type of this property should be ObjectId. So we use
                      mongoose.Schema.Types.ObjectId. We also set a property called ref and specify the target
                      collection - Author. In the author property we will store an ObjectId that references an author
                      document. However, once again, we don't really have a proper relationship here. We can store a
                      course with an invalid author, and Mongo doesn't complain about that.

                      So now have modified the model run the application again:

                      Connected to MongoDB... { _id: 5c338a931514bb0cc4f07ae0, name: 'Node Course', author:
                      5c33787f925b1d69c861529e, __v: 0 }

                      we now have the author property. Now, back in MongoDB compass, let's look at this playground
                      database and our courses collection:

                      //TODO fig xx-xx

                      You can see we have two documents. The first one doesn't have an author, but the second one does.

                      Population ==========

                      In this lecture, we will get all the courses along with their Authors. Let's enable the call to
                      listCourses():

                      listCourses();

                      In this function:

                      async function listCourses() { const courses = await Course .find() .select('name author -_id');
                      console.log(courses); }

                      We are calling the find method to get all the courses and we're selecting only their name
                      property. Save the changes and run the application.

                      [ { _id: 5c33787f925b1d69c861529e, name: 'Node Course' }, { _id: 5c338c91ab5cad1bf8984ace, name:
                      'Node Course' } ]

                      We only get _id and name in the results. If we add author:

                      async function listCourses() { const courses = await Course .find() .select('name author');
                      console.log(courses); }

                      The results:

                      [ { _id: 5c33787f925b1d69c861529e, name: 'Node Course' }, { _id: 5c338a931514bb0cc4f07ae0, name:
                      'Node Course', author: 5c33787f925b1d69c861529e } ]

                      Our second document now has an author. We are only getting the reference or the object id here. In
                      a real world application, you want to load this author document so we can display it's name.
                      That's where we can call the populate method:

                      async function listCourses() { const courses = await Course .find() .populate('author')
                      .select('name author'); console.log(courses); }

                      As the first argument we specify the path to a given property - in this case author. And because
                      earlier, when defining the course model, we set author to be an ObjectId and we referenced the
                      Author collection:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: { type:
                      mongoose.Schema.Types.ObjectId, ref: 'Author' } }));

                      When we load a course object and populate the author property, Mongoose knows that it should query
                      the authors collection in MongoDB. Run the application:

                      Connected to MongoDB... [ { _id: 5c33787f925b1d69c861529e, name: 'Node Course' }, { _id:
                      5c338a931514bb0cc4f07ae0, name: 'Node Course', author: { _id: 5c35c8042a373608dcac60ad, name:
                      'Mosh', bio: 'My bio', website: 'My Website', __v: 0 } } ]

                      Our first document doesn't have an author so we don't get anything. Our second course does have an
                      author and we can see a complete representation of an author document. In a real world
                      application, an author can have multiple properties. Perhaps when showing a list of courses, we
                      don't want to get all the additional properties of the author - maybe you just want to get the
                      name property.

                      We can achieve this by supplying a second argument to the populate method which specifies the
                      properties you want to include or exclude:

                      .populate('author', 'name -_id')

                      If you run the application again:

                      [ { _id: 5c33787f925b1d69c861529e, name: 'Node Course' }, { _id: 5c338a931514bb0cc4f07ae0, name:
                      'Node Course', author: { name: 'Mosh' } }, { _id: 5c338c91ab5cad1bf8984ace, name: 'Node Course',
                      author: null } ]

                      Now the author property only contains the name property. It's also possible to use the populate
                      method to populate multiple properties. For example, let's imagine that each course has a category
                      and the category references the category document. So here we can call populate again, add
                      category, and optionally pick only the name property of each category document:

                      async function listCourses() { const courses = await Course .find() .populate('author', 'name
                      -_id') .populate('category', 'name') .select('name author'); console.log(courses); }

                      One last thing to finish the lecture. Earlier we discussed how Mongo doesn't have relationships or
                      data integrity in our database. So here in our courses collection it is possible to set our author
                      to an invalid document. You can use Compass to simulate this by manually editing the ObjectId of
                      the author property:

                      //TODO fig xx-xx

                      MongoDB allows you to make this modification without complaining. If you run the application:

                      Connected to MongoDB... [ { _id: 5c33787f925b1d69c861529e, name: 'Node Course' }, { _id:
                      5c338a931514bb0cc4f07ae0, name: 'Node Course', author: null }, { _id: 5c338c91ab5cad1bf8984ace,
                      name: 'Node Course', author: null } ]


                      You can see the author is now null because there is no author with the given id in our database.

                      115 - Embedding Documents =========================

                      So in the last lecture you learned how to use references to relate documents. In this lecture we
                      are going to look at another technique which is embedding documents.

                      Here we have the authorSchema exactly as it was in the previous lecture:

                      const authorSchema = new mongoose.Schema({ name: String, bio: String, website: String });

                      With three properties - name, bio and website. We have an Author model:

                      const Author = mongoose.model('Author', authorSchema);

                      Below that we have the Course model:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String }));


                      Here we don't have the Author property. That's what we are going to add in this lecture. In the
                      last lecture we set the type of our author property to an ObjectId and referenced the Author
                      collection:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: { type:
                      mongoose.Schema.Types.ObjectId, ref: 'Author' } }));

                      In this lecture we are going to embed an author document directly inside of the course document:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: { type:
                      authorSchema } }));

                      We set the type of the author property to authorSchema which is defined here:

                      const authorSchema = new mongoose.Schema({ name: String, bio: String, website: String });

                      That is the only change we need to make. Now let's take a look at the createCourse function:

                      async function createCourse(name, author) { const course = new Course({ name, author });

                      We take a course name and an author, initialize the course and save it, as we did previously.

                      At the end of the file we have a call to the createCourse function:

                      createCourse('Node Course', new Author({ name: 'Mosh' }));

                      Before going any further open MongoDB Compass and delete the playground database. We want to start
                      on a clean canvas to make sure we are on the same page.

                      Run the application:

                      Connected to MongoDB... { _id: 5c35d9d06cfab944e4ae7c51, name: 'Node Course', author: { _id:
                      5c35d9d06cfab944e4ae7c50, name: 'Mosh' }, __v: 0 }

                      You can see the new course document. We can see author is an object with two properties - id and
                      name. So this is an embedded or sub-document. These sub-documents are like normal documents so
                      most features that are available in normal documents are also available in sub documents. For
                      example, we can implement validation here, we can enforce that author.name should be required.

                      However, these sub-documents, cannot be created on their own. They can only be saved in the
                      context of their parent. So let's say I want to change the name of this author. Copy the course
                      id. Create a new function:

                      async function updateAuthor(courseId) { const course = await Course.findById(courseId);
                      course.author.name = 'Mosh Hamedani'; course.save(); }

                      First we find a course with the given id. Now, we can modify the author:

                      course.author.name = 'Mosh Hamedani';

                      Now we can call course.save(). Bear in mind we don't have course.author.save() - that does not
                      exist.

                      Let's add a call to this function:

                      updateAuthor('5ac4da76334f0d2cf09211e5');

                      Run the application again. To check the document has been updated look at Compass. Refresh the
                      view then browse the playground database, courses collection, course document, author property.
                      You should see the author name has been updated:

                      //TODO fig xx-xx

                      We can also update a sub-document directly. So, instead of querying it first, we can update it
                      directly in the database:

                      async function updateAuthor(courseId) { const course = await Course.update({ _id: courseId}, {
                      $set: { 'author.name': 'John Smith' } }); }

                      We replace findById with update passing a query object as the first argument. The second argument
                      is our update object. We use the set operator, which we have seen before, which we set to an
                      object. Here we pass one or more key/value pairs. To access the a nested property we use the dot
                      notation. Let's say we want to update the name of the author of a course:

                      'author.name': 'John Smith'

                      With this we don't need to modify this object in memory and save it explicitly. We update it
                      directly in the database. So back in the terminal run the application again. Go into Compass and
                      refresh. You should see the author name has been updated.

                      If you want to remove the sub-document you use the unset operator:

                      async function updateAuthor(courseId) { const course = await Course.update({ _id: courseId}, {
                      $unset: { 'author': '' } }); }

                      We can specify author.name to remove the nested property or we can specify author to remove the
                      sub-document as a whole (as in the code above)

                      As discussed previously, these sub-documents are similar to normal documents, so here we can
                      enforce validation. We can enforce that every course should have an author, so here's the
                      definition of our course schema:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: authorSchema
                      }));

                      If you want to make this author property required we need to pass a Schema type object setting the
                      type to authorSchema and the required property to true:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, author: { type:
                      authorSchema, required: true } }));

                      This syntax is identical to the validation we looked at in the section on Mongoose data
                      validation. If you want to make a specific property in the author document required you apply that
                      validation on the author sub-document itself:

                      const authorSchema = new mongoose.Schema({ name: { type: String, required: true }, bio: String,
                      website: String });

                      We specify a schema type object and set the required property to true.

                      116 - Using an Array of Sub-documents =====================================

                      So in the last lecture we add an author as a sub-document in the course document. In this lecture,
                      I'm going to show you how to change this to an array of sub-documents.

                      First rename the property to authors, then change it's value to an array of authorSchema:

                      const Course = mongoose.model('Course', new mongoose.Schema({ name: String, authors:
                      [authorSchema] }));

                      We need to modify the createCourse function so that when creating an array we pass an array of
                      authors:

                      async function createCourse(name, authors) { const course = new Course({ name, authors });

                      Finally, in the call to createCourse, instead of passing one author object we pass an array:

                      createCourse('Node Course', [ new Author({ name: 'Mosh' }), new Author({ name: 'John'}) ]);

                      Now back in Compass delete the courses collection. Run the application:

                      Connected to MongoDB... { authors: [ { _id: 5c361a1ad2643c0ab0b8237f, name: 'Mosh' }, { _id:
                      5c361a1ad2643c0ab0b82380, name: 'John' } ], _id: 5c361a1ad2643c0ab0b82381, name: 'Node Course',
                      __v: 0 }

                      In Compass refresh and look at the new document that has been created in the courses collection:

                      //TODO fig xx-xx

                      You can see the courses collection and the course document with an array of authors. Every Author
                      is an object and when you expand you see two properties _id and name.

                      We can add authors to this array at a later date if required. Back in the code, let's create a new
                      function called addAuthor:

                      async function addAuthor(courseId, author) { const course = await Course.findById(courseId);

                      course.authors.push(author); course.save(); }

                      First we find a course, then we push the author into the authors array. At this point our changes
                      are not saved to the database so we call course.save.

                      Add a call to the addAuthor function:

                      addAuthor('5c361a1ad2643c0ab0b82381', new Author({ name: 'Amy'}));

                      Run the application and check in Compass to ensure the new Author has been successfully added to
                      the array.

                      Removing an Author is very similar:

                      async function removeAuthor(courseId, authorId) { const course = await Course.findById(courseId);
                      const author = course.authors.id(authorId); author.remove(); course.save(); }

                      We supply two parameters - courseId and authorId. We use the findById method to find the course.
                      Next we use dot notation to goto course.authors and here we have an id method. The id method can
                      be used to lookup a child object by it's id. So we pass the authorId and store the returned author
                      object in a const called author. Now we can call the remove method on the author object. Finally
                      we call course.save();

                      Add a call to the removeAuthor function:

                      removeAuthor('5c361a1ad2643c0ab0b82381', '5c361cafe15b1105e4afb80a');

                      Run the application and take a look at the data in Compass:

                      //TODO fig xx-xx

                      The specified author should have been removed.

                      This is how we work with sub-documents.

                      117 - Project - Build the Movies API ====================================

                      Alright now, I want to get back to our vidly project, and build an API to manage the list of
                      movies. Now, don't think that this is exactly like managing the list of genres, this exercise is
                      more challenging.

                      So this is the shape of the movies that we want to store in MongoDB:

                      - title String - genre An embedded genre object - numberInStock Number - dailyRentalRate Number

                      Note that the vidly database already contains a genres collection but we are embedding genre
                      documents inside a movie document to optimize the performance of our queries. Also, take into
                      account, that it's very unlikely that we will rename the name of a genre in the future - sci-fi is
                      sci-fi, thriller is thriller so in this particular case, I'm not worried about our data becoming
                      inconsistent in the future.

                      You might be curious why we still need a separate genres collection. Somewhere in our application
                      on the client side you may want to have a drop-down list that allows the user to select the genre
                      for a movie. For this reason, we will keep the genres collection - querying this collection is
                      much easier than querying all the movies and then getting the unique list of genres.

                      To save time we wont type the solution out by hand. You can download it as a zip file attached to
                      this lecture. Here we will just highlight the key points that are important to understand.

                      Let's start with our movie model and the Movie schema:

                      const Movie = mongoose.model('Movies', new mongoose.Schema({ title: { type: String, required:
                      true, trim: true, minlength: 5, maxlength: 255 }, genre: { type: genreSchema, required: true },
                      numberInStock: { type: Number, required: true, min: 0, max: 255 }, dailyRentalRate: { type:
                      Number, required: true, min: 0, max: 255 } }));

                      We have a title property which is a string that is required. trimming is also enabled to get rid
                      of any paddings around the title of the movie. I set the minimum length to five characters and the
                      maximum length to 255 characters. This is because I don't want a malicious client to send a very
                      long string t hat could potentially cause problems in our application.

                      Next we have genre. I have set the type of this genre to genreSchema. In the code above the model
                      definition you can see we have created a genreSchema constant and loaded it from our genre module:

                      const { genreSchema } = require('./genre');

                      The genreSchema is defined in a file called genre.js. Previously we didn't define the genreSchema
                      separately. Instead it was defined directly in the call to mongoose.model. However, because we
                      need to reference the genreSchema in our movie module it has been extracted into a separate
                      constant that can be reused in multiple places.

                      Also at the end of the genre module we add the genreSchema to our module.exports:

                      exports.genreSchema = genreSchema;

                      So back in the Movie module, next we have the numberInStock property which is a required number.
                      The min is set to 0 because we don't want to end up with a negative number here. This kind of
                      validation ensures our application behaves properly. We also set a maximum of 255 character. Again
                      this is to prevent a malicious client to sending a very large number that could potentially cause
                      problems in our application.

                      The same is true for the last property dailyRentalRate.

                      Below the definition of our Schema and model we have our validateMovie function. This is where we
                      define our Joi schema:

                      function validateMovie(movie) { const schema = { title: Joi.string().min(5).max(50).required(),
                      genreId: Joi.string().required(), numberInStock: Joi.number().min(0).required(), dailyRentalRate:
                      Joi.number().min(0).required() };

                      This is different to our Mongoose schema. Note that our Joi schema has a property called genreId
                      not genre because we want the client to send only the Id of a genre. Therefore the genreId is set
                      to a string that is required.

                      In contrast in our Mongoose schema we have genre which is a complex object. So you can see that in
                      a real world application your Mongoose Schema can start to grow independent of your Joi Schema.

                      The Joi schema validates what the client sends us - the input to our API. The Mongoose Schema is a
                      representation of our model in the application. That's our persistence model, that's what we're
                      store as a document in MongoDB.

                      So that covers our movie module. Now let's take a look at our movies routes. We will overview just
                      one route here - the one that calls the post method to create a new movie:

                      router.post('/', async (req, res) => { const { error } = validate(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      const genre = await Genre.findById(req.body.genreId); if (!genre) return
                      res.status(400).send('Invalid genre.');

                      let movie = new Movie({ title: req.body.title, genre: { _id: genre._id, name: genre.name },
                      numberInStock: req.body.numberInStock, dailyRentalRate: req.body.dailyRentalRate }); movie = await
                      movie.save();

                      res.send(movie); });

                      At the top we validate the object that we send in the request, if it's invalid we return a 400
                      error which is bad request (as we did before). After that we have something new. We use findById
                      to find a genre. If it doesn't exist we return the 400 error with the message 'Invalid genre.'.
                      This makes sure that the genreId that the client sends represents a valid genre.

                      Below that we create the movie object. We set the title based on what we get in the request but
                      for genre we set the value to a complex object with two properties - _id and name. We read both of
                      these from the genre. You might ask why I didn't send this genre to the genre objected that we
                      loaded in the code nearer the top of the post method:

                      const genre = await Genre.findById(req.body.genreId);

                      The reason we don't do that is that, is because this genre object, also has a version property
                      that is set by Mongo which we dont want in movie.genre. Also, in a more complex application, the
                      object that we load when we call Genre.findById may have 50 properties. We don't want to store all
                      those properties when embedding the genre document in the movie document. That's why we
                      selectively set the properties.

                      The rest of the code in the vidly application, as it currently stands, is pretty self explanatory.

                      118 - Project - Build the Rentals API =====================================

                      So far we have built APIs to manage customer, genres and movies. Now let's take this application
                      to the next level.

                      I want you to implement an API to manage the rentals:

                      - Create a new rental POST /api/rentals - Get the list of rentals GET /api/rentals

                      Solution -------- In the models folder we have a new module rental. Let's take a look at the
                      schema:

                      const Rental = mongoose.model('Rental', new mongoose.Schema({ customer: { type: new
                      mongoose.Schema({ name: { type: String, required: true, minlength: 5, maxlength: 50 }, isGold: {
                      type: Boolean, default: false }, phone: { type: String, required: true, minlength: 5, maxlength:
                      50 } }), required: true }, movie: { type: new mongoose.Schema({ title: { type: String, required:
                      true, trim: true, minlength: 5, maxlength: 255 }, dailyRentalRate: { type: Number, required: true,
                      min: 0, max: 255 } }), required: true }, dateOut: { type: Date, required: true, default: Date.now
                      }, dateReturned: { type: Date }, rentalFee: { type: Number, min: 0 } }));

                      We have a customer property with the type set to a custom schema that is defined here:

                      customer: { type: new mongoose.Schema({

                      In other words I am not reusing the customer Schema we defined in the customer module. The reason
                      for this is that because our customer can have 50 properties. We don't want to have all those
                      properties inside the Rental object. We only need the primary properties that we need when
                      displaying the list of rentals. So we have:

                      - name - isGold - perhaps we want to give a discount to our gold customers - phone - when we look
                      at a list or rentals or a single rental it might be handy to have contact information for this
                      customer

                      You might ask, what if in the future we need to display more information about this customer on
                      the rental page. Here we will have the id of the customer as well so for anything additional we
                      can always send a GET request to our customer API to get a complete representation of our
                      customer.

                      By the same token we have a movie property set to a custom schema:

                      movie: { type: new mongoose.Schema({

                      We have not re-used the movie Schema that we defined in movie.js. This is for the same reason as
                      before - our movie may have 50 properties and we don't want to add them all here. So for a rental
                      object or rental document, we only need the title of the movie and dailyRentalRate because in the
                      future we are going to use this to calculate the rental fee. If we include this in an embedded
                      document we don't need and additional query for the movies collection to calculate the rental fee.

                      Note that both the customer and the movie are marked as required:

                      required: true

                      We have another property that is called dateOut:

                      dateOut: { type: Date, required: true, default: Date.now },

                      It's a date, it's required and the default value for this property is the current date/time.

                      We also need another property called dateReturned:

                      dateReturned: { type: Date },

                      This is also a date but it's not required because initially we don't have a value for this
                      property and then in the future when this customer returns a movie we will set this value.

                      The last property is rentalFee:

                      rentalFee: { type: Number, min: 0 }

                      which is a number that cannot be less than zero.

                      So this is the shape of our rental documents in MongoDB.

                      Next we have the validateRental function:

                      function validateRental(rental) { const schema = { customerId: Joi.string().required(), movieId:
                      Joi.string().required() };

                      Note that the schema we have here is very different to the schema we defined in our rental
                      documents in MongoDB. Here we have only two properties - customerId and MovieId. These are the
                      properties that the client sends to the server because we don't want the client to set the dateOut
                      property. This should be set on the server based on the current date/time. By the same toke we
                      don't want the client to set dateReturned or rentalFee. These should be set on the server. So,
                      when creating a new rental, the client should send only two values - customerId and movieId.

                      Now let's take a look at the API implementation in routes\rentals.js.

                      We have an endpoint to get the list of rentals:

                      router.get('/', async (req, res) => { const rentals = await Rental.find().sort('-dateOut');
                      res.send(rentals); });

                      Very simple - just like before except that here we are sorting by dateOut in a descending order.
                      That's why we have the minus sign.

                      Now let's take a look at our other route for creating a new rental. First we validate the request:

                      const { error } = validate(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      If it's not valid we send a 400 error. After that we want to make sure that the customer id that
                      the customer is sending us is a valid customer. That's why here we find the customer by id:

                      const customer = await Customer.findById(req.body.customerId); if (!customer) return
                      res.status(400).send('Invalid customer.');

                      If we don't find the customer we respond with a 400 error and say this is an invalid customer.

                      By the same token, we need to validate the movie id that the client sends us. We find the movie
                      and if it doesn't exist we return a 400 error:

                      const movie = await Movie.findById(req.body.movieId); if (!movie) return
                      res.status(400).send('Invalid movie.');

                      We also want to make sure that the movie we are renting out is in stock. So, if numberInStock is 0
                      we return a 400 error:

                      if (movie.numberInStock === 0) return res.status(400).send('Movie not in stock.');

                      After this point everything is valid so we create a new rental object:

                      let rental = new Rental({ customer: { _id: customer._id, name: customer.name, phone:
                      customer.phone }, movie: { _id: movie._id, title: movie.title, dailyRentalRate:
                      movie.dailyRentalRate } }); rental = await rental.save();

                      We set the customer object to a complex object with the _id, name and phone properties. We store
                      the _id here because perhaps in the future we want more information about the customer that is not
                      available in the rental document so we can query the customer later.

                      Similarly we have the movie property which is a complex object with three properties - _id, title
                      and dailyRentalRate. Note that here, we have not set the dateOut property. This is because earlier
                      we defined the property to have a default value of the current date/time. So when we save this
                      rental Mongoose will automatically set that property.

                      After that we update the numberInStock property of the movie then save:

                      movie.numberInStock--; movie.save();

                      Here, we have a problem. There are two separate operations. It is possible that after we save the
                      rental something goes wrong, maybe our server crashes, or connection to MongoDB drops meaning that
                      perhaps the second operation - movie.save() will not complete.

                      That's where we need a transaction. With a transaction we can ensure that both these operations
                      will update the state of our data in the database or none of them will be applied. So they are
                      atomic - they both complete or the both roll back. Now in a lot of relational databases we have
                      the concept of transactions. In MongoDB, we don't really have transactions.

                      There is a technique that is called two phase commit which is beyond the scope of this course. In
                      the next lecture, however, we will look at an npm package that simulates a transaction in
                      Mongoose.

                      119 - Transactions ==================

                      In some relational database like SQL server or MySQL we have the concept of transaction which
                      basically means a group of operations that should be performed as a unit. So either all these
                      operations will complete and change the state of the database or, if something fails at some
                      point, all these operations that have been applied will be rolled back and our database will go
                      back to it's initial state.

                      Now, in MongoDB we don't have transactions as we have in these relational databases. We have a
                      technique called two phase commit, which you can learn more about at:

                      https://docs.mongodb.com/manual/tutorial/perform-two-phase-commits/

                      This document clearly explains how to perform two phase commits using a real world example. Now,
                      in this lecture, I'm going to introduce you to a library that uses the concept of transaction, but
                      internally it implements this transaction using the two phase commit. So, back in the terminal,
                      let's install fawn:

                      npm i fawn

                      The version I had installed was 2.1.5. In routes\rentals.js first we need to load fawn:

                      const Fawn = require('fawn');

                      This a class with an initialize method that we need to call:

                      Fawn.init(mongoose);

                      Back in the post method where we create a rental object:

                      let rental = new Rental({

                      We are no longer going to create the rental and update the movie explicitly. Instead we are going
                      to create a task object which is like a transaction. So delete these three lines:

                      rental = await rental.save();

                      movie.numberInStock--; movie.save();

                      New up a Fawn task:

                      new Fawn.Task()

                      Here we can add one more operations. All these operations together will be treated as a unit. So
                      we want to save the new rental to the rentals collection:

                      .save('rentals', rental)

                      Note that here you are working directly with the collection. That's why we need to pass the actual
                      name of the collection, which is plural, not singular, and also note that this name is case
                      sensitive (if you look in Compass you will see the name of the collections are all lowercase).
                      This is our first operation - saving the rental.

                      As part of this unit we also want to update the movies collection. Here, as the second arugment,
                      we pass a query object to determine the movie, or movies that should be updated. The third
                      argument is our update object. Here we use the increment operator setting the value to an object.
                      The target property you want to update is numberInStock. We want to decrement this property by -1:

                      .update('movies', { _id: movie._id }, { $inc: { numberInStock: -1 } })

                      So we have defined two operations:

                      .save('rentals', rental) .update('movies', { _id: movie._id }, { $inc: { numberInStock: -1 } })

                      Maybe in your application, as part of performing this transaction, you want to remove a document
                      somewhere else. So we could add another operation .remove You can read more about Fawn on their
                      GitHub page documentation.

                      So, after we chain all these operations, finally you need to call run():

                      new Fawn.Task() .save('rentals', rental) .update('movies', { _id: movie._id }, { $inc: {
                      numberInStock: -1 } }) .run();

                      If you don't call run then none of the operations will be performed. Now, it's possible that
                      something fails during this transaction so we need to wrap this in a try\catch block:

                      try { new Fawn.Task() .save('rentals', rental) .update('movies', { _id: movie._id }, { $inc: {
                      numberInStock: -1 } }) .run();

                      res.send(rental); } catch(ex) { res.status(500).send('Something failed.'); }

                      If something fails we catch the exception and return a 500 error to the client which means
                      internal server error. In a real world application at this point you want to log this exception so
                      later you can come back and see what went wrong. We are going to have a separate section in the
                      course about error handling and logging so for now don't worry about it.

                      In MongoDB Compass delete the rentals collection. Run the application:

                      nodemon

                      Back in Compass look at the movies collection:

                      //TODO fig xx-xx

                      Here we have a movie with numberInStock of 8. We will create a new rental and then check the
                      numberInStock has decremented by 1 to 7.

                      In Postman send a post request to our rentals endpoint:

                      http://localhost:3000/api/rentals

                      In the body of the request I have a valid customerId and movieId:

                      { "customerId": "5c37c6fc99ee168d28f4f617", "movieId": "5c37c5bb99ee168d28f4f616" }

                      Let's send this and our response should be;

                      { "dateOut": "2019-01-10T22:29:06.114Z", "_id": "5c37c73299ee168d28f4f619", "customer": {
                      "isGold": false, "_id": "5c37c6fc99ee168d28f4f617", "name": "Fred Smith", "phone": "07856 771163"
                      }, "movie": { "_id": "5c37c5bb99ee168d28f4f616", "title": "Terminator", "dailyRentalRate": 2 } }

                      We can see dateOut, id, customer and movie.

                      Now, back in the Compass, in the movies collection refresh the list and you should see the number
                      in stock drops to 7. So this verifies that our transaction completed successfully.

                      A question for you - In our post method we create our rental object

                      let rental = new Rental({ customer: { _id: customer._id, name: customer.name, phone:
                      customer.phone }, movie: { _id: movie._id, title: movie.title, dailyRentalRate:
                      movie.dailyRentalRate } });

                      We only set customer and movie. Then in our try block we create the Fawn task, run it then send
                      the rental object to the client. In this code we didn't set the id or dateOut property but in the
                      body of the response we can see both the properties are set. So how did this happen?

                      You might expect that MongoDB set the dateOut and id properties but in MongoDB we don't have these
                      default values. We define them in our mongoose Schema. So when we create a new rental object
                      Mongoose knows the Schema for this object, it looks at various properties and sets the default
                      values. The same is true for the _id properties, MongoDB doesn't set this. The _id property is set
                      before we save the document to the database. I didn't tell you this earlier because I didn't want
                      confuse your with too many details.

                      We will cover more about id in the next lecture. Let's look at one more thing before we finish
                      this lecture. Back in Compass click the refresh collections button and you will see a new
                      collection:

                      ojlinttaskcollections

                      So where did that come from? The Fawn library that we installed uses that collection to perform
                      two phase commits. When we run the Fawn task it adds a new document to that collection that
                      represents our transaction. Then it will execute each of the operations in the task independently
                      then finally , when all the operations are complete, it will delete the document from the
                      collection.

                      ObjectId ========

                      In this lecture we are going to look at object id's in MongoDB. You may have noticed that when you
                      store a document in MongoDB it sets the value of the _id property to a long string like this:

                      // _id: 5ac4aa5307ac0119b0e74255

                      Here we have 24 characters where every two characters represent a byte. So essentially we have 12
                      bytes to uniquely identify a document in MongoDB. The twelve bytes are used in the following way:

                      - 4 bytes: timestamp The time this document was created. - 3 bytes: machine identifier Two
                      different machines will have two different identifiers. - 3 bytes: process identifier If you
                      generate two object id's on the same machine but in different processes these two bytes will be
                      different. - 3 bytes: counter If your on the same machine, in the same process at the same second
                      but generate two different documents the counter bytes will be different

                      Also, because a timestamp is included in the _id property, there is no need to create a separate
                      property or document like createdAt. By the same token, if you want to sort your documents based
                      on the creation time you can simply sort them by the id property.

                      So with these twelve bytes we can uniquely identify the document in MongoDB. Having said that
                      there is a very, very small chance that we will generate two object id's that are the same. Let's
                      see how that can happen.

                      You know that, in each byte, we have 8 bits and each bit holds either 0 or 1. So how many numbers
                      can we represent?

                      - 1 byte = 8 bits - 2 ^ 8 = 256

                      So with one byte we can store 256 different numbers. Now, as discussed, the last three bytes
                      represent a counter. This is like the counter that you have probably seen in SQL Server, MySQL or
                      other databases. So how many numbers can we store in 3 bytes: - 1 byte = 8 bits - 2 ^ 8 = 256 - 2
                      ^ 24 = 16M

                      So, if have the same second, on the same machine, in the same process and we generate more than
                      16M documents the counter bytes will overflow and that's where we will end up with two documents
                      with the same object id. However, this is a very unlikely scenario for many applications out
                      there. All we need to remember is the object id is almost unique but not 100 percent.

                      Now you might be curious as to why we don't have a mechanism in MongoDB that guarantees
                      uniqueness. For example, in database management systems like SQL server or My SQL, in each table
                      we have an auto incrementing number that guarantees uniqueness. So next time we store a course
                      record in our database the id of that course will be the id of the course plus 1. This approach
                      guarantees the uniqueness of this identifier but it hurts scalability.

                      In MongoDB the id we have here:

                      // _id: 5ac4aa5307ac0119b0e74255

                      Is not generated by MongoDB itself. It is actually generated by MongoDB driver. So we have the
                      MongoDB driver that talks to MongoDB. Because the id is generated by the driver, it means, we
                      don't have to wait for MongoDB to generate a new unique identifier.

                      That's why applications built on top of MongoDB are highly scalable. You can have several
                      instances of MongoDB and we don't have to talk to a central place to get a unique identifier. The
                      driver itself can generate an almost unique identifier using the twelve bytes we discussed above.

                      So, when you build an application with Node and Express, you use Mongoose. As I told you before,
                      Mongoose is an abstraction over MongoDB driver, so when you create a new object/document Mongoose
                      talks to MongoDB driver to generate a new id, but it can also explicitly generate an id if you
                      want to. Let's see how to do this.

                      const mongoose = require('mongoose');

                      const id = new mongoose.Types.ObjectId(); console.log(id.getTimestamp());

                      We call the getTimestamp() method that belongs to the object id. Run the application:

                      2019-01-11T15:46:38.000Z

                      We also have a static method on this ObjectId class for validating object ids:

                      const isValid = mongoose.Types.ObjectId.isValid('1234'); console.log(isValid);

                      Obviously this is not a valid object id so when we run the application we see:

                      false

                      121 - Validating Object ID's ============================

                      Back to our vidly application. In Postman we are going to send a POST request to our rentals
                      endpoint:

                      http://localhost:3000/api/rentals

                      In the body of the request we have a valid customerId and movieId:

                      { "customerId": "5ac4aa5307ac0119b0e74255", "movieId": "5ac4ebc10227194c687cd3cb" }

                      Now let see what happens if we change the customerId object id in the body of the request to a
                      value like 1234:

                      { "customerId": "1234", "movieId": "5ac4ebc10227194c687cd3cb" }

                      Run the application and send the request in Postman. Postman hangs and in the terminal you see the
                      following error:

                      UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by
                      throwing inside of an async function without a catch block, or by rejecting a promise which was
                      not handled with .catch(). (rejection id: 2)

                      This basically means we had a promise that was rejected but we didn't handle it properly. Now as I
                      told you before we have a separate section about error handling and logging in the course so let's
                      not worry about that part. Instead look at the error:

                      CastError: Cast to ObjectId failed for value "1234" at path "_id" for model "Customer"

                      So let's talk through the message to simplify it. We are talking about the Customer model and we
                      are talking about the id property. In the error message you see the word path which represents a
                      chain of properties. For example, a customer can have address, address can have street etc. So
                      that's why we use path. Mongoose is complaining that it can't cast the value 1234 to ObjectId.
                      Obviously, this is because, 1234 is not a valid ObjectId.

                      The issue we have in our implementation is that:

                      - We are not seeing a response from the POST request - We are getting a message in terminal

                      In the situation where we send an invalid customerId we should receive a 400 error - bad request
                      because the server cannot fulfill this request.

                      Back in routes/rentals.js look at the handler for creating a new rental:

                      router.post('/', async (req, res) => { const { error } = validate(req.body);

                      At the top we validate the request. This ensures that we have a customerId and a movieId but it
                      doesn't check if these values are valid object id's. The exception that we saw above is thrown by
                      this line:

                      const customer = await Customer.findById(req.body.customerId);

                      When we call findById on the Customer class, if we pass an invalid object id we get the exception.

                      One way to fix the problem is to add an if statement to check the type is valid:

                      if(!mongoose.Types.ObjectId.isValid(req.body.customerId)) return res.status(400).send('Invalid
                      customer.');


                      If the customerId is not a valid ObjectId we return an error 400. We would also have to check the
                      movieId. However this is a bad implementation because earlier we defined this function to validate
                      our request:

                      validate(req.body);

                      So the logic to check for valid object id's really belongs in the function above. So we would
                      check to make sure that the customerId is a string, that has a value and is a valid ObjectId. If
                      the input is in the right shape only then should we go to the database to find the Customer.

                      Go back to the validateRental function in models\rental.js:

                      function validateRental(rental) { const schema = { customerId: Joi.string().required(), movieId:
                      Joi.string().required() };

                      return Joi.validate(rental, schema); }

                      Here we need to add validation because we need to:

                      - Talk to Mongoose - Call the isValid method of ObjectId.Type

                      Now, extending the validation is a little bit complex and you don't want to repeat that every time
                      you need a validate function. There is actually an npm package for adding support to validating
                      ObjectId's in Joi. So, back in the terminal:

                      npm i joi-objectid

                      The current version that get's installed is 2.0.0. Back in rental.js we need to load this module:

                      Joi.objectId = require('joi-objectid')(Joi);

                      require('joi-objectid') returns a function. We call the function and return a reference to the Joi
                      module defined above:

                      const Joi = require('joi'); require('joi-objectid')(Joi);

                      The result of this is a function so we can set Joi.objectId to this function:

                      Joi.objectId = require('joi-objectid')(Joi);

                      objectId is a method on the Joi object. Back in the validateRental function we will change the
                      definition of the customerId from Joi.string() to Joi.objectId() which is the method that we
                      defined at the top of the module. We make the same change for the movieId:

                      function validateRental(rental) { const schema = { customerId: Joi.objectId().required(), movieId:
                      Joi.objectId().required() };

                      return Joi.validate(rental, schema); }

                      Now, back in the terminal, let's run the application again:

                      nodemon

                      In Postman send another POST request with an invalid customerId. You should see the following:

                      "customerId" with value "1234" fails to match the required pattern: /^[0-9a-fA-F]{24}$/

                      You should also receive a 400 - Bad Request. The Terminal should now also not be showing the
                      unhandled promise rejection.

                      122 - A Better Implementation =============================

                      Back in rental.js it is likely that we will use the Joi.objectId() method in other places in our
                      application, like in the movie module or the customer module.

                      We don't want to re-define this objectId method in every module. So, on top of the file, move the
                      definition of the objectId method from rental.js to index.js:

                      Joi.objectId = require('joi-objectid')(Joi);

                      Now we load it once in index.js and then we can use it anywhere in our application. Don't forget
                      to also add the code to load Joi:

                      const Joi = require('joi');

                      We also need to modify models\movie.js. When creating a movie we need to pass a valid genreId so
                      we replace the call to:

                      genreId: Joi.string().required(),

                      with:

                      genreId: Joi.objectId().required(),

                      One last change, before we finish this lecture, in our routes folder let's take a look at
                      movies.js, specifically the route for creating a new movie:

                      router.post('/', async (req, res) => { const { error } = validate(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      const genre = await Genre.findById(req.body.genreId); if (!genre) return
                      res.status(400).send('Invalid genre.');

                      let movie = new Movie({ title: req.body.title, genre: { _id: genre._id, name: genre.name },
                      numberInStock: req.body.numberInStock, dailyRentalRate: req.body.dailyRentalRate }); movie = await
                      movie.save();

                      res.send(movie); });

                      Here we create a new movie object:

                      let movie = new Movie({

                      Save it to the database:

                      movie = await movie.save();

                      Then return it:

                      res.send(movie);

                      In this implementation I am resetting the movie after saving it to the database. This was purely
                      to demonstrate that this save method returns a movie document. Also, I didn't want to distract
                      with too much detail about how objectId's work.

                      Now that you know that objectId's are actually generated by MongoDB driver, not MongoDB database,
                      you'll also know that when we create a new movie object Mongoose talks to MongoDB driver and set's
                      the id right here:

                      let movie = new Movie({

                      Before saving this movie to the database. So technically we don't need to reset this movie in
                      order to return that id to the client. So we can remove that:

                      await movie.save();

                      and change movie from a variable:

                      let movie = new Movie({

                      to a constant:

                      const movie = new Movie({

                      The same principle applies when creating a new customer and a new genre.

                      123 - Recap ===========

                      Mongoose: Modelling Relationships between Connected Data
                      --------------------------------------------------------

                      So, in this section, you learned that:

                      - To model relationships between connected data, we can either reference a document or embed it in
                      another document. - When referencing a document, there is really no relationship between these two
                      documents. So, it is possible to reference a non-existing document. - Referencing documents
                      (normalization) is a good approach when you want to enforce data consistency. Because there will
                      be a single instance of an object in the database. But this approach has a negative impact on the
                      performance of your queries because in MongoDB we cannot JOIN documents as we do in relational
                      databases. So, to get a complete representation of a document with its related documents, we need
                      to send multiple queries to the database. - Embedding documents (denormalization) solves this
                      issue. We can read a complete representation of a document with a single query. All the necessary
                      data is embedded in one document and its children. But this also means we’ll have multiple copies
                      of data in different places. While storage is not an issue these days, having multiple copies
                      means changes made to the original document may not propagate to all copies. If the database
                      server dies during an update, some documents will be inconsistent. For every business, for every
                      problem, you need to ask this question: “can we tolerate data being inconsistent for a short
                      period of time?” If not, you’ll have to use references. But again, this means that your queries
                      will be slower.

                      // Referencing a document const courseSchema = new mongoose.Schema({ author: { type:
                      mongoose.Schema.Types.ObjectId, ref: ‘Author’ } })

                      // Embedding a document const courseSchema = new mongoose.Schema({ author: { type: new
                      mongoose.Schema({ name: String, bio: String }) } })

                      - Embedded documents don’t have a save method. They can only be saved in the context of their
                      parent.

                      // Updating an embedded document const course = await Course.findById(courseId);
                      course.author.name = ‘New Name’; course.save();


                      - We don’t have transactions in MongoDB. To implement transactions, we use a pattern called “Two
                      Phase Commit”. If you don’t want to manually implement this pattern, use the Fawn NPM package:

                      // Implementing transactions using Fawn try { await new Fawn.Task() .save(‘rentals’, newRental)
                      .update(‘movies’, { _id: movie._id }, { $inc: numberInStock: -1 }}) .run(); } catch (ex) { // At
                      this point, all operations are automatically rolled back }

                      - ObjectIDs are generated by MongoDB driver and are used to uniquely identify a document. They
                      consist of 12 bytes: - 4 bytes: timestamp - 3 bytes: machine identifier - 2 bytes: process
                      identifier - 3 byes: counter

                      - ObjectIDs are almost unique. In theory, there is a chance for two ObjectIDs to be equal but the
                      odds are very low (1/16,000,000) for most real-world applications.

                      // Validating ObjectIDs mongoose.Types.ObjectID.isValid(id);

                      - To validate ObjectIDs using joi, use joi-objectid NPM package.

                      Section 10 - Authentication and Authorization =============================================

                      124 - Introduction ==================

                      Back to our vidly application. So far we have built these API endpoints so we can manage:

                      /api/genres /api/movies /api/customers /api/rentals

                      Nearly all applications out there require some sort of authentication and authorization. So in
                      this section, we're going to take this application to the next level and implement authentication
                      and authorization.

                      Now before we go any further, I want to make sure we are on the same page.

                      So authentication is the process of identifying if the user is who they claim they are - that's
                      when we login. So we send our username and password to the server, and the server authenticates
                      us.

                      Authorization, is determining if the user has the right permission to perform the given operation.

                      // Authentication // Authorization

                      So in our vidly application, we want to make sure that only authenticated users or logged in users
                      can perform operations that modify data. If the user is anonymous - if they are not logged in they
                      they can only read data from the endpoints.

                      If they want to create a new genre or update a movie, they have to be authenticated first. As an
                      additional security, we want to make sure that only admin users can delete data. So that's a
                      second level of authorization - we're talking about permissions here.

                      These are the requirements we are going to implement in this section. To do this, we are going to
                      add two new endpoints to our application.

                      First, we should be able to register users.

                      // Register: POST /api/users

                      Because we POST we create a new resource, in this case a new user.

                      We should also be able to login a user - that's used for authentication. Now here's a question for
                      you. What http method, should we use to implement login? With login we are not creating a new
                      resource, not updating or removing an existing one, so how can we implement this in RESTful terms?
                      This is a scenario which you may encounter frequently in real-world applications. Sometimes the
                      operation you're dealing with doesn't have that Create/Read/Update/Delete semantic. The way we
                      model this is RESTful terms is by referring to this as a request or command.

                      So we are creating a new login request or command so we use POST

                      // Login: POST /api/logins

                      In your application, you may want to store all the logins into the applications in a separate
                      collection in MongoDB. So, in that context using POST makes perfect sense here. Even if you don't
                      store individual logins and you just want to validate the username and password you can still
                      treat this resource as login resource and use post to create it.

                      Here's an exercise for you. I want you to implement this API:

                      // Register: POST /api/users

                      to register new users. For each user we want the following properties:

                      - name - email - password

                      Also, when defining your schema, for the email property in the Schema type object, set the unique
                      property to true. So when we define the Schema we set the type of email to a Schema type object:

                      email: { type: String, unique: true }

                      This will ensure that we do not store two documents with the same email in MongoDB.

                      125 - Creating the User Model =============================

                      First I am going to define a new User model. In the models folder add a new file called user.js

                      To save time we can copy a lot of the code from genre.js:

                      const Joi = require('joi'); const mongoose = require('mongoose');

                      const genreSchema = new mongoose.Schema({ name: { type: String, required: true, minlength: 5,
                      maxlength: 50 } });

                      const Genre = mongoose.model('Genre', genreSchema);

                      function validateGenre(genre) { const schema = { name: Joi.string().min(3).required() };

                      return Joi.validate(genre, schema); }

                      exports.genreSchema = genreSchema; exports.Genre = Genre; exports.validate = validateGenre;

                      So, at the top, we have this Schema. We will define this while calling the model method. There is
                      really no need, in this case, to define this as a separate constant:

                      const Genre = mongoose.model('Genre', new mongoose.Schema({ name: { type: String, required: true,
                      minlength: 5, maxlength: 50 } }));

                      Modify the model and collection name to User:

                      const User = mongoose.model('User', new mongoose.Schema({

                      The name property is a required string that has to be between 5 and 50 characters. That sounds
                      good to me. Next, let's add email:

                      email: { type: String, required: true, minlength: 5, maxlength: 255, unique: true }

                      We increas the maximum length and also, as discussed in the last lectue, we should add the unique
                      property to make sure we don't store two users with the same email in MongoDB.

                      The last property is password:

                      password: { type: String, required: true, minlength: 5, maxlength: 1024 }

                      We set the max length to higher value because this password will be hashed. We don't need the
                      unique property.

                      Next is our validate function:

                      function validateUser(user) { const schema = { name: Joi.string().min(5).max(50).required(),
                      email: Joi.string().min(5).max(255).required().email(), password:
                      Joi.string().min(5).max(255).required() };

                      First, we rename to validateUser. We specify name, which is between 5-50 characters and required.
                      We have email, which should be between 5-255 characters and required. Here, we also call the email
                      method to make sure the email is valid. Finally we have password which is also a string between 5
                      and 255. This is the password that the user sends in plain text. We are going to hash this which
                      will result in a longer string - that's the string we will store in MongoDB.

                      Finally we need to change the call to Joi.validate from genre to user:

                      return Joi.validate(user, schema);

                      So we are done with our validate user function, now we need to export our user model. We can
                      delete our first exports statment - that's for our schema:

                      exports.User = User; exports.validate = validateUser;

                      So we are done with our User model. In the next section we will add a route to register new users.

                      126 - Registering Users =======================

                      Alright, now we are going to create a new route to register new users. In the routes folder add a
                      new file, users.js. Once again, to save time, I'm going to go to genres.js and copy the require
                      statement and the new routes into our users.js module:

                      const {Genre, validate} = require('../models/genre'); const mongoose = require('mongoose'); const
                      express = require('express'); const router = express.Router();

                      router.get('/', async (req, res) => { const genres = await Genre.find().sort('name');
                      res.send(genres); });

                      Now let's make some changes. On the top we need to import the user model instead of the Genre
                      model:

                      const {User, validate} = require('../models/user');

                      So, for models/user, we import the user class as well as the validate function. We also require
                      mongoose, express and router.

                      Next we add our new route which is post:

                      router.post('/', async (req, res) => {

                      For creating, registering new users, and finally we need to export this router:

                      module.exports = router;

                      Now, in index.js, we need to tell express that for any route that starts with /api/users it should
                      use the router we just exported above.

                      const users = require('./routes/users');

                      Then we tell express to use this route:

                      app.use('/api/users', users);

                      So, we have built the big picture. Now let's go back to our users module and implement this new
                      route:

                      router.post('/', async (req, res) => { });

                      So, here we need to validate the request. If it's not valid we have to return a 400 error, which
                      is bad request, otherwise we're going to create a new use object and save it to the database.

                      We can borrow some more code from our genres module. Copy the boddy of the post method onto the
                      users post method and make the following adjustments:

                      router.post('/', async (req, res) => { const { error } = validate(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      let user = await User.findOne({ email: req.body.email }); if (user) return
                      res.status(400).send('User already registered.');

                      user = new User({ name: req.body.name, email: req.body.email, password: req.body.password

                      });

                      user = await user.save();

                      res.send(user); });

                      We add some validation to make sure the user is not already registered. We use findOne instead of
                      findById because we are not looking a user up by their id we are looking them up by one of their
                      properties - email:

                      let user = await User.findOne({ email: req.body.email });

                      This returns a promise which we await and assign to a user object. We define a variable instead of
                      a constant because later we will reset this.

                      In this scenario if the user already exists in the database we return a 400 bad request to the
                      client:

                      if (user) return status(400).send('User already registered.');

                      Ok so if we have a valid user object that is not registered in the database then we save this user
                      in the database.

                      First we reset the user object (at this point it should be null):

                      user = new User({ name: req.body.name, email: req.body.email, password: req.body.password

                      });

                      And then we save the user and return it to the client:

                      user = await user.save(); res.send(user);

                      Test the application. In postman send a post request to:

                      http://localhost:3000/api/users

                      In the body of the request set the raw property and type to Json (application/json) object and
                      then pass three properties:

                      { "name": "Mosh Hamedani", "email": "1" }

                      So in this request I am sending an invalid email and we are not passing a password.

                      You should receive the following response:

                      "email" length must be at least 5 characters long

                      So change the email to:

                      { "name": "Mosh Hamedani", "email": "123456" }

                      You should receive the following response:

                      "email" must be a valid email

                      So, now, let's change the email to:

                      { "name": "Mosh Hamedani", "email": "programmingwithmosh@gmail.com" }

                      And now you should recieve the following message:

                      "password" is required

                      Finally let's add a password that is 5 characters long:

                      { "name": "Mosh Hamedani", "email": "programmingwithmosh@gmail.com", "password": "12345" }

                      At last you should get a 200 response and the user object that has been stored in the database
                      should be returned to you:

                      { "_id": "5c40ec28c44fce70cc7bf89f", "name": "Mosh Hamedani", "email":
                      "programmingwithmosh@gmail.com", "password": "12345", "__v": 0 }

                      When registering a new user it isn't ideal that we are returning their password in the response
                      above to the client. We will look at that in the next lecture.

                      If we post again with the same values we should receive the following error message (along with
                      400 bad request):

                      User already registered.

                      127 - Using Lodash ==================

                      So, back in our post method, we want to modify the response to our client. So there are two
                      options here. One approach is to send a custom object like this:

                      res.send({ name: user.name, email: user.email });

                      This way we can exclude the password and the version properties. This approach is perfectly fine
                      but in this lecture we will introduce you to a useful library that gives you alot of utility
                      functions for working with objects. If you are an experienced JavaScript developer you'll probably
                      know what I'm talking about - lodash. This is the second option.

                      lo-dash is basically the optimized version of underscore. Underscore has been around for a long
                      time and has a lot of utility functions for working with objects, strings, arrays and so on.

                      If you look in the documentation, you can see all the utility function that we have for working
                      with arrays, numbers, strings, objects and so on. So lodash is extremely powerful and in this
                      lecture we will look at how to use it in your Node applications.

                      Install lodash

                      npm i lodash

                      So in the users module we need to install lodash:

                      const _ = require('lodash');

                      By convention we assign this to a constant called _ because it is short and clean. The underscore
                      object has a utility method called pick:

                      _.pick(user, ['name', 'email']);

                      We pass the pick method an object, user, and then pass an array of properties in the that object
                      that we want to pick. This will return a new object with only those properties.

                      Instead of manually repeating user. when we send the response:

                      res.send({ name: user.name, email: user.email });

                      We can use the pick method:

                      res.send( _.pick(user, ['id', ''name', 'email']) );

                      We have also included the id property in the example above. We can also modify the code when
                      setting up the new user object.

                      user = new User( _.pick(req.body, ['name', 'email', 'password']));

                      Now here we might 50 properties. A malicious user may send us properties to be stored in the
                      database. We only want to hand pick a few of these so in the example above we specify name, email
                      and password.

                      So we create the user, save it, then return it to the client.

                      Test the application in postman. Send a new post request to the server and you should see the
                      following object in the response:

                      { "id": "5c40f89510d6601e481f70c0", "name": "Mosh Hamedani", "email":
                      "programmingwithmosh10@gmail.com" }

                      Which contains only id, name and email. Now in all these requests so far we have sent really
                      simple passwords. If you want to enforce password complexity there is an npm package built on top
                      of Joi called Joi password complexity.

                      You can use this library to configure an object that determins the password complexity in your
                      application:

                      const complexityOptions = { min: 10, max: 30, lowerCase: 1, upperCase: 1, numeric: 1, symbol: 1,
                      requirementCount: 2, }

                      As it stands our new api endpoint is storing passwords in plain text which is very bad. This will
                      be addressed in the next lecture where we will examine password hashing

                      128 - Hashing Passwords =======================

                      In this lecture we will look at how to hash passwords using a very popular library called bcrypt:

                      npm i bcrypt

                      Create a playground file to learn how to use the bcrypt library called hash.js. Load bcrypt and
                      store it in a constant:

                      const bcrypt = require('bcrypt');

                      To hash a password we need a salt. What is a salt? Well imagine our password is:

                      1234

                      When we hash that let's imagine we get a string like this:

                      1234 -> abcd

                      The hashing algorithm is one way so if we have abcd we cannot decrypt this and get 1234. From a
                      security point of view that is great. If a hacker looks at out database he or she cannot decrypt
                      these hashed passwords. However they can compile a list of popular passwords and hash them. They
                      can then look at the database of our application, find the hashed password, and then they know
                      that abcd represents 1234. So that's why we need a salt.

                      A salt is basically a random string that is added before or after this password, so the resulting
                      hash password will be different each time based on the salt used. Let's see this in action:

                      bcrypt.genSalt();

                      Note that this method has two version. The first one is asynchronous, the second one is
                      synchronous. As a best practice you should always use asynchronous methods because as I told you
                      at the beginning of the course in Node applications we have a single thread. We don't want to keep
                      that thread busy because then we can't server other clients.

                      So we call genSalt and as an argument we pass the number of rounds that we want to run the
                      algorithm to generate the salt. The higher the number, the longer it's going to take to generate
                      the salt. Also, the salt will be more complex and harder to break. So the default value is 10
                      we'll use that.

                      bcrypt.genSalt(10);

                      Because this is an asynchronous method, we can either pass a callback here, and that's what you
                      see in the official documentation as well as a lot of tutorial videos on the web. But this method
                      also has an overload that returns a promise. So, instead of passing a callback we get a promise,
                      await it and then get the salt:

                      const salt = await bcrypt.genSalt(10);

                      Now we need to wrap this in an async function like run:

                      async function run() { const salt = await bcrypt.genSalt(10); console.log(salt); }

                      run();

                      We log the salt to the console and finally we call the run function. Run the application:

                      $2b$10$yAVPxjSIzXXNTR8R37CM3O

                      So this is an example of a Salt. We can see the number of rounds we use included in the salt (10):

                      $2b$10$

                      So here we have a long random string that is included as part of hashing our password. With this,
                      every time we hash our password with a new salt, we get a different result.

                      Now that we have a salt we can hash our password:

                      const hashed = await bcrypt.hash('1234', salt);

                      We use the hash method of the bcrypt object, we pass the password 1234 through as the first
                      argument, the second argument is our salt. You can pass a callback through as the third argument
                      but we are not going to use this. Instead we are going to get the promise that is returned.

                      So we await the promise and get the hashed password. So now, let's log this on the console as
                      well:

                      console.log(hashed);

                      Run the application:

                      $2b$10$HiiGktgLBfQe.ZBlzV.Vzu $2b$10$HiiGktgLBfQe.ZBlzV.VzujY/HM0inkT9qHxgUhVFsmp1OV/ALNy6

                      On the first line we have our salt, on the second line we can see the salt as well - so the salt
                      is included in the hashed password. The reason this is included is that later when we want to
                      authenticate the user we want to validate their username and password. So there the user sends the
                      password in plain text, we need to hash it again, but we need to have the original salt that was
                      used to generate this hash. So during comparing the plain text password, with the hashed password,
                      bcrypt needs to know the original salt that was used to hash the password.

                      So now we know how bcrypt works let's put these two lines in our post route handler:

                      const salt = await bcrypt.genSalt(10); user.password = await bcrypt.hash(user.password, salt);

                      Instead of 1234 we use user.password - the plain text password. So we hash it with the salt then
                      reset it by assigning to it. Finally we save the user to the database:

                      await user.save();

                      We also need to import bcrypt:

                      const bcrypt = require('bcrypt');

                      In Compass delete the users collection because all the user documents so far contain plain text
                      passwords. Run the application and send a new post request in postman:

                      { "id": "5c41b11db5aa91409489159f", "name": "Mosh Hamedani", "email":
                      "programmingwithmosh10@gmail.com" }

                      So here we have a new user. Refresh the list in compass and you should see the new user with a
                      hashed password:

                      fig xx-xx

                      So we have now implemented the register new user endpoint.

                      129 Authenticating Users ========================

                      In the routes folder add a new file called auth.js. Copy and paste all the code from users.js to
                      auth.js.

                      Go to index.js and import the module:

                      const auth = require('./routes/auth');

                      We tell express to use the new route:

                      app.use('/api/auth', auth);

                      So, if we have any requests for the /api/auth endpoint or any of it's child endpoints we are going
                      to delegate this to the auth router.

                      Now, back in the auth module on the top, first we have to validate the body of the request. But
                      the validate function we have here:

                      const { error } = validate(req.body);

                      This is the one that we imported from our user module:

                      const {User, validate} = require('../models/user');

                      So this is validating that in the body of the request we have three properties: - name - email -
                      password

                      In a real world application you might have other properties as part of registering a user. This
                      validate function is for validating a new user, it's not for validating the email and password
                      that we expect at this endpoint. So here we need a different validate function. So we remove the
                      validate function that we were importing:

                      const {User} = require('../models/user');

                      And define a separate validate function in the auth module. Again, to save time, we can copy our
                      validate function from the user module to the auth module and modify it:

                      function validate(req) { const schema = { email: Joi.string().min(5).max(255).required().email(),
                      password: Joi.string().min(5).max(255).required() };

                      return Joi.validate(req, schema); }

                      We renamed the function to validate and changed the parameter to req. For this schema object we
                      need only two properties - email and password so we also deleted the name.

                      Now, back in our route handler, this is our first validation:

                      const { error } = validate(req.body);

                      Next we need to make sure that we do have a user with a given email so we load the user:

                      let user = await User.findOne({ email: req.body.email });

                      If we don't have the user(we add a NOT ! to the expression) we should return a 400 bad request and
                      send a message - "Invalid email or password".

                      if (!user) return res.status(400).send('Invalid email or password.');

                      Note that we don't send a error 404, which means not found, because we don't want to tell the
                      client why the authentication failed. We don't want to tell if the email is incorrect or the
                      password - so we don't want to say "We dont have a user with the given email". We just tell the
                      client that this is a bad request, it doesn't have the right data to be processed. So this is for
                      validating the username or email. Next we need to validate the password. For that we need to use
                      bcrypt.

                      So let's delete all this code here:

                      user = new User(_.pick(req.body, ['name', 'email', 'password'])); const salt = await
                      bcrypt.genSalt(10); user.password = await bcrypt.hash(user.password, salt); await user.save();

                      and add a call to the compare method of the bcrypt object:

                      const validPassword = await bcrypt.compare(req.body.password, user.password);

                      We use the compare method to compare the plain text password with our hashed password. Our plain
                      text password is in req.body.password and our hash password is in user.password. As you saw
                      earlier the hash password does include the salt. So when we call the compare method bcrypt is
                      going to get that salt and use it to rehash this plain text password. If they are equal then this
                      will return true. We await the promise and store the result in validPassword.

                      If the password is not valid:

                      if(!validPassword) return res.status(400).send('Invalid email or password.');

                      We return a 400 error with the deliberately vague message.

                      Finally, if we get to this point, then we have a valid login. So for now, I just want to send a
                      simple true value to the client:

                      res.send(true);

                      130 - Testing the Authentication ================================

                      So, for now, let's test this new endpoint back in Postman. We can modify the request we had for
                      creating new users. So to save time we can save it as let's say Register User and Create a new
                      collection to put it in called Vidly. In the future we can use Register User instead of opening a
                      new tab, fill out the details and so on.

                      Open a new tab and create a post request to test our authentication endpoint:

                      http://localhost:3000/api/auth

                      In the body of the request we are going to send a Json object:

                      { "email": "programmingwithmosh10@gmail.com", "password": "12345" }

                      If your application hangs it might be that we forgot to import Joi at the top of our auth module:

                      const Joi = require('joi');

                      Send the request again you get a status 200 with a response of true.

                      If we change the password to an invalid value:

                      { "email": "programmingwithmosh10@gmail.com", "password": "123456" }

                      Send the request and you get a status 400 Bad Request with a message of "Invalid email or
                      password"

                      If we send a valid password but change the email so that it is invalid:

                      { "email": "programmingwithmosh101@gmail.com", "password": "12345" }

                      Again we get a status 400 Bad Request with the same generic message.

                      131 - Json Web Tokens =====================

                      So we now have an endpoint for authenticating users. Now we need to modify the response that we
                      return so that instead of returning a true value we return a JSon web token. A Json web token is
                      basically a long string that identifies a user. As a metaphor you can think of it as you drivers
                      license or your passport.

                      So when the user logs in on the server we generate the Json web token:

                      fig xx-xx

                      We give it to the client and then tell them - hey next time you want to come back here and call
                      one of our API endpoints you need to show your passport, you need to show your drivers license. So
                      on the client we need to store this Json web token which is a long string, so we can send it back
                      to the server for future API calls. Now the client can be a web application or a mobile
                      application.

                      If it's a web application, e.g. Angular or React you can use local storage. This is special
                      storage space that is available in every browser. If you're building a mobile app, you have a
                      similar option depending on what platform you use.

                      So now, let me show you an example of a Json web token. Head over to jwt.io. On this website we
                      have a debugger for working with Json web tokens:

                      fig xx-xx

                      In the encoded section you can see a real example of a Json web token. The long string that you
                      see in the encoded section represents a Json object. When this is decoded we will get a Json
                      object. You can see that this string has three parts - each part is color coded.

                      The first part is red, the second purple and the third blue. On the right side you can see the
                      string decoded. The red part is the header of the Json web token. In this header we have two
                      properties. One is alg which is short for algorithm, that determines the algorithm used for
                      encoding this token. The other is type which has a value of JWT - Json Web Token. We never have to
                      worry about this header it's just a standard. What matters to us is the second part - the Payload
                      which is the purple part.

                      So here we have a Json object with three properties:

                      - sub is like a user id - name - admin

                      Now the payload that you see:

                      { "sub": "1234567890", "name": "Mosh Hamedani", "admin": true }

                      is different from the payload I have here, because I modified the Json web token that is on this
                      website. So I generated a custom web token and put it here. What I want to point out here is that
                      this payload:

                      { "sub": "1234567890", "name": "Mosh Hamedani", "admin": true }

                      include public properties about the user just like on your passport you have some properties about
                      yourself like your name, dob, place of birth etc. We have the same exact concept in a Json web
                      token. We can include a few basic public properties about a user and with this every time we send
                      a token from the client to the server we can easily extract the user id from the payload.

                      If we need to know the name of the user then we can simply extract that as well. We don't have to
                      query the database, send the id to get a user object and then extract the name property.

                      By the same token, if you want to know if the user is an admin user or not you can include that
                      here:

                      { "sub": "1234567890", "name": "Mosh Hamedani", "admin": true }

                      Again we don't have to send an extra query to the database, to see if the user with the given id
                      is admin or not.

                      You might be concerned about this approach from a security point of view, because you may think
                      that anyone can simply set this admin property for themselves to true and then they will be
                      treated as admin on the server. That's not how Json web tokens work.

                      The third part of this Json Web Token, in blue, is a digital signature. This digital signature is
                      created based on the content of the Json web token along with the secret or private key. This
                      secret or private key is only available on the server.

                      So if a malicious user gets the Json web token and modifies the admin property the digital
                      signature will be invalid because the content of the Json web token is modified. Now we need a new
                      digital signature but the hacker cannot generate this digital signature because they will need the
                      private key, which is only available on the server. If they don't have access to the server they
                      cannot create a valid digital signature, and when they send this new tampered Json Web Token to
                      the server it will be declined. The server will say this is not a valid Json Web Token.

                      So this is how Json Web Tokens work.

                      132 - Generating Authentication Tokens ======================================

                      If you look at the libraries on the jwt.io website you can see we have various libraries for
                      working with Json Web Tokens for different platforms - .Net, Python, Node, etc.

                      Back in the terminal install jsonwebtoken:

                      npm i jsonwebtoken

                      In the auth module, before return the response we need to create a new Json Web Token. First we
                      need to import the jsonwebtoken module:

                      const jwt = require('jsonwebtoken');

                      Now, back in our route handler, we call the sign method of the jwt object:

                      const token = jwt.sign({ _id: user._id}, 'jwtPrivateKey');

                      The first argument is a payload which can be a simple string or an object. The properties we add
                      to the object are entirely up to us. So in our application for now, I want the payload of our Json
                      web tokens be an object with only one property: _id.

                      The second argument is a secret or private key. This private key is used to create the digital
                      signature. For now we hard code the private key. You would not do this in a real world
                      application, you should not store your secrets in your source code. Later we're going to extract
                      this and put it in an environment variable. You can use any string here - it doesn't have to be
                      jwtPrivateKey.

                      As a result of calling the sign method we will get a token which we store in a constant called
                      token.

                      Finally we return this token to the client:

                      res.send(token);

                      To test this send a post request with a valid email and password from Postman to our
                      authentication endpoint. You should receive a response containing a Json web token. Copy this and
                      then in jwt.io in the debugger paste it in:

                      fig xx-xx

                      So now you can see the payload of our Json web token:

                      { "_id": "5c4235f7c157933a98284ac4", "iat": 1547850077 }

                      We have our _id property which we set (that's the object id for a MongoDB document). You also have
                      iat, which is the time the token was created. We can use this to determine the age of a JWT.

                      133 - Storing Secrets in Environment Variables ==============================================

                      Earlier in the course, when I was talking about express advanced topics, I introduced you to Node
                      package called config. We use this package to store the configuration files of our application in
                      Json files or environment variables.

                      In this lecture we are going to take this private key out:

                      const token = jwt.sign({ _id: user._id}, 'jwtPrivateKey');

                      and store it in an environment variable because, as I told you before, you should never store
                      secrets in your code base. Otherwise these secrets are visible to anyone who as access to your
                      source code. So, back in the terminal, let's install the config module:

                      npm i config


                      Back in the code create a new folder called config and in that folder create a file called
                      default.json to store the default configuration.

                      Add the following simple Json object to this file:

                      { "jwtPrivateKey": "" }

                      We just add one setting. We set this to an empty string, we don't specify the actual value. Here
                      we're just defining a template for all the settings in our application.

                      Create another file in the config folder called custom-environment-variables.json So, as we
                      discussed before, in this file we specify the mapping between our application settings and our
                      environment variables. So copy the Json object from default.json into
                      custom-environment-variables.json. We also map the setting to an environment variable called
                      jwtPrivateKey:

                      { "jwtPrivateKey": "vidly_jwtPrivateKey" }

                      As a best practice, as discussed before, it is better to prefix this with an application name so
                      you don't end up one application setting overwriting another application setting. So we use
                      vidly_jwtPrivateKey.

                      Go back to auth.js module where we are currently referencing the secret:

                      const token = jwt.sign({ _id: user._id}, 'jwtPrivateKey');

                      We are gong to replace this with a call to config.get method:

                      const config = require('config');

                      Back in the post method we call config.gert and passw the name of our application setting:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      That is not a secret it's the name of our application setting. The actual value or secret will be
                      in an environment variable.

                      One last change, in index.js. When the application starts we want to make sure that this
                      environment variable is set. Otherwise we need to terminate the application because our
                      authentication endpoint cannot function properly

                      So, at the top of the file, we load the config module

                      const config = require('config');

                      We use the config.get method again:

                      if(!config.get('jwtPrivateKey')) { console.error('FATAL ERROR: jwtPrivateKey is not defined.');
                      process.exit(1); }

                      If the environment variable is not defined we log a fatal error and then exit the process. Earlier
                      you learned about the process object. This is one of the global objects in Node. Here we have a
                      method called exit to which we supply a code. 0 indicates success. Anything but 0 indicates
                      failure. Often we use exit(1) if you want to exit the process in case of an error.

                      So, at this point, we have not set the environment variable. Let's run the application and see
                      what happens:

                      FATAL ERROR: jwtPrivateKey is not defined. [nodemon] app crashed - waiting for file changes before
                      starting...

                      You might think the application is still running because nodemon has not terminated. But if you go
                      to postman and send an http request to the application, you will see our application is not
                      responding.

                      If the application crashes nodemon continues to run. To demonstrate use node to run the
                      application instead:

                      node index.js

                      You receive the same error:

                      FATAL ERROR: jwtPrivateKey is not defined.

                      but node terminates and we are back in the terminal.

                      Now let's set the environment variable. As discussed before on Mac you use export on Windows you
                      use set.

                      I set the environment variable on my Windows Machines to the following: vidly_jwtPrivateKey
                      myinSecureKey

                      If you back to postman and send another request to login you should see a valid Json web token
                      that is signed with a private key that is stored in an environment variable:

                      eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiI1YzQyMzVmN2MxNTc5MzNhOTgyODRhYzQiLCJpYXQiOjE1NDc4OTE5NTR9.xROPzBJyEB2VkHTGgzF9lHM-ou0xnSuF0CCt40I-YG8

                      View Environment Variables from the Command Line ================================================
                      SET View all. SET prefix View all variables with names starting with prefix.

                      NOTE - doesn't seem to work from terminal in Visual Studio Code

                      134 - Setting Response Headers ==============================

                      So, in the current implementation when the user logs in we generate a Json web token and return it
                      in the body of the response. Now let's take this application to the next level. Let's imagine when
                      the user registers we want to assume they are logged in, so they don't have to login separately.

                      Of course this requirement does not apply to every application. Sometimes you want to enforce the
                      user to verify their email address, so after this sign off you send them an email and they click a
                      link. So the process is different.

                      However, in this course, let's imagine that vidly is an application that runs locally in a video
                      store. So, people who use this application are people who work in this video store so you don't
                      need to verify their email address. So the first day that they join the store, they need to create
                      an account and boom they're logged in.

                      So let's go to the post method in our users module where we register a new user If you look the
                      response we're returning here, we're returning an object with three properties:

                      res.send(_.pick(user, ['id', 'name', 'email'])

                      Now, we could add the Json web token as another property here, but that's a bit ugly because it's
                      not a property of a user. A better approach is to return the Json web token in an http header.

                      So just like we have headers in our request we also have headers in our response. So I'm going to
                      go back to our Auth module and borrow this line of code:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      for generating the token. Back in the users module before we send the response to the client we
                      generate the token then we call response.header:

                      res.header('x-auth-token', token).send(_.pick(user, ['id', 'name', 'email']));

                      The first argument is the name of the header. Because we are sending a custom header, we set the
                      header prefix to x- and then supply an arbitrary name like auth-token. The second argument is our
                      value, which in this case is our token. With this simple change we set the header and then send
                      the response to the client.

                      On the line above we are using jwt:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      as well as the config module. So we need to import these at the top of our module:

                      const jwt = require('jsonwebtoken'); const config = require('config');

                      Now let's test this:

                      nodemon

                      In postman find the Register user template and modify the email in the req.body:

                      { "name": "Mosh Hamedani", "email": "notregisteredbefore1@gmail.com", "password": "12345" }

                      Send this and you get the following response as you did before:

                      { "id": "5c43208d29738a3c10b21544", "name": "Mosh Hamedani", "email":
                      "notregisteredbefore1@gmail.com" }

                      Look in the headers tab and you should see a new header:

                      x-auth-token
                      →eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiI1YzQzMjI2ZWIwMTE2ZDI2ODA1NmEyMjMiLCJpYXQiOjE1NDc5MDM1OTh9.eRdcIsY-G8bv04NNhhPts0QYmsSHnTAdaKxzSlPG0oE

                      This is set to our Json token. So in our client app, when we register the user we can read this
                      header, we can store this Json web token, on the client, and next time we go to make an API call
                      we can send this to the server.

                      135 - Encapsulating Logic in Mongoose Modules =============================================

                      Now there is a problem in our current implementation. In the users module this is how we generate
                      a Json web token:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      We have the exact same code in the auth module:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      Look at the payload of this Json object - currently we only have the id property. Chances are
                      we're going to add another property in this payload - maybe the name of the user, maybe their
                      email address, maybe their role, perhaps you want to know if they are an admin user or not. With
                      the current implementation every time we want to change this payload we have to go to the other
                      module and make the exact same change. In this lecture we will examine how to encapsulate this
                      logic in a single place.

                      Now, where should we move this logic to? An amateur programmer may think okay, I will create a
                      function like this:

                      function generateAuthenticationToken() {

                      }

                      Put this function somewhere that we can reuse, maybe in another module, that we can import in both
                      auth and user modules, and with this we have the logic in a single place. Well, that is true, it
                      works but with this approach you will end up with a lot of functions hanging around all over the
                      place.

                      In object oriented programming we have a principle called information expert principle. That means
                      an object that has enough information and is an expert in a given area should be responsible for
                      making decisions and performing tasks.

                      As a real world example, think of a chef. A chef has the knowledge of cooking. That's why the act
                      of cooking in a restaurant is done by the chef, not by the waiter. The waiter doesn't have the
                      right knowledge or information about cooking at a restaurant. So if chef is an object then we
                      leave the actual cooking to the chef.

                      Take this principle an apply it in this code. So here:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      as part of creating the Json web token, in the payload, we need the id of the user. Tomorrow we
                      may need the name of the user or their email. All this information is encapsulated where? In the
                      user object. So it's the user object that should be responsible for generating the authentication
                      token.

                      So the generateAuthenticationToken function we described above should not be hanging somewhere in
                      a module, that should be a method in the user object. So we need to add the
                      generateAuthenticationToken method to the user object that we load from the database:

                      const token = user.generateAuthenticationToken();

                      This will give us our token. How can we add this? We need to go back to our user module where we
                      defined our user model and make a simple change. So here's our user model:

                      const User = mongoose.model('User', new mongoose.Schema({ name: { type: String, required: true,
                      minlength: 5, maxlength: 50 }, email: { type: String, required: true, minlength: 5, maxlength:
                      255, unique: true }, password: { type: String, required: true, minlength: 5, maxlength: 1024 }
                      }));

                      We need to extract the definition of this schema and put it in a separate constant because we're
                      going to work with that separately. So extract the schema code from the call to mongoose.model:

                      const userSchema = new mongoose.Schema({ name: { type: String, required: true, minlength: 5,
                      maxlength: 50 }, email: { type: String, required: true, minlength: 5, maxlength: 255, unique: true
                      }, password: { type: String, required: true, minlength: 5, maxlength: 1024 } });

                      And now add the following code to create the user model:

                      const User = mongoose.model('User', userSchema);

                      Now we want to add the generateAuthToken method to this schema:

                      userSchema.methods.generateAuthToken = function() {}

                      userSchema.methods returns an object to which you can add additional key value pairs. So we add a
                      key: generateAuthToken which we set to a function.

                      When we do this, our use object will have a method called generateAuthToken. In this function we
                      can have parameters. So if you have a parameter then when calling this method we can pass
                      arguments. In this, we don't need any parameters. So, let's cut the logic for generating the token
                      from auth.js:

                      const token = jwt.sign({ _id: user._id}, config.get('jwtPrivateKey'));

                      and paste it into our generateAuthToken method in the user module. So in the payload:

                      { _id: user._id}

                      we need the id of the user. How do we get that? Well, now our generateAuthToken method is part of
                      the user object so in order to reference the object itself we replace user with this:

                      { _id: this._id}

                      Remember using this means we should use the regular function syntax, you cannot use an arrow
                      function:

                      userSchema.methods.generateAuthToken = () => { const token = jwt.sign({ _id: user._id},
                      config.get('jwtPrivateKey')); }

                      because, as discussed before, arrow function don't have their own this object. this in an arrow
                      function references the calling function.

                      Typically we use arrow function for standalone function. If you want to create a method that is
                      part of an object you should not use an arrow function.

                      So we have the token, you can finally return the token:

                      userSchema.methods.generateAuthToken = function() { const token = jwt.sign({ _id: user._id},
                      config.get('jwtPrivateKey')); return token; }

                      Back in the auth module we generate the token:

                      const token = user.generateAuthToken();

                      and send it to the user:

                      res.send(token);

                      We need to make the same change in our users module.

                      Remove the require statements for config and jwt from the auth module:

                      const config = require('config'); const jwt = require('jsonwebtoken');

                      and add them to the top of the user module. Test the application by registering a new user in
                      Postman:

                      You should see the following in the body of the response:

                      { "id": "5c434756a5687a327067fc8c", "name": "Mosh Hamedani", "email":
                      "notregisteredbefore6@gmail.com" }

                      and our authentication should be visible in the headers section:

                      x-auth-token
                      →eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiI1YzQzNDc1NmE1Njg3YTMyNzA2N2ZjOGMiLCJpYXQiOjE1NDc5MTMwNDd9.O8lzuUh_bNumSsmrRZozQB2zRIazNYRJlgH9ZLCYVng

                      136 - Authorization Middleware ==============================

                      So at the beginning of this section we decided to protect operations that modify data and only
                      make them available to users that have authenticated.

                      For example, in genres.js the post endpoint that creates a new genre should only be available to
                      authenticated users:

                      router.post('/', async (req, res) => { const { error } = validate(req.body); if (error) return
                      res.status(400).send(error.details[0].message);

                      let genre = new Genre({ name: req.body.name }); genre = await genre.save();

                      res.send(genre); });

                      We can enforce this with some logic that reads the req header:

                      const token = req.header('x-auth-token');

                      The request object has a method called header to which we supply the name of the header
                      (x-auth-token). We expect a JWT stored in this header so we store it in token.

                      Next we validate the token. If the token is valid then we give access to the api endpoint
                      otherwise we return a response code 401 (the client doesnt have the authentcation credentials to
                      access this resource):

                      const token = req.header('x-auth-token'); res.status(401);

                      We don't want to repeat this logic in every route handler that needs to modify data. So we need to
                      put this logic in a middleware function (which we discussed back in the section Express - Advanced
                      Topics)

                      So we put this logic in a middleware function and then we can apply that function in route
                      handlers that need to modify data.

                      First add a new folder called middleware then a file called auth.js

                      Add a function to this file called auth which accepts three parameters:

                      function auth(req, res, next)

                      Next is used to pass control to the next middleware function in the request processing pipeline.
                      If this concept feels unfamiliar to you then go back to the section called express admin topics,
                      because we explored middleware functions in detail.

                      In the body of the function implement logic to attempt to get the token. If we don't have a token
                      then we return a 401 response with a message:

                      function auth(req, res, next) { const token = req.header('x-auth-token'); if(!token)
                      res.status(401).send('Access denied. No token provided'); }

                      This helps the client to figure out why they cannot access this resource. If there is a token we
                      need to verify that it is valid using JWT module. On the top of the file import jsonwebtoken:

                      const jwt = require('jsonwebtoken');

                      Next call the verify method passing the token as the first argument and the private key for
                      decoding the token as the second:

                      const decoded = jwt.verify(token, config.get('jwtPrivateKey'));

                      For the above logic to work you will need to import the config module:

                      const config = require('config');

                      Now we call jwt.verify:

                      const decoded = jwt.verify(token, config.get('jwtPrivateKey'));

                      As the first argument we pass a token, and as the second argument we pass the private key for
                      decoding this token. So, because we store that private key in an environment variable, we need to
                      use the config module to read it. Add a require statement for config at the top of the file:

                      const config = require('config');

                      If the supplied token is valid the verify method will return the decoded payload which we assign
                      to const called decoded.

                      However if the token is not valid the verify method will throw an exception. We can catch this
                      exception and return a 400 response - bad request:

                      try { const decoded = jwt.verify(token, config.get('jwtPrivateKey')); } catch(ex) {
                      res.status(400).send('Invalid token.'); }

                      Again, with this error message, we can troubleshoot the authentication issues. So if I'm the
                      client I cannot access a given API endpoint, we look at the error message, okay we realize we sent
                      an invalid token. Then we look at the logic on the client where we get teh token and send it to
                      the server. So this is our catch block.

                      Back in the try block we add our decoded payload to our req:

                      req.user = decoded;

                      We add the user property to our request object and set this to decoded. This is different to
                      earlier when we only put the user _id property in the payload:

                      userSchema.methods.generateAuthToken = function() { const token = jwt.sign({ _id: user._id},
                      config.get('jwtPrivateKey')); return token; }

                      So we added a generateAuthToken method to our userSchema. We created a Json web token and you can
                      see the payload is just the user id. So when we decode the jwt the object we get will just contain
                      the id. We put this in the request ( in auth.js) as a user object.

                      req.user = decoded;

                      So in our route handlers we can access request.user._id and so on.

                      Now in the try block we need to call next() to pass control to the next middleware function in the
                      request processing pipeline - in our case that's our route handler so we call next:

                      next();

                      As we discussed before, in middleware functions, we either terminate the request/ response life
                      cycle or pass control to the next middleware function.

                      There is a small issue with the code. In the case where we don't have a token we send a status 401
                      to the client but we should also make sure that we exit from the function:

                      if(!token) return res.status(401).send('Access denied. No token provided');

                      The last thing to do is export the auth function:

                      module.exports = auth;

                      Alternatively we can make this code more concise by exporting the function directly instead:

                      module.exports = function (req, res, next) {}

                      137 - Protecting Routes =======================

                      So now that we have a middleware function we could either go to index.js where we are already
                      applying middleware functions:

                      app.use(express.json());

                      So could add our middleware function in index.js and then it would be executed before every route
                      handler. However, we don't want to do this because not all api endpoints should be protected.

                      Some of our API endpoints should be public like registering a user or logging in, or getting the
                      list of genres or customers. So in this case we want to apply this middleware function selectively
                      to certain endpoints.

                      So, back to the genres module, here's our post route handler:

                      router.post('/', async (req, res) => {

                      The first argument is the route, the second is optionally middleware and the third will be the
                      actual route handler. So at the top of the genres file let's import the middleware function:

                      const auth = require('../middleware/auth');

                      Now modify the post method to pass auth as a middleware function to be executed before the other
                      middleware function which in this case is our route handler:

                      router.post('/', auth, async (req, res) => { }

                      Now let's test this in Postman by sending a POST request to the genres endpoint (make sure you
                      don't send the authentication token in the header):

                      http://localhost:3000/api/genres

                      You should receive response code 401 Unauthorized and the message:

                      Access denied. Not token provided

                      Now in the Headers tab of Postman provide an invalid token by entering x-auth-token for the key
                      and 1234 for the value.

                      You should receive response code 400 Bad Request and the message:

                      Invalid token.

                      Finally let's supply a valid token (copied from our POST User method that we use to register a new
                      user). Also make sure you supply a valid JSon object in the body of the request.

                      You should receive response code 200 OK and the new JSON genre object in the body of the response.

                      As an exercise apply this middleware function can now be applied to other middleware functions
                      that modify data.

                      138 - Getting the Current User ==============================

                      In a lot of applications there are times when we want to get information about the currently
                      logged in user.


                      So in this lecture we are going to add a new api endpoint to our users.js module for getting the
                      current user.

                      Currently we only have 1 route handle for creating a new user in the users.js module.

                      We need to add another handler for get methods. Now here as the route or the path we can pass a
                      parameter:

                      router.get('/:id');

                      But this means the client should send the id to the server. Whilst this approach is perfectly fine
                      there are times, perhaps for security reasons, you dont want to have an endpoint like this because
                      then I can send the id of another user and look at their account where there may be some
                      information that should not be visible publicly.

                      An often used approach to get information about the current user is to have an api endpoint like
                      me:

                      router.get('/me');

                      With this the client is not going to send the user id - it will be obtained from the Json Web
                      Token.

                      It is not possible to forge someone else's Json Web Token because in order to do so I would need
                      to create a new digital signature for that Json Web Token.

                      Now let's add the route handler:

                      router.get('/me', auth, async (req, res) => { const user = await
                      User.findById(req.user._id).select('-password'); res.send(user); });

                      The me api endpoint should only be available to authenticated users so we need to import the auth
                      middleware:

                      const auth = require('../middleware/auth');

                      To clarify here auth represents authorization NOT authentication because authentication is about
                      validating the username and password. In this case we want to see if the user has permission to
                      access a resource or not and that is authorization.

                      So the auth middleware will prevent any requests that don't provide a valid Json Web Token from
                      executing the code in the route handler. The route handler has access to the req.user object which
                      means we can access it's _id property:

                      (req.user._id)

                      So instead of passing the _id property in the path or route we get it from req.user._id which
                      actually comes from our Json Web Token which makes it a more secure approach.

                      We call User.findById excluding the password (we don't want to send this back to the client):

                      const user = await User.findById(req.user._id).select('-password');

                      Finally you can send this user object to the client:

                      res.send(user);

                      Let's test in Postman using GET request:

                      http://localhost:3000/api/users/me

                      Initially dont specify a JWT and you will receive a 401 Unauthorized response with the message:

                      Access denied. No token provided.

                      Now add a valid JWT (you can get this from Register User) in the header and click send. You will
                      recieve a 200 OK response and the user account details that match the supplied JWT in the body of
                      the response:

                      { "_id": "5ad5fd6ed4b65e98dee78835", "name": "Mosh Hamedani", "email": "maxsage@gmail.com", "__v":
                      0 }

                      Note the password has been excluded.

                      139 - Logging Out Users =======================

                      In our routes/auth module we defined this route:

                      router.post('/', async (req, res) => { }

                      For authenticating users. What about logging out users? Do we need a separate route for that? No,
                      because we are not storing this token:

                      const token = user.generateAuthToken();

                      anywhere in the server, so we don't need a separate route handler to delete this token. So
                      technically you need to implement the logging out feature on the client not on the server.

                      So on the client application when the user wants to log out you simply delete that token from the
                      client. Now there are courses and tutorials that teach you to store the token on the server in the
                      database - this is very bad practice because these tokens are like keys that give a client access
                      to protected api endpoints. If a hacker can get access to your database they can see all these
                      tokens for authenticated users - they don't even have to know the password for a user. They can
                      simply use one of the stored tokens to execute requests on the behalf of a user.

                      So you should not store tokens in your database. If you really want to store the token in the
                      database make sure you encrypt it.

                      Storing a token in plain text in the database is like getting the passport or drivers licenses of
                      all the users, putting them in a central place, and then anyone malicious or otherwise, who has
                      access to the central place can simply get the passport and drivers licenses and imitate other
                      clients.

                      So, once again, do not store the tokens on the server. Store them on the client. As a security
                      best practice, whenever you are sending the token from the client to the server, make sure to use
                      https. So a hacker, sitting in the middle, sniffing traffic cannot read the token sent from client
                      to the server because the data is encrypted.

                      140 - Role Based Authorization ==============================

                      So far we have implemented authentication and authorization successfully. Now let's take this
                      application to the next level. Let's imagine certain operations such as deleting data can only be
                      performed by admins.

                      Let's examine how to implement role based authourization.

                      In models/user.js examine the userSchema. Currently we have three properties:

                      - name - email - password

                      We need to add another property to the userSchema called isAdmin of type Boolean:

                      isAdmin: Boolean

                      In MongoDB Compass make one of the users an admin by editing a document and adding a field after
                      password. Don't forget to change the default type from string to Boolean. So, now we have a user
                      that is an admin.

                      When they login we need to include the isAdmin property in the JWT payload so next time the send
                      this JWT to the server we can extract this property directly from the token. We don't have to get
                      the id, go into the database, and see if you're an admin or not. Again, as discussed previously,
                      with a digital signature included in a Json web token, a malicious user cannot change the value of
                      isAdmin for their user account. If they make any changes, they have to regenerate the digital
                      signature - this requires knowing the private key that we stored in an environment variable on the
                      server.

                      Now back in the user model when we generate the token we want to add our new isAdmin property in
                      the payload:

                      const token = jwt.sign({ _id: this._id, isAdmin: this.isAdmin }, config.get('jwtPrivateKey'));

                      This is the benefit of encapsulating this logic inside the user object. It means there is a single
                      place that we need to modify. Previously we had this logic in two different places - meaning we
                      would have had to implement this change twice.

                      Now on the server we need a new middleware function to check if the current user is an admin or
                      not. In the middleware folder and a new file called admin.js with the following code:

                      module.exports = function(req, res, next) { }

                      We set module.exports to a middleware function that takes a request, a response and a reference to
                      the next middleware function in the request processing pipeline. So here we're assuming this
                      middleware function will be executed after the authorisation middleware function. Our
                      authorisation middleware function sets req.user which means we can access that in our new
                      function:

                      module.exports = function(req, res, next) { if(!req.user.isAdmin) return
                      res.status(403).send('Access denied.'); }

                      If req.user.isAdmin is false we return response code 403 which means forbidden. This is one of the
                      areas that a lot of developers get wrong. So we have:

                      401 Unauthorized - the user tries to access a protected resource without a valid JWT 403 Forbidden
                      - the user sends a valid JWT but they are not authorized to access the resource (e.g. non-admin)


                      So if the user isAdmin we pass control to the next middleware function:

                      next();

                      Which in this case is the route handler. Now we are going to apply this middleware function on one
                      of our routes. In the delete api endpoint of genres we pass two middleware functions using an
                      array

                      router.delete('/:id', [auth, admin], async (req, res) => { }

                      The first one is auth and the second is admin. These middleware functions will be executed in
                      sequence. First auth - if the client sends a valid Json web token, then we'll get to the second
                      middleware function. If the user is an admin then the third middleware function or route handler
                      will be executed. Import the admin middleware function at the top of genre.js:

                      const admin = require(''../middleware/admin');

                      141 - Testing the Authorization ===============================

                      So back in MongoDB Compass, go to the genres collection and copy a valid genre id. In Postman send
                      a delete request to:

                      http://localhost:5000/api/genres/5c43a8a94e22960a2c26ef3f

                      So initially I don't have a token.

                      We receive a response status 401 Unauthorized with the message:

                      Access denied. No token provided.

                      Next use Postman to login with a user that is not an admin and copy the resulting JWT. You can
                      verify that the user is not an admin using the debugger at jwt.io - you should only see the _id
                      and _iat properties . Let's verify that this user cant delete genres.

                      You will receive a response status 403 Forbidden with the message:

                      Access denied

                      Now login at the auth endpoint with a user that IS NOT an admin:

                      http://localhost:3000/api/auth

                      In the response body you should receive a JWT:

                      eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1NDc5OTM3NDd9.LHozVfSKCYNMdXoGnZ_qcDGqbjFjHp8RuSMolDd6Ahc

                      We can verify that this user is not an admin by going to JWT debugger (jwt.io) and pasting the JWT
                      into the encoded section:

                      fig xx-xx

                      If you check the payload you should see only the id property (and iat) we don't have isAdmin. So,
                      this user should not be able to delete a genre. We can verify that by using Postman to send
                      another delete request to the genres endpoint:

                      http://localhost:5000/api/genres/5c43a8a94e22960a2c26ef3f

                      We add the x-auth-token to the headers (make sure you are in headers NOT Params. Send this request
                      and you should get 403 - forbidden with a message in the body:

                      Access denied.

                      Now, in contrast, if we log in with a user that is an admin then we should be able to delete the
                      genre.

                      So now login at the auth endpoint with a user that IS an admin:

                      http://localhost:3000/api/auth

                      Copy the JWT (which is a little bit longer than previous JWT's) into JWT debugger. If you check
                      the payload then isAdmin should be set to true.

                      { "_id": "5c445adddfbdc04b04613d8a", "isAdmin": true, "iat": 1547994978 }

                      Next, copy and paste this JWT in the DELETE Genre request in Postman, hit Send and you will
                      receive a response status 200 OK and the deleted Genre object in the body of the response:

                      { "_id": "5c43a8a94e22960a2c26ef3f", "name": "Griller", "__v": 0 }


                      One last thing before we finish the lecture. In this simple application we have a single isAdmin
                      property to determine if the user is an admin or not. In your application you might have multiple
                      roles:

                      admin moderator etc.

                      In that case you would need a property like roles:

                      isAdmin: Boolean, roles: []

                      This would be an array. This could contain strings or complex objects, that really depends on the
                      scope of your application. In a more advanced application instead of managing roles you would
                      manage operations, that is the operations that the user is allowed to perform:

                      isAdmin: Boolean, roles: [], operations []

                      operations would be an array of complex objects. For example, for a given user, we would say this
                      user is allowed to delete genres, or create genres. So you would control access at a more granular
                      level. Now, irrespective or which approach you choose, the big picture is still the same. You pass
                      something that determines the level of access of the user in the JWT that is generated as part of
                      authenticating the user. Then you would add middleware, where currently we are just checking the
                      value of this boolean property:

                      if(!req.user.isAdmin) return res.status(403).send('Access denied.');

                      In a more complex application we can look at the roles array or the operations array. Based on
                      that, you make a decision, you either decline access:

                      return res.status(403)

                      or grant it:

                      next();

                      142 - Recap ===========

                      Authentication and Authorization ---------------------------------

                      So, in this section, you learned that:

                      - Authentication is the process of determining if the user is who he/she claims to be. It involves
                      validating their email/password. - Authorization is the process of determining if the user has
                      permission to perform a given operation. - To hash passwords, use bcrypt:

                      Hashing passwords -----------------

                      const salt = await bcrypt.genSalt(10); const hashed = await bcrypt.hash(‘1234’, salt);

                      // Validating passwords const isValid = await bcrypt.compare(‘1234’, hashed);

                      A JSON Web Token (JWT) is a JSON object encoded as a long string. We use them to identify users.
                      It’s similar to a passport or driver’s license. It includes a few public properties about a user
                      in its payload. These properties cannot be tampered because doing so requires re-generating the
                      digital signature.

                      When the user logs in, we generate a JWT on the server and return it to the client. We store this
                      token on the client and send it to the server every time we need to call an API endpoint that is
                      only accessible to authenticated users.

                      To generate JSON Web Tokens in an Express app use jsonwebtoken package.

                      Generating a JWT ----------------

                      const jwt = require(‘jsonwebtoken’); const token = jwt.sign({ _id: user._id}, ‘privateKey’);

                      Never store private keys and other secrets in your codebase. Store them in environment variables.
                      Use the config package to read application settings stored in environment variables.

                      When appropriate, encapsulate logic in Mongoose models:

                      Adding a method to a Mongoose model ---------------------------=-------

                      userSchema.methods.generateAuthToken = function() { } const token = user.generateAuthToken();

                      Implement authorization using a middleware function. Return a 401 error (unauthorized) if the
                      client doesn’t send a valid token. Return 403 (forbidden) if the user provided a valid token but
                      is not allowed to perform the given operation.

                      You don’t need to implement logging out on the server. Implement it on the client by simply
                      removing the JWT from the client.

                      Do not store a JWT in plain text in a database. This is similar to storing users’ passports or
                      drivers license in a room. Anyone who has access to that room can steal these passports. Store
                      JWTs on the client. If you have a strong reason for storing them on the server, make sure to
                      encrypt them before storing them in a database.

                      143 - Introduction ==================

                      In our current implementation of Vidly app, we have assumed an ideal world where everything works
                      successfully. However, in the real world, there are always unexpected errors. For example, it is
                      possible that our connection to MongoDB drops out for whatever reason. So, as a best practice we
                      should count on these unexpected situations and handle them properly. This means we should:

                      - send a proper error message to the client - log the exception on the server

                      This means later we can look at the log, and see what the frequent issues are and how we can
                      improve the application.

                      Let's demonstrate with a real world scenario where the MongoDB server dies. So, here in the
                      terminal, we are running the application with nodemon:

                      [nodemon] 1.17.1 [nodemon] to restart at any time, enter `rs` [nodemon] watching: *.* [nodemon]
                      starting `node index.js` Listening on port 5000... Connected to MongoDB...

                      and we also have another terminal window open running the Mongo Daemon:

                      2019-01-20T10:24:09.236-0800 I CONTROL [initandlisten] MongoDB starting : pid=3236 port=27017
                      dbpath=C:\data\db\ 64-bit host=XPS15 2019-01-20T10:24:09.236-0800 I CONTROL [initandlisten]
                      targetMinOS: Windows 7/Windows Server 2008 R2 2019-01-20T10:24:09.237-0800 I CONTROL
                      [initandlisten] db version v3.6.3

                      This is the background service that is running on port 27017:

                      2019-01-20T18:24:10.138+0000 I NETWORK [initandlisten] waiting for connections on port 27017

                      In Postman we have a tab open to send a get request to api/genres:

                      http://localhost:3000/api/genres

                      Currently if we send this request we get a 200 response and some result(s) displayed in the body
                      of the response:

                      [ { "_id": "5c43a7aa7e7aa5349c1ca9f5", "name": "Griller", "__v": 0 }, { "_id":
                      "5c43a8f94e22960a2c26ef40", "name": "Griller", "__v": 0 }, { "_id": "5c43a9e3a342de3bfc0b33a8",
                      "name": "Griller", "__v": 0 } ]

                      Stop the process in mongoDB using Ctrl+C.

                      2019-01-20T19:02:09.938+0000 I CONTROL [consoleTerminate] shutting down with code:12

                      Now, let's see what happens when we use postman to send the request one more time. the Send button
                      in postman should change to Sending... and after approx 30 seconds (although I got a message
                      immediately saying "mongoError: Topology was destroyed" meaning the connection was interrupted
                      whilst MongoDB was being written to) you will receive an error message in the terminal where your
                      Node application is running:

                      (node:1084) UnhandledPromiseRejectionWarning: MongoError: MongoNetworkError: failed to reconnect
                      after 30 attempts with interval 1000ms

                      By default, when you connect to MongoDB, if the connection cannot be established, MongoDB driver
                      will attempt to reconnect 30 times in 1 second intervals. Look at the warning in the terminal:

                      DeprecationWarning: Unhandled promise rejections are deprecated. In the future promise rejections
                      that are not handled will terminate the Node.js process with a non-zero exit code.

                      This means in future versions of Node the application will stop running if it encounters an error
                      like this and no further clients will be served. Now in this particular demonstration, yes, I shut
                      down our MongoDB server so it wouldn't really matter if this process is live or not. But let's
                      imagine in a real world scenario is going down for, let's say, 1 minute. Then is

                      Imagine a scenario where our mongodb server is going to be shutdown for one minute. With the
                      current implementation our node process will terminate and will not be able to server any other
                      client even after mongodb restarts.

                      We need to properly hand these scenarios, and that's what you're going to learn in this section.

                      144 - Handling Rejected Promises ================================

                      Whenever you see unhandled promise rejection that means your using a promise which means your
                      dealing with asynchronous code that has thrown an error that hasn't been handled properly In
                      genres.js in the get route you can see the find promise:

                      router.get('/', async (req, res) => { const genres = await Genre.find().sort('name');
                      res.send(genres); });

                      Here we have a promise:

                      Genre.find().sort('name');

                      That is awaited here:

                      await Genre.find().sort('name');

                      There is currently no try/catch block in the code to handle rejected promises.

                      This implementation is the same as getting a promise, calling then but not calling catch to handle
                      rejections:

                      Genre.find() .then() .catch()

                      So if your using the promise syntax with then you should always call catch to handle exceptions.
                      If your using async and await you should always have try/catch blocks.

                      So add a try catch block that responds with status 500 internal server error and send a message:

                      try { const genres = await Genre.find().sort('name'); res.send(genres); } catch (ex) { // Log the
                      exception res.status(500).send('Something failed'); }

                      We will add logging later in this section. Start the mongo demon and then run the vidly
                      application, stop the mongo demon and then submit a get genres request from postman

                      Now in Postman after about 30 seconds you should see a response status 500 and the message:

                      Something failed.

                      Importantly if you look at the terminal window that you used to launch the vidly application you
                      should no longer see the UnhandledPromiseRejectionWarning which will result in the termination of
                      this process in future version of node.

                      145 - Express Error Middleware ==============================

                      So, in the last lecture, we took the first step to handle errors properly. But there is a problem
                      in the current implementation. Let's say, tommorow, we need to change the message sent to the
                      client:

                      res.status(500).send('Something failed');

                      With the current implementation you have to go to every route handler where we have used a
                      try/catch block to modify the message. Also if you are performing logging and further down the
                      line you want to implement it slightly differently again you will need to visit every route
                      handler.

                      We want to move the error handling logic to somewhere central. Goto index.js where the middleware
                      is being registered. In express there is a special kind of middleware function called error
                      middleware. We register that middleware function after all the existing middleware functions. So,
                      after the other app.use statements, we call app.use:

                      app.use(function(err, req, res,next){

                      });

                      Pass a middleware function with 3 parameters - request, response and next. We also add the fourth
                      argument here at the front. That's the exception or error that we catch somewhere in the
                      application.

                      Now, in this function, we add all the logic for handling errors in our application Cut the logic
                      from genres.js and paste it into the error middleware function:

                      app.use(function(err, req, res, next){ // Log the exception res.status(500).send('Something
                      failed.'); })

                      Now back in the catch block in genres.js add the next parameter to pass control to the next
                      middleware function in the request processing pipeline. In the catch block we also call next
                      passing the exception as an argument:

                      router.get('/', async (req, res, next) => { try { const genres = await Genre.find().sort('name');
                      res.send(genres); } catch(ex) { next(ex); } });

                      Now because in index.js we register the error middleware function AFTER all the other middleware
                      functions when we call next we will end up here:

                      function(err, req, res, next)

                      The first argument passed to this function will be the exception. This new implementation gives us
                      a single place to handle errors.

                      In a real world example the logic for logging an exception might be several lines long. We don't
                      really want to put this code in index.js which is really for orchestration and high level
                      arrangement. The details should be encapsulated in a different modules. For this reason we will
                      move this middleware function to a separate module. We will add a new file called error.js to the
                      middleware folder and move the error handling and logging function there:

                      module.exports = function(err, req, res, next) { // Log the exception
                      res.status(500).send('Something failed.'); }

                      Import the module in index.js

                      const error = require('./middleware/error');

                      Now modify the app.use statement to pass in the error function.

                      app.use(error);

                      NOTE that we don't call the function, we just pass a reference to it. Whilst we have achieved a
                      better design it is still necessary for us to wrap the other endpoints in try/catch blocks. This
                      is repetitive. In the next lecture we will look at how to improve this implementation.

                      146 - Removing try/catch Blocks ===============================

                      So we still have a try/catch block in the genres get route handler. The problem with this
                      implementation is that we have to repeat this try/catch block in every route handler. Also the try
                      catch logic is adding noise to the code which is distracting us from the logic that belongs to
                      this route handler.

                      Ideally we should move this high-level code somewhere else to a single function:

                      function asyncMiddleware() { try { // ... } catch(ex) { next(ex); } }

                      So we define a function called asyncMiddleware with a try block that executes some code which will
                      vary depending on the route handler. Then we have the catch block that takes an exception where we
                      simply call next passing in the exception.

                      Now what if we pass a function (our route handler function) as an argument to the asyncMiddleware
                      function? It means we can call the function in the try block:

                      function asyncMiddleware (handler) { try { handler(); } catch(ex) { next(ex); } }

                      This means we can simplify the code in the genres get route handler - we no longer need the try
                      block, the catch block and the next parameter:

                      router.get('/', async (req, res) => { const genres = await Genre.find().sort('name');
                      res.send(genres); });

                      Look at the anonymous async function that you are passing in the code above. Eventually we want to
                      pass this function as an argument to the asyncMiddleware function.

                      Because handler is an async function we should await it and mark the function as async:

                      async function asyncMiddleware (handler) { try { await handler(); } catch(ex) { next(ex); } }

                      Now modify the get route handler in genres so that for the second method we call the
                      asyncMiddleware function and pass the anonymous function that is currently in the get route as an
                      argument that we call handler:

                      router.get('/', auth, asyncMiddleware(async (req, res) => { const genres = await
                      Genre.find().sort('name'); res.send(genres); }));

                      There is a slight issue here - in the asyncMiddleware function the handler function:

                      await handler();

                      That we are calling needs access to 2 arguments - the request and response. You can see the
                      anonymous function in the get route uses these parameters:

                      async(req, res)

                      So when calling it (as we do in asyncMiddleware) we should pass the req and res objects:

                      await handler(req, res);

                      The issue we have here is that nowhere in the asyncMiddleware function have we defined req, res
                      and next. The only parameter in asyncMiddleware is a parameter to another function which we call
                      handler.

                      So the question remains - how do we get access to these three objects? Before we discuss that
                      question we need to investigate a deeper issue. In the current implementation we are calling the
                      asyncMiddleware function and passing the handler as an argument:

                      asyncMiddleware(...handler code...)

                      So we are CALLING the function. However when defining an express route we are not going to call
                      our middleware or route handler functions - we simply pass a reference to a function.

                      To clarify we will define another temporary route as an example(delete it later):

                      router.get('/another', (req, res, next)) => { });

                      Here we are passing a route handler function that takes two arguments - req, res and potentially
                      next as well.

                      Note that in the code above we are passing a function reference. In other words we are not calling
                      the function and passing in arguments like this:

                      router.get('/another', (req, res, next)) => { }(arg1, arg2));

                      It's the express framework that calls the function and passes the arguments at runtime. So the
                      problem we have is that in the current implementation we are calling asyncMiddleware we are not
                      passing a reference to a function that takes the req, res and next parameters. To overcome this
                      issue we need to make a small change to the asyncMiddleware function.

                      When we call the asyncMiddleware function we can return a route handler function that looks like
                      this:

                      (req, res, next) => {});

                      This will make the asyncMiddleware function like a factory function. We call it and get a new
                      function that is a route handler that looks like this:

                      (req, res, next) => {});

                      Express can call that and pass the req, res and next arguments at runtime. So in the
                      asynMiddleware function we need to return a route handler function:

                      async function asyncMiddleware(handler) { return (req, res, next) => {

                      }; }

                      Now we have access to the req, res and next arguments (Express is going to pass this for us) So we
                      can move the existing code inside the code block we just created:

                      async function asynMiddleware(handler) { return (req, res, next) => { try { await
                      handler(req,res); } catch(ex) { next(ex); } }; }

                      Now in this function we are awaiting the call to the handler so we need to mark the calling
                      function as async:

                      return async (req, res, next) => {}

                      This means the asyncMiddleware function no longer needs to be marked as async because nowhere in
                      the asyncMiddleware are we awaiting a promise we are simply returning a function.

                      To review - with this new implementation we have moved the try/catch block to a single place. We
                      no longer need to repeat it in each route handler.This means the code in our route handlers will
                      be more focused. We can see the actual logic that belongs to the route handler.

                      We achieved this be defining the asyncMiddleware function that takes a function reference called
                      handler. When we call this function:

                      return async (req, res, next) => {}

                      So when we pass our original route handler here:

                      router.get('/', auth, asyncMiddleware(async (req, res) => { const genres = await
                      Genre.find().sort('name'); res.send(genres); }));

                      We are passing a function reference. We call that handler:

                      async function asyncMiddleware(handler)

                      When we call this function we return a standard express route handler:

                      return (req, res, next) => {

                      This route handler is an async function with three parameters in the body of the function we have
                      a try/catch block:

                      try { await handler(req,res); } catch(ex) { next(ex); }

                      In the try block we simply call the handler that we passed as an argument:

                      await handler(req, res)

                      Finally the asyncMiddleware function doesn't belong in the genres module so we move it to a new
                      file in the middleware folder called async.js and export the function.

                      module.exports = function (handler) { return async (req, res, next) => { try { await handler(req,
                      res); } catch(ex) { next(ex); } }; }


                      Now in genre.js you will need to import the module:

                      const asyncMiddleware = require('../middleware/async');

                      Now with this new implementation we simply wrap each route handler with the asyncMiddleware:

                      router.post('/', auth, asyncMiddleware(async (req, res) => { const { error } = validate(req.body);
                      if (error) return res.status(400).send(error.details[0].message);

                      let genre = new Genre({ name: req.body.name }); genre = await genre.save();

                      res.send(genre); }));

                      So we call asyncMiddleware and pass the existing route handler code as an argument.

                      147 - Express Async Errors ==========================

                      In the last lecture we defined the async middleware function. While the async middleware function
                      solves the problem of repetitive try/catch blocks the issue we have is that we have to remember to
                      call the asyncMiddleware function every time. This also makes our code a little bit noisy.

                      In this lecture we will use an npm module to monkey patch (A monkey patch is a way for a program
                      to extend or modify supporting system software locally (affecting only the running instance of the
                      program) our route handlers at runtime. So when we send a request to an endpoint that module will
                      wrap our route handler code inside something similar to the async function we created in the last
                      lecture.

                      So from the terminal in the vidly application run:

                      npm i express-async-errors@2.1.0

                      Next import the express-async-errors module into index.js:

                      require('express-async-errors');

                      That's all we have to do. We don't have to get the result and store it in a constant.

                      Remove the call to asyncMiddleware from the route handlers that are currently using it (genre GET
                      and POST) and remove the require statement for asyncMiddleware from the top of genres.js as well.

                      Now test by running mongod in the terminal, start the vidly application and get all the genres in
                      postman to check that endpoint is working.

                      Now stop mongodb and retry the get genres request in postman. After a fairly long period of time
                      you should receive a status 500 internal server error along with the message:

                      Something failed

                      This verifies that the module we installed properly moved control from our route handler to our
                      error handling function.

                      Using express async error handling module is very easy and for this reason it is my suggested
                      approach for handling async errors in express route handlers. However if this approach doesn't
                      work for your application you can switch back and use the asyncMiddleware function from the
                      previous lecture.

                      148 - Logging Errors ====================

                      So error.js is our current error middleware. Now, as discussed before, in every enterprise
                      application we need to log the exceptions that are thrown in the application. Later on we can
                      examine the log to see which areas of the application can be improved.

                      In this lecture we will introduce a very popular logging library called winston currently on
                      version 2.4. Install winston in the vidly application:

                      npm i winston@2.4.0

                      In index.js load winston:

                      const winston = require('winston');

                      The constant winston is the default logger that is exported from this module. We can also create a
                      logger manually but using the default logger will be sufficient for our application.

                      The logger object has what is known as a transport. A transport is essentially a storage device
                      for our logs and winston comes with several transports built-in:

                      console - for logging messages to the console file - for logging to a file http - for calling an
                      http endpoint to log messages

                      There are also plugin npm modules to log messages in both MongoDB and CouchDB as well as Redis and
                      Loggly (a popular log analysis and monitoring service for enterprise applications).

                      So this default logger that is exported from the winston module comes with a transport for logging
                      messages to the console but in this lecture we will add another transport for logging messages to
                      a file.

                      In index.js after the require statements add the following code:

                      winston.add(winston.transports.File, { filename: 'logfile.log' });

                      Now back in our error middleware we can log errors using winston. First import winston:

                      const winston = require('winston');

                      In the error function add the following code:

                      winston.error(err.message, err);

                      The first argument is the logging level which determines the importance of the error we are going
                      to log - error The most severe logging message - warn A warning - info For information (e.g.
                      Connected to MongoDB) - verbose - debug - silly

                      You can write the syntax differently to indicate the logging level with a helper message:

                      winston.error(err.message, err);

                      The second parameter is optional metadata, so we can pass the err object and every property in the
                      err object will be available in the log. To demonstrate let's throw an error in the get genres
                      route handler:

                      throw new Error('Could not get the genres.');

                      So now in our current implementation the error middleware will catch that error, log it using
                      winston and return the response code 500 to the client.

                      So let's run the application and get genres in postman - you should see the response code 500 -
                      internal server error.

                      In the console you will see the error: Could not get the genres. You will also see the stack trace
                      below (which is part of the err object). So this is the console transport which is configured on
                      the default logger.

                      Now in our project explorer we should see a new file logfile.log which contains a Json object with
                      several properties:

                      {"level":"error","message":"Could not get the genres.","timestamp":"2019-01-22T15:03:51.344Z"}

                      Message - Could not get the genres Stack - Represents the stack trace Level - Set to error
                      Timestapm - When the error occurred

                      So using the level property you could query the logfiles and extract only the errors or only the
                      information.

                      So this is the big picture. We simply call winston.error or one of the other helper methods and,
                      depending on the transports which we have configured, winston will log the given message.

                      149 - Logging to MongoDB ========================

                      Now let's look at how to log messages to mongodb. Install another winston package:

                      npm i winston-mongodb@3.0.0

                      Back in index.js in the last version we added a file transport, this time round we will add a
                      mongodb transport.

                      After we load winston we need to load winston-mongodb:

                      require('winston-mongodb');

                      Here we don't care about what is exported from this module - we just need to require it. Next add
                      another transport for winston under the code for the file transport:

                      winston.add(winston.transports.MongoDB, {db: 'mongodb://localhost/vidly'});

                      We pass an options object. There are a few properties here that you can see in the documentation
                      but we just set db: It is possible to seperate your logging database and your application database
                      but in this example we will keep logging in the application database.

                      Next time there is another error in the application because we have added another transport
                      Winston will automatically store our error in mongoDB. So let's run the application again and
                      submit a get genres request in postman. If you now look in MongoDBCompass if you refresh you
                      should see a log collection with one object:

                      _id: ObjectId("5c475a4128cb491d6c9ac25d") timestamp: 2019-01-22 18:00:33.365 level: "error"
                      message:"Could not get the genres" meta: Object

                      You can see a timestamp, an error level, a message and a meta object. The meta property is the
                      second argument that we passed to the winston.error call in error.js which was the err object.

                      The err object has a few properties (message, name, stacktrace) all of which get stored in
                      MongoDB.

                      So, in compass, if you expand the meta object you can see message, name, stack etc. These are all
                      the properties of the standard error object in JavaScript.

                      In the last lecture we talked about logging levels. When adding a transport we can also set the
                      logging levels on a per transport basis. For example, maybe you only want to log errors to MongoDB
                      and exclude info, verbose and all the other logging levels.

                      To achieve this you would modify the options object in the call to winston.add for the MongoDB
                      transport by adding in a level property

                      winston.add(winston.transports.MongoDB, { db: 'mongodb://localhost/vidly', level: 'error' });

                      If you were to set the level property to info you would receive info, warn and error messages
                      because warn and error are more severe than info:

                      error warn info verbose debug silly

                      Nothing beyond info will be logged in MongoDB

                      150 - Uncaught Exceptions =========================

                      The error middleware that we have added only catches errors that happen as part of the request
                      processing pipeline. So this is particular to express. If an error occurs outside of the context
                      of express the error middleware will not pick it up.

                      To demonstrate let's go back to index.js and after the code to for winston add the the following
                      code:

                      throw new Error('Something failed during startup.');

                      So the above error is thrown outside the context of processing a request - outside the context of
                      express. The process will crash and winston wont log anything. To verify this, you can delete
                      everything in logfile.log, save, and run the application:

                      node index.js

                      In the terminal we see our error:

                      throw new Error('Something failed during startup');

                      If you check the logfile.log it will still be empty. So if you deployed this application to
                      production, it would fail and there is no way for you to know what went wrong unless you have
                      access to the console on the server. So in this lecture we will examine how to properly handle
                      unhandled exceptions in node process. So, this is at a higher level, it is not tied to express.

                      Back in index.js earlier in the course you learned about the process object. process is an event
                      emitter which is an object which can emit or publish events. It gives a method called on which you
                      can use to subscribe or listen to events.

                      In node there is a standard event called uncaughtException. This event is raised when we have an
                      exception in the node process which hasn't been handled using a catch block:

                      process.on('uncaughtException');

                      If we have an uncaughtException event then wse can supply a function to handle it:

                      process.on('uncaughtException', (ex) => { console.log('WE GOT AN UNCAUGHT EXCEPTION');
                      winston.error(ex.message, ex); });

                      Back in the terminal run the application again:

                      WE GOT AN UNCAUGHT EXCEPTION

                      Notice this time the process doesn't terminate because we caught the exception. The process
                      terminates if we don't catch our exception. Check the logfile.log:

                      {"message":"Something failed during startup","stack":"Error: Something failed during startup\n at
                      Object.
                      <anonymous> (C:\\DevelopmentTutorials\\TheCompleteNodeJSCourse\\
                        11-handling-and-logging-errors\\150-uncaught-exceptions\\vidly\\index.js:30:7)\n at
                        Module._compile (module.js:653:30)\n at Object.Module._extensions..js (module.js:664:10)\n at
                        Module.load (module.js:566:32)\n at tryModuleLoad (module.js:506:12)\n at Function.Module._load
                        (module.js:498:3)\n at Function.Module.runMain (module.js:694:10)\n at startup
                        (bootstrap_node.js:204:16)\n at
                        bootstrap_node.js:625:3","level":"error","timestamp":"2019-01-22T18:58:54.281Z"}

                        We can see our error message. This is how we handle uncaught exceptions In the next lecture we
                        will look at unhandled promise rejections.

                        151 - Unhandled Promise Rejections ==================================

                        In the last lecture we learnt how to handle uncaught exceptions. So if there is an exception in
                        your application and you have not caught that exception using a catch block you can subscribe to
                        the on uncaughtException of the process object and log the error using winston.

                        However this approach only works with synchronous code which means if you have a promise
                        somewhere that is rejected the function you provide to uncaughtException will not be executed.

                        Let's replace the exception we threw in the previous lecture with a rejected promise:

                        const p = Promise.reject(new Error('Something failed miserably!'));

                        So imagine this promise represents the result of an asynchronous operation such as a call to the
                        database or a remote http service and so on.

                        So as discussed previously with promises we should either call .then() followed by .catch() to
                        handle rejections:

                        p.then().catch();

                        Or if we are using the async and await syntax we await the promise but we wrap it in a try/catch
                        block.

                        In the code we just added to index:

                        const p = Promise.reject(new Error('Something failed miserably!'));

                        we have a promise so I can call then():

                        p.then(() => console.log('Done'));

                        but I wont call catch() So we will have an unhandled rejection.

                        So if we run the application again we will get an UnhandledPromiseRejectionWarning. Currently
                        the application will continue to run but remember that Unhandled promise rejections are
                        deprecated - so this won't be the case in the future.

                        So to deal with unhandled promise rejections we need to subscribe to the unhandledRejection
                        event of the process object (index.js):

                        process.on('unhandledRejection', (ex) => { console.log('WE GOT AN UNHANDLED REJECTION');
                        winston.error(ex.message, ex); });

                        If we run the application again and then view logfile.log we will see the unhandled promise
                        rejection.

                        As a best practice whether you are dealing with an uncaught exception or an unhandled rejection
                        you should exit the process because at that point your process could be in an unclean state.

                        So if we exit the process how can we restart it in production. Well there are tools for that are
                        called process managers which we will look at later in the course. So modify the code to exit
                        the process in both code blocks:

                        process.on('uncaughtException', (ex) => { winston.error(ex.message, ex); process.exit(1); });

                        process.on('unhandledRejection', (ex) => { winston.error(ex.message, ex); process.exit(1); });

                        You can write this code in a different way by using the winston.handleExceptions method:

                        winston.handleExceptions(new winston.transports.File({ filename: 'uncaughtExceptions.log' }));

                        Note that when we call handleExceptions we are specifying a different transport than the one we
                        have configured with our default logger:

                        winston.add(winston.transports.File, { filename: 'logfile.log' });

                        You can use the same filename or a different filename that is your choice. We can also have
                        multiple transports. One question you might have is whether you should log to a file or to a
                        database. My opinion is that you should use both transports (databases are good for querying,
                        filesystem is always available (as opposed to database server which might go down))

                        At the time of writing winston.handleExceptions only works for uncaught exceptions, if you have
                        unhandled rejections they wont get logged.

                        I will show you a trick to get this working. First remove process.on('uncaughtException') and we
                        will just rely on winston.handleExceptions.

                        Next when we have an unhandledRejection we can simply throw the exception:

                        process.on('unhandledRejection', (ex) => { throw ex; });

                        which will raise an unhandled exception that is then dealt with by winston.handleExceptions that
                        will log it in the file and terminate the process.

                        152 - Error Handling Recap ==========================

                        To summarize. In express we have error middleware that is basically a function with four
                        arguments:

                        err req res next

                        This function catches any errors in the request processing pipeline. So we use winston to log
                        the error then return a response status 500 to the client. As discussed, this only works for
                        errors that occur in the request processing pipeline. Any errors that occur outside the context
                        of express will be ignored. If something goes wrong during application startup this function is
                        not going to be executed. That's why we call winston.handleExceptions in index.js to get any
                        uncaught exceptions and log them to a file.

                        Currently this only works with uncaught exceptions, it wont work with unhandled promise
                        rejections - hopefully this will be available in the future. In the meantime you can use the
                        workaround described at the end of the previous lecture. So as a best practice when you are
                        dealing with these kind of exceptions, you should terminate the node process because the process
                        can be in an unclean state. So you should restart it in a clean state. In production we use
                        tools that we call process managers, which are responsible for automatically restarting a node
                        process.

                        Now if you look at code in index.js you can see it is starting to get a bit out of hand. In the
                        next few lectures we will look at how to refactor this code and tidy it up to make it clean and
                        maintainable.

                        153 - Refactoring index.js Extracting the Routes
                        ================================================

                        The main issue with the code as it currently stands in index.js is lack of separation of
                        concerns. There are lots of things happening here which is why we need so many require
                        statements at the top of the file. Below that we have some for handling and logging errors, then
                        some configuration code, then the mongodb database connection logic, then we setup our api
                        endpoints and various middleware - these are all separate concerns. They should not be mixed up
                        in one module. In this module we should only orchestrate our concerns.

                        The details of setting up routes or the details of connecting to the database should be
                        separated. So in this lecture we will focus on extracting our routes into a separate module.

                        So create a new folder called startup with a new file called routes.js In this file we should
                        export a function:

                        module.exports = function() {}

                        In this function we will add all the code for setting up our routes and other middleware:

                        module.exports = function() { // app.use(at); // If everything required authentication
                        app.use(express.json()); app.use('/api/genres', genres); app.use('/api/customers', customers);
                        app.use('/api/movies', movies); app.use('/api/rentals', rentals); app.use('/api/users', users);
                        app.use('/api/auth', auth); app.use(error); }

                        So look at the dependencies here. We have a dependency to app object, express all these routes
                        etc. So in index.js on the top we create the app object like this:

                        const app = express();

                        We should have a single instance of app in the entire application. We don't want to load express
                        then call it to create an app object in our new module. So we want to send a reference to our
                        app as an argument to the new module:

                        module.exports = function(app)

                        Back in index.js we can load our new module:

                        require('./startup/routes')(app);

                        this returns a function which we call it and pass the app object:

                        Now we can move all the routes that we have setup in index.js to our new module:

                        const genres = require('./routes/genres'); const customers = require('./routes/customers');
                        const movies = require('./routes/movies'); const rentals = require('./routes/rentals'); const
                        users = require('./routes/users'); const auth = require('./routes/auth');

                        We also need express:

                        const express = require('express');

                        Now we will take the error middleware out of index.js:

                        const error = require('./middleware/error');

                        index.js is starting to look a bit tidier with less require statements and a cleaner
                        implementation.

                        Back in routes.js we need to change the route definitions because their paths are incorrect. In
                        Visual Studio Code you can multi select by selecting some text (./) and then using ctrl+d to
                        select the additional desired instances. replace the existing text ./ with ../ to fix up the
                        route paths.

                        Now, as an exercise, I want you to back to index.js and move all the database initialization
                        code to a different module. You will see the solution the next lecture.

                        154 - Extracting the DB logic =============================

                        Here in index.js we only have a small amount of code for database initialization. Add a new file
                        to startup called db.js. Export the function and move the database connection logic to that
                        file:

                        const mongoose = require('mongoose'); const winston = require('winston');

                        module.exports = function() { mongoose.connect('mongodb://localhost/vidly') .then(() =>
                        winston.info('Connected to MongoDB...')); }

                        We also loaded winston and used it to log info messages instead of console.log.

                        We remove the catch method that writes to the console:

                        .catch(err=> console.error('Could not conntect to MongoDB...'))

                        because if we can't connect to MongoDB we want to log that exception and terminate the process
                        but the catch statement handles the rejected promise and just displays a message on the console
                        - so we are not logging this and it is not terminating the process. We just added this earlier
                        purely for demonstration purposes. With the new implementation we don't need this.

                        Finally We also added code to import mongoose. We can cut this from index.js:

                        const mongoose = require('mongoose');

                        So that is our database module. You can see the code is very clean and short, we have a single
                        responsibility. We don't have too many things mixed up together.

                        Now back in index.js we load the db module and call the function that is returned:

                        require('./startup/db')();

                        Here we get a function which we call.

                        Let's verify with our current implementation that if we can't connect to the database during the
                        application startup that the exception will be logged and the process will be terminated.

                        So stop mongod and then run the application you should see an exception thrown in the console
                        window where the app was started:

                        winston-mongodb: error initialising logger { MongoError: failed to connect to server
                        [localhost:27017] on first connect [MongoError: connect ECONNREFUSED 127.0.0.1:27017]

                        You should also see that the exception has been logged in the uncaughtExceptions file. This is
                        why we needed to delete the catch logic in the database connection function to let our global
                        error handler deal with the rejected promise.

                        You're next exercise is to go back to index.js and extract all the code for logging errors into
                        a separate module called logging.js We will cover the solution in the next lecture.

                        155 - Extracting the Logging Logic ==================================

                        In this lecture we are going to move all the code for setting up logging to a different module.
                        So anything that is related to winston and handling rejected promises.

                        So back in the startup folder let's add a new file logging.js and export a function:

                        module.exports = function() {}

                        Now in index.js take the code for setting up winston and move it to logging.js within the
                        function.

                        We need to import winston and winston-mongodb so move those require statements from index.js as
                        well:

                        const winston = require('winston'); require('winston-mongodb');

                        We can also move the require statement for logging express-async-errors to our new logging
                        module:

                        require('express-async-errors');

                        Finally we need to go back to index.js and load the logging module. Put it before the other
                        require statements just in case they generate errors:

                        require('./startup/logging');

                        That completes the logging refactoring.

                        In the next lecture we will move all the code for dealing with configuration to a separate
                        module.

                        156 - Extracting the config Logic =================================

                        Let's add a config.js file in the startup folder that exports a function. Now move all the code
                        related to configuration settings into this new module:

                        module.exports = function() { if(!config.get('jwtPrivateKey')) { console.error('FATAL ERROR:
                        jwtPrivateKey is not defined.'); process.exit(1); } }

                        This code contains a dependency for config. We can move the require statement from index.js:

                        const config = require('config');

                        Now if we don't have the jwtPrivateKey config setting we no longer want to log this to the
                        console and exit the process. Instead we should store this as a fatal error in our log by
                        throwing an exception:

                        throw new Error('FATAL ERROR: jwtPrivateKey is not defined.');

                        Our current infrastructure will catch the exception, log it and terminate the process. Note it
                        is best practice to throw error objects instead of strings because when you throw an Error
                        object the stack trace will be available for you to view later. If, instead, you throw a string
                        with the error message the stack trace will not be available.

                        Finally in index.js load the config module:

                        require('./startup/config')();

                        and it's a function so we call it.

                        Now, if you look at the code in index.js, you only have 12 lines of code. The last thing we can
                        move here is the configuration of Joi:

                        const Joi = require('joi'); Joi.objectId = require('joi-objectid')(Joi);

                        We could move this to a module like validation.js or we could call that module api.js. We are
                        using Joi on the api layer. We use it to validate the input to our api. For this application,
                        honestly, I don't have a strong opinion of what we should call that module. We'll call it
                        validation.js - and cover the refactoring in the next lecture.

                        157 - Extracting the Validation Logic =====================================

                        Create a new file called validation.js and export a function then move the require statement
                        that adds object id validation to Joi:

                        module.exports = function() { Joi.objectId = require('joi-objectid')(Joi); }

                        Also at the top of validation.js add the require statement for Joi (you can move this from
                        index.js):

                        const Joi = require('joi');

                        Next add a require statement for the validation module in index.js:

                        require('./startup/validation.js')();

                        The code in index.js is much cleaner. Remember what we had before. There were about 60 or 70
                        lines of code with really poor separation of concerns. Now with this refactoring we are doing
                        only one thing - setting up the application. The details of logging, of routes, of databases are
                        delegate to other modules. This is single responsibility principle in practice.

                        Finally replace the console.log statement in index.js where we configure app to listen on port
                        3000 with winston:

                        app.listen(port, () => winston.info(`Listening on port ${port}...`));

                        Don't forget to require winston:

                        const winston = require('winston');

                        Run the application:

                        info: Listening on port 5000... info: Connected to MongoDB...

                        These are the two info messages coming from winston.

                        158 - Showing Unhandled Exceptions on the Console
                        =================================================

                        I notice a tiny problem in the current implementation. If you take this application on a
                        different machine and run:

                        node index.js

                        It terminates without telling us what happened. In the current implementation we are using
                        winston to handle exceptions with only a file transport. So if you look at
                        uncaughtExceptions.log you will see the exception detail. However if you didn't know this you
                        would have no idea what was going on.

                        For this reason we should add a console transport to display exceptions on the console as well.
                        So in logging.js in the winston.handleExceptions method we add a new transport:

                        new winston.transports.Console({ colorize: true, prettyPrint: true});

                        Now if you run the application again on the new machine you will see the exception on the
                        console (in this case jwtPrivateKey is not defined)

                        159 - Recap ===========

                        Handling and Logging Errors ---------------------------

                        So, in this section, you learned that:

                        Our applications don’t run in an ideal world. Unexpected errors can happen as a result of bugs
                        in our code or issues in the running environment. For example, our MongoDB server may shut down,
                        or a remote HTTP service we call may go down.

                        As a good developer, you should count for these unexpected errors, log them and return a proper
                        error to the client.

                        Use the Express error middleware to catch any unhandled exceptions in the “request processing
                        pipeline”.

                        Register the error middleware after all the existing routes:

                        app.use(function(err, req, res, next) { // Log the exception and return a friendly error to the
                        client. res.status(500).send(‘Something failed’); });

                        To pass control to the error middleware, wrap your route handler code in a try/ catch block and
                        call next().

                        try { const genres = await Genre.find(); … } catch(ex) { next(ex); });

                        Adding a try/catch block to every route handler is repetitive and time consuming. Use
                        express-async-errors module. This module will monkey-patch your route handlers at runtime. It’ll
                        wrap your code within a try/catch block and pass unhandled errors to your error middleware.

                        To log errors use winston -------------------------

                        Winston can log errors in multiple transports. A transport is where your log is stored.

                        The core transports that come with Winston are Console, File and Http. There are also 3rd-party
                        transports for storing logs in MongoDB, CouchDB, Redis and Loggly.

                        The error middleware in Express only catches exceptions in the request processing pipeline. Any
                        errors happening during the application startup (eg connecting to MongoDB) will be invisible to
                        Express.

                        Use process.on(‘uncaughtException’) to catch unhandled exceptions, and
                        process.on(‘unhandledRejection’) to catch rejected promises.

                        As a best practice, in the event handlers you pass to process.on(), you should log the exception
                        and exit the process, because your process may be in an unclean state and it may result in more
                        issues in the future. It’s better to restart the process in a clean state. In production, you
                        can use a process manager to automatically restart a Node process. You’ll learn about that later
                        in the course.
